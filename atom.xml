<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Time渐行渐远]]></title>
  <link href="http://dmlcoding.com/atom.xml" rel="self"/>
  <link href="http://dmlcoding.com/"/>
  <updated>2018-05-15T16:30:54+08:00</updated>
  <id>http://dmlcoding.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[集成学习]]></title>
    <link href="http://dmlcoding.com/15255701784620.html"/>
    <updated>2018-05-06T09:29:38+08:00</updated>
    <id>http://dmlcoding.com/15255701784620.html</id>
    <content type="html"><![CDATA[
<p>集成学习的思想是将若干个学习器(分类器&amp;回归器)组合之后产生一个新学习器.弱分类器(weak learner)指那些分类准确率只稍微好于随机猜测的分类器(error rate&lt; 0.5).</p>

<p>集成算法的成功在于保证弱分类器的多样性(Diversity).而且集成不稳定的算法也能够得到一个比较明显的性能提升.</p>

<p>常见的集成学习思想有:<br/>
    + Bagging<br/>
    + Boosting<br/>
    + Stacking</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">为什么需要集成学习</h2>

<ol>
<li>弱分类器间存在一定的差异性,这会导致分类的边界不同,也就是说可能存在错误.那么将多个弱分类器合并后,就可以得到更加合理的边界,减少整体的错误率,实现更好的效果.</li>
<li>对于数据集过大或者过小,可以分别进行划分和有放回的操作产生不同的数据子集,然后使用数据子集训练不同的分类器,最终再合并成为一个大的分类器.</li>
<li>如果数据的划分边界过于复杂,使用线性模型很难描述情况,那么可以训练多个模型,然后再进行模型的融合.</li>
<li>对于多个异构的特征集的时候,很难进行融合,那么可以考虑每个数据集构建一个分类模型,然后将多个模型融合.</li>
</ol>

<h1 id="toc_1">Bagging方法</h1>

<p>Bagging方法又叫自举汇聚法(Bootstrap Aggregating),思想是:在原始数据集上通过有放回的抽样的方式,重新选择出S个新数据集来分别训练S个分类器的集成技术.也就是说这些模型的训练数据中允许存在重复数据.</p>

<p>Bagging方法训练出来的模型在预测新样本分类的时候,会使用<strong>多数投票</strong>或者求<strong>均值</strong>的方式来统计最终的分类结果.</p>

<p>Bagging方法的弱学习器可以是基本的算法模型,eg:Linear,Ridge,Lasso,Logistic,Softmax,ID3,C4.5,CART,SVM,KNN等</p>

<p>备注:Bagging方式是有放回的抽样,并且每个子集的样本数量必须和原始样本数量一致,但是子集中允许存在重复数据.</p>

<p><img src="media/15255701784620/15259417755837.jpg" alt="Bagging方法-训练过程"/></p>

<h2 id="toc_2">随机森林(Random Forest)</h2>

<p>在Bagging策略的基础上进行修改后的一种算法</p>

<ol>
<li>从原始样本集(n个样本)中用Bootstrap采样(有放回重采样)选出n个样本;</li>
<li>从所有属性中随机选择k个属性,选择出最佳分割属性作为节点创建决策树;</li>
<li>重复以上两步m次,即建立m棵决策树;</li>
<li>这m个决策树形成随机森林,通过投票表决结果决定数据属于哪一类.</li>
</ol>

<h2 id="toc_3">随机森林的推广算法</h2>

<p>RF(随机森林)算法在实际应用中具有比较好的特性,应用也比较广泛,主要应用在:分类,回归,特征转换,异常点检测.常见的RF变种算法如下:</p>

<ul>
<li>Extra Tree</li>
<li>Totally Random Trees Embedding(TRTE)</li>
<li>lsolation Forest</li>
</ul>

<h2 id="toc_4">Extra Tree</h2>

<p>Extra Tree是RF的一个变种,原理基本和RF一样,区别如下:</p>

<ol>
<li>RF会随机采样作为子决策树的训练集,而Extra Tree每个子决策树采样原始数据集训练;</li>
<li>RF在选择划分特征点的时候会和传统决策树一样,会基于信息增益,信息增益率,基尼系数,均方差等原则来选择最优特征值;而Extra Tree会随机的选择一个特征值来划分决策树,</li>
</ol>

<p>Extra Tree因为是随机选择特征值的划分点,这样会导致决策树的规模一般大于RF所生成的决策树.也就是说Extra Tree模型的方差相对于RF进一步减少.在某些情况下,Extra Tree的泛华能力比RF的强.</p>

<h2 id="toc_5">Totally Random Trees Embedding(TRTE)</h2>

<p>TRTE是一种非监督的数据转化方式.将低维的数据集映射到高维,从而让映射到高维的数据更好的应用于分类回归模型.</p>

<p>TRTE算法的转换过程类似RF算法的方法,建立T个决策树来拟合数据.当决策树构建完成后,数据集里的每个数据在T个决策树叶子节点的位置就定下来了,将位置信息转换为向量就完成了特征转换操作.</p>

<h2 id="toc_6">Isolation Forest(IForest)</h2>

<p>IForest是一种异常点检测算法,使用类似RF的方式来检测异常点;IForest算法和RF算法的区别在于:</p>

<ol>
<li>在随机采样的过程中,一般只需要少量数据即可;</li>
<li>在进行决策树构建过程中,IForest算法会随机选择一个划分特征,并对划分特征随机选择一个划分阈值.</li>
<li>IForest算法构建的决策树一般深度max_depth是比较小的</li>
</ol>

<p>区别原因:目的是异常点检测,所以只要能够区分异常的即可,不需要大量数据;另外在异常点检测的过程中,一般不需要太大规模的决策树.</p>

<p>对于异常点的判断,则是将测试样本x拟合到T棵决策树上.计算在每棵树上该样本的叶子节点的深度\(h_t(x)\).从而计算出平均深度\(h(x)\);然后就可以使用下列公式计算样本点x的异常概率值,p(s,m)的取值范围为[0,1],越接近于1,则是异常点的概率越大.</p>

<p>\[p(x,m)=2^{-\dfrac{h(x)}{c(m)}}\]<br/>
\[c(m)=2\ln(m-1)+\xi-2\dfrac{m-1}{m} : m为样本个数,\xi为欧拉常数\]</p>

<h2 id="toc_7">RF随机森林总结</h2>

<ul>
<li><p>RF的主要优点</p>

<ul>
<li>1. 训练可以并行化,对于大规模样本的训练具有速度的优势;</li>
<li>2. 由于进行随机选择决策树划分特征列表,这样在样本维度比较高的时候,仍然具有比较高的训练性能;</li>
<li>3. 可以给出各个特征的重要性列表;</li>
<li>4. 由于存在随机抽样,训练出来的模型方差小,泛化能力强;</li>
<li>5. RF实现简单;</li>
<li>6. 对于部分特征的缺失不敏感.</li>
</ul></li>
<li><p>RF的主要缺点</p>

<ul>
<li>1. 在某些噪音比较大的特征上,RF模型容易陷入过拟合;</li>
<li>2. 取值比较多的划分特征对RF的决策会产生更大的影响,从而有可能影响模型的效果.</li>
</ul></li>
</ul>

<h2 id="toc_8">随机森林算法案例</h2>

<pre><code>```
```
</code></pre>

<h2 id="toc_9">RF scikit-learn相关参数</h2>

<p><img src="media/15255701784620/15260264540993.jpg" alt=""/></p>

<h2 id="toc_10">随机森林的思考</h2>

<p>在随机森林的构建过程中,由于各棵树之间是没有关系的,相对独立的;在构建的过程中,构建第m棵子树的时候,不会考虑前面的m-1棵树.</p>

<p>思考:<br/>
1. 如果在构建第m棵子树的时候,考虑到前m-1棵子树的结果,会不会对最终结果产生有益的影响?<br/>
2. 各个决策树组成随机森林后,在形成最终结果的时候能不能给定一种既定的决策顺序呢?</p>

<h1 id="toc_11">Boosting</h1>

<p>提升学习(Boosting)是一种机器学习技术,可以用于回归和分类的问题,它每一步产生弱预测模型(如决策树),并加权累加到总模型中;如果每一步的弱项模型的生成都是依据损失函数的梯度方式的,那么就称为梯度提升(Gradient boosting).</p>

<p>提升技术的意义:如果一个问题存在弱预测模型,那么可以通过提升技术的方法得到一个强预测模型.</p>

<p>常见的模型有:</p>

<ul>
<li>Adaboost</li>
<li>Gradient Boosting(GBT/GBDT/GBRT)</li>
</ul>

<p><img src="media/15255701784620/15260302457703.jpg" alt=""/></p>

<h2 id="toc_12">Adaboost算法公式</h2>

<p>Adaboost算法将基分类器的线性组合作为强分类器,同时给分类误差率较小的基本分类器以大的权重,给分类误差率较大的基分类器以小的权重值;构建的线性组合为:<br/>
\[f(x)=\sum_{m=1}^M\alpha_mG_m(x)\]</p>

<p>最终分类器是在线性组合的基础上进行Sign函数转换:<br/>
\[G(x)=sign(f(x))=sign \left[\sum_{m=1}^M\alpha_mG_m(x) \right]\]</p>

<p>Sign函数<br/>
<img src="media/15255701784620/15260310974094.jpg" alt="Sign函数"/></p>

<h2 id="toc_13">AdaBoost算法原理</h2>

<p>Adaptive Boosting是一种迭代算法.每轮迭代中会在训练集上产生一个新的学习器,然后使用该学习器对所有样本进行预测,以评估每个样本的重要性(Informative).换句话来讲就是,算法会为每个样本赋予一个权重,每次用训练好的学习器标注/预测各个样本,如果某个样本点被预测的越正确,则将其权重降低;否则提高样本的权重.权重越高的样本在下一个迭代训练中所占的比重就越大,也就是说越难区分的样本在训练过程中会变得越重要.</p>

<p>整个迭代过程直到错误率足够小或者达到一定的迭代次数为止.</p>

<p>样本加权</p>

<p><img src="media/15255701784620/15260307178045.jpg" alt="样本加权"/></p>

<p>最终的强学习器<br/>
\[G(x)=sign(f(x))=sign \left[\sum_{m=1}^M\alpha_mG_m(x) \right]\]</p>

<p>损失函数<br/>
\[loss=\dfrac{1}{n}\sum_{i=1}^nI(G(x_i)\neq y_i)\]</p>

<p>损失函数<br/>
\[loss=\dfrac{1}{n}\sum_{i=1}^nI(G(x_i)\neq y_i) \leq \dfrac{1}{n}\sum_{i=1}^ne^{(-y_if(x))}\]</p>

<p>第k-1轮的强学习器<br/>
\[f_{k-1}(x)=\sum_{j=1}^{k-1}\alpha_jG_j(x)\]</p>

<p>第k轮的强学习器<br/>
\[f_{k}(x)=\sum_{j=1}^{k}\alpha_jG_j(x) \qquad<br/>
f_k(x)=f_{k-1}(x)+\alpha_kG_k(x)<br/>
\]</p>

<p>损失函数<br/>
\[loss(\alpha_m,G_m(x))=\dfrac{1}{n}\sum_{i=1}^ne^{(-y_i(f_{n-1}(x)+\alpha_mG_m(x)))}\]</p>

<p>未完待续</p>

<h2 id="toc_14">...</h2>

<h2 id="toc_15">AdaBoost总结</h2>

<ul>
<li><p>daBoost的优点如下:</p>

<ul>
<li>可以处理连续值和离散值;</li>
<li>模型的鲁棒性比较强;</li>
<li>解释强,结构简单.</li>
</ul></li>
<li><p>AdaBoost的缺点如下:</p>

<ul>
<li>对异常样本敏感,异常样本可能会在迭代过程中获得较高的权重值,最终影响模型效果.</li>
</ul></li>
</ul>

<h1 id="toc_16">Stacking</h1>

<p>Stacking是指训练一个模型用于组合(combine)其他模型(基模型/基学习器)的技术.即首先训练出多个不同的模型,然后再以之前训练的各个模型的输出作为输入来新训练一个新的模型,从而得到一个最终的模型.一般情况下使用单层的Logistic回归作为组合模型<br/>
<img src="media/15255701784620/15260322012383.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[决策树]]></title>
    <link href="http://dmlcoding.com/15255685118456.html"/>
    <updated>2018-05-06T09:01:51+08:00</updated>
    <id>http://dmlcoding.com/15255685118456.html</id>
    <content type="html"><![CDATA[
<p>在决策树算法的学习过程中,信息增益是特征选择的一个重要指标.它定义为一个特征能够为分类系统带来多少信息,带来的信息越多,说明该特征越重要,相应的信息增益也就越大<br/>
<img src="media/15255685118456/15256176444642.jpg" alt=""/></p>

<h1 id="toc_0">信息熵(Entropy)</h1>

<p>\[H(X)=-\sum_{i=1}^mp_i\log_2(p_i)\]</p>

<span id="more"></span><!-- more -->

<ul>
<li>信息量:指的是一个样本/事件所蕴含的信息,如果一个事件的概率越大,那么就可以认为该事件所蕴含的信息越少.比如:总所周知的&quot;太阳从东方升起&quot;.因为是确定事件,所以不携带任何信息量.</li>
<li>信息熵:1948年,香农引入信息熵;<strong>一个系统越是有序,信息熵就越低;一个系统越是混乱,信息熵就越高.</strong> 所以,信息熵被认为是一个系统有序程度的度量</li>
<li>信息熵就是用来描述系统信息量的不确定度(复杂度)的.</li>
</ul>

<p>High Entropy(高信息熵):表示随机变量X是均匀分布的,各种取值情况是等概率出现的.<br/>
Low Entropy(低信息熵):表示随机变量X各种取值不是等概率出现.可能出现有的事件概率很大,有的事件概率很小.</p>

<h2 id="toc_1">条件熵H(Y|X)</h2>

<blockquote>
<p>给定条件X的情况下,随机变量Y的信息熵就叫做条件熵</p>
</blockquote>

<p>在计算条件熵的情况下,先计算一个小例子.看下面这张图<br/>
<img src="media/15255685118456/15256671505083.jpg" alt=""/></p>

<p>我们可以得出<br/>
P(X=数学)=4/8=0.5<br/>
P(Y=M)=4/8=0.5<br/>
P(X=数学,Y=F)=2/8=0.25<br/>
p(Y=M|X=英语)=0(由图可知,英语专业的都是女生)</p>

<p>根据这个公式,计算H(X)和H(Y)<br/>
\[H(X)=-\sum_{i=1}^mp_i\log_2(p_i)\]<br/>
因为:<br/>
P(X=数学)=0.5<br/>
P(X=英语)=0.25<br/>
P(X=IT)=0.25<br/>
所以:<br/>
\[H(X)=-0.5log_2{0.5}-0.25log_2{0.25}-0.25log_2{0.25}=1.5\]</p>

<p>因为:<br/>
P(Y=M)=4/8=0.5<br/>
P(Y=F)=4/8=0.5<br/>
\[H(Y)=-0.5log_2{0.5}-0.5log_2{0.5}=1\]</p>

<p>比如:当专业(X)为数学的时候,Y的信息熵的值为:H(Y|X=数学)</p>

<p><img src="media/15255685118456/15256671787875.jpg" alt=""/></p>

<p>摘出专业都是数学的这部分,性别符合均匀分布.因此条件熵为1<br/>
\[H(Y|X=数学)=1\]</p>

<p>给定条件X的情况下,所有不同X值情况下Y的信息熵的平均值叫做条件熵.<br/>
\[H(Y|X)=\sum_{j=1}P(X=v_j)H(Y|X=v_j)\]</p>

<p><img src="media/15255685118456/15256888532803.jpg" alt=""/></p>

<p>\[H(Y|X)=0.5*1+0.25*0+0.25*0=0.5\]</p>

<p>给定条件X的情况下,所有不同X值情况下Y的信息熵的平均值叫做条件熵.另外一个公司如下所示:<br/>
\[H(Y|X)=H(X,Y)-H(X)\]<br/>
事件(X,Y)发生所包含的熵,减去事件X单独发生的熵,即为在事件X发生的前提下,Y发生&quot;新&quot;带来的熵,这个也就是条件熵本身的概念.</p>

<p>参考:<a href="https://blog.csdn.net/pipisorry/article/details/51695283">https://blog.csdn.net/pipisorry/article/details/51695283</a></p>

<h2 id="toc_2">条件熵H(Y|X)公式推导</h2>

<p>\[<br/>
\begin{aligned}<br/>
H(Y|X) &amp; = \sum_{j=1}P(X=v_j)H(Y|X=v_j) \\\<br/>
&amp; = \sum_xP(X)H(Y|X) \\\<br/>
&amp; = \sum_xp(x)\left(-\sum_yp(y|x)\log(p(y|x))\right) \\\<br/>
&amp; = -\sum_x\sum_yp(x,y)log\left(\dfrac{p(x,y)}{p(x)}\right) \\\<br/>
&amp; = -\sum_x\sum_yp(x,y)log(p(x,y))-\left [-\sum_x \left (\sum_yp(x,y) \right )\log(p(x)) \right ] \\\<br/>
&amp; = H(X,Y)- \left [-\sum_xp(x)\log(p(x)) \right ] \\\<br/>
&amp; = H(X,Y)-H(X)<br/>
\end{aligned} <br/>
\]</p>

<h2 id="toc_3">信息增益</h2>

<p>信息增益恰好是:信息熵-条件熵</p>

<p>也就是说,信息增益代表了在一个条件下,信息复杂度(不确定性)减少的程度.</p>

<p>那么我们现在也很好理解了,在决策树算法中,我们的关键就是每次选择一个特征,特征有多个,那么到底按照什么标准来选择哪一个特征.</p>

<p>这个问题就可以用信息增益率来度量.如果选择一个特征后,信息增益率最大(信息不确定性减少的程度最大),那么我们就选取这个特征</p>

<h1 id="toc_4">决策树(Decision Tree)</h1>

<h2 id="toc_5">什么是决策树</h2>

<p>决策树是在已知各种情况发生概率的基础上,通过构建决策树来进行分析的一种方式,是一种直观应用概率分析的一种图解法;决策树是一种预测模型,代表的是对象属性与对象值之间的映射关系;决策树是一种树形结构,其中每个内部节点表示一个属性的测试,每个分支表示一个测试输出,每个叶节点代表一种类别;决策树是一种非常常用的有监督的分类算法.</p>

<p>决策树的决策过程就是从根节点开始,测试待分类项中对应的特征属性,并按照其值选择输出分支,直到叶子节点,将叶子节点的存放的类别作为决策结果.</p>

<p>决策树分为两大类:分类树和回归树,前者用于分类标签值,后者用于预测连续值,常用算法有ID3,C4.5,CART等</p>

<h2 id="toc_6">决策树的构建过程</h2>

<p>决策树算法的重点是决策树的构造;决策树的构造就是进行属性选择度量,确定各个特征属性之间的拓扑结构(树结构);构建决策树的关键步骤就是分裂属性,分裂属性是指在某个节点按照某一个类特征属性的不同划分构建不同的分支,其目标就是让各个分裂子集尽可能的&quot;纯&quot;(让一个分类子类中待分类的项尽可能的属于同一个类别).</p>

<p>构建步骤如下:</p>

<ol>
<li>将所有的特征看成一个一个的节点;</li>
<li>遍历每个特征的每一种分割方式,找到最好的分割点;将数据划分为不同的子节点.eg:\(N_1,N_2...N_m\);计算划分之后所有子节点的&quot;纯度&quot;信息;</li>
<li>对第二步产生的分割,选择出最优的特征以及最优的划分方式;得出最终的子节点:\(N_1,N_2...N_m\);</li>
<li>对子节点\(N_1,N_2...N_m\)分别继续执行2-3步,直到每个最终的子节点都足够&quot;纯&quot;.</li>
</ol>

<h2 id="toc_7">决策树特征属性类型</h2>

<p>属性类型当然可以是离散型和连续型.</p>

<p>根据特征属性的类型不同,在构建决策树的时候,采用不同的方式,具体如下:</p>

<ol>
<li>属性是离散值,而且不要求生成的是二叉决策树,此时一个属性就是一个分支.</li>
<li>属性是离散值,而且要求生成的是二叉决策树,此时使用属性划分的子集进行测试,按照&quot;属于此子集&quot;和&quot;不属于此子集&quot;分成两个分支.</li>
<li>属性是连续值,可以确定一个值作为分裂点split_point,按照&gt;split_point和&lt;=split_point生成两个分支.</li>
</ol>

<h2 id="toc_8">决策树分割属性选择</h2>

<p>决策树算法是一种&quot;贪心&quot;算法策略,只考虑在当前数据特征情况下的<strong>最好分割方式</strong>,不能进行回溯操作.</p>

<p>对于整体的数据集而言,按照所有的特征属性进行划分操作,对所有的划分操作的结果集的&quot;<strong>纯度</strong>&quot;进行比较.选择&quot;纯度&quot;越高的特征属性作为当前需要分割的数据集进行分割操作,持续迭代,直到得到最终结果.决策树是通过&quot;纯度&quot;来选择分割特征属性点的.</p>

<p>说了这么多&quot;纯&quot;,那么究竟该如何量化纯度值呢?</p>

<h2 id="toc_9">决策树量化纯度</h2>

<p>决策树的构建是基于<strong>样本概率</strong>和<strong>纯度</strong>进行构建操作的,那么进行判断数据集是否&quot;纯&quot;可以通过三个公式进行判断,分别是<strong>Gini系数</strong>,<strong>熵(Entropy)</strong>,<strong>错误率</strong>.<strong>这三个公式值越大,表示数据越&quot;不纯&quot;.越小表示越&quot;纯&quot;</strong>;实践证明这三个公式效果差不多,一般情况使用熵公式</p>

<p>\[Gini=1-\sum_{i=1}^nP(i)^2\]</p>

<p>\[H(Entropy)=-\sum_{i=1}^nP(i)\log_2(P(i))\]</p>

<p>\[Error=1-max  \sideset{_{i=1}^n}{}\lbrace P(i) \rbrace\]</p>

<h2 id="toc_10">决策树量化纯度</h2>

<p>当计算出各个特征属性的量化纯度值后使用<strong>信息增益度</strong>来选择出当前数据集的分割特征属性;<strong>如果信息增益度的值越大,表示在该特征属性上会损失的纯度越大,那么该属性就越应该在决策树的上层</strong>,计算公式为:<br/>
\[Gain=\Delta=H(D)-H(D|A)\]</p>

<p>Gain为A为特征对训练数据集D的信息增益,它为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差</p>

<h2 id="toc_11">决策树算法的停止条件</h2>

<p>决策树构建的过程是一个递归的过程,所以必须给定停止条件,否则过程将不会进行停止,一般情况有两种停止条件:<br/>
1. 当每个子节点只有一种类型的时候停止构建;<br/>
2. 当前节点中记录数小于某个阈值,同时迭代次数达到给定值时,停止构建过程,此时使用\(\max(p(i))\)作为节点的对应类型</p>

<p>方式一可能会使树的节点过多,导致过拟合(Overfiting)等问题;<br/>
比较常用的方式是使用方式二作为停止条件</p>

<h2 id="toc_12">决策树算法效果评估(重新听,补充这里的推导算法)</h2>

<p>决策树的效果评估和一般的分类算法一样,采用<strong>混淆矩阵</strong>来进行计算准确率,召回率,精确率等指标.</p>

<p>也可以采用叶子节点的纯度值总和来评估算法的效果.值越小,效果越好.</p>

<p>也就是决策树的损失函数(该值越小,算法效果越好)<br/>
\[C(T)=\sum_{t=1}^{leaf}\dfrac{|D_t|}{|D|}H(t)\]</p>

<h3 id="toc_13">决策树直观理解结果计算</h3>

<p><img src="media/15255685118456/15256176444642.jpg" alt=""/></p>

<h1 id="toc_14">决策树生成算法</h1>

<p>建立决策树的主要是以下三种算法</p>

<ul>
<li>ID3</li>
<li>C4.5</li>
<li>CART(Classification And Regression Tree)</li>
</ul>

<h2 id="toc_15">ID3算法</h2>

<p>ID3算法是决策树的一个经典的构造算法,内部使用信息熵以及信息增益来进行构建;每次迭代选择信息增益最大的特征属性作为分割属性.</p>

<p>也就是会用到前面写到的两个公式</p>

<p>\[H(D)=-\sum_{i=1}^nP(i)\log_2(P(i))\]<br/>
\[Gain=\Delta=H(D)-H(D|A)\]</p>

<h2 id="toc_16">ID3算法优缺点</h2>

<ul>
<li><p>优点</p>

<ul>
<li>决策树构建速度快,实现简单</li>
</ul></li>
<li><p>缺点</p>

<ul>
<li>计算依赖于特征数目较多的特征,而属性值最多的属性并不一定最优</li>
<li>ID3算法不是递增算法</li>
<li>ID3算法是单变量决策树,对于特征属性之间的关系不会考虑</li>
<li>抗噪性差</li>
<li>只适合小规模数据集,需要将数据放到内存中</li>
</ul></li>
</ul>

<h2 id="toc_17">C4.5算法</h2>

<p>在ID3算法的基础上,进行算法优化提出的一种算法(C4.5);现在C4.5已经是特别经典的一种决策树构造算法;使用<strong>信息增益率</strong>来取代ID3算法中的信息增益,在树的构造过程中会<strong>进行剪枝操作进行优化</strong>;能够自动完成对连续属性的离散化处理;C4.5算法在选中分割属性的时候选择信息增益率最大的属性,涉及到的公式为:<br/>
\[H(D)=-\sum_{i=1}^nP(i)\log_2(P(i))\]<br/>
\[Gain=\Delta=H(D)-H(D|A)\]<br/>
\[Gain\_ration(A)=\dfrac{Gain(A)}{H(A)}\]</p>

<h2 id="toc_18">C4.5算法优缺点</h2>

<ul>
<li><p>优点</p>

<ul>
<li>产生的规则易于理解</li>
<li>准确率较高</li>
<li>实现简单</li>
</ul></li>
<li><p>缺点</p>

<ul>
<li>对数据集需要进行多次顺序扫描和排序,所以效率较低</li>
<li>只适合小规模数据集,需要将数据放到内存中</li>
</ul></li>
</ul>

<p>总结:属性越多,信息增益率越大</p>

<h2 id="toc_19">CART算法</h2>

<p>使用<strong>基尼系数</strong>作为数据纯度的量化指标来构建的决策树算法就叫做CART(Classification And Regression Tree,分类回归树)算法.CART算法使用<strong>GINI增益</strong>作为分割属性选择的标准,选择GINI增益最大的作为当前数据集的分割属性;可用于分类和归类两类问题.强调备注:CART构建的是二叉树.</p>

<p>\[Gini=1-\sum_{i=1}^nP(i)^2\]<br/>
\[Gain=\Delta=Gini(D)-Gini(D|A)\]</p>

<h2 id="toc_20">ID3,C4.5,CART分类算法总结</h2>

<ol>
<li>ID3和C4.5算法只适合在小规模数据集上使用</li>
<li>ID3和C4.5算法都是单变量决策树</li>
<li>当属性值取值比较多的时候,最好考虑C4.5算法,ID3得出的效果会比较差</li>
<li>决策树分类一般情况只适合小数据量的情况(数据可以放内存)</li>
<li>CART算法是三种算法中最常用的一种决策树构建算法</li>
<li>三种算法的区别仅仅只是对于当前树的评价标准不同而已,<em>ID3使用信息增益</em>,<em>C4.5使用信息增益率</em>,<em>CART使用基尼系数</em></li>
<li>CART算法构建的一定是二叉树,ID3和C4.5构建的不一定是二叉树</li>
</ol>

<table>
<thead>
<tr>
<th>算法</th>
<th>支持模型</th>
<th>树结构</th>
<th>特征选择</th>
<th>连续值处理</th>
<th>缺失值处理</th>
<th>剪枝</th>
<th>特征属性多次使用</th>
</tr>
</thead>

<tbody>
<tr>
<td>ID3</td>
<td>分类</td>
<td>多叉树</td>
<td>信息增益</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr>
<td>C4.5</td>
<td>分类</td>
<td>多叉树</td>
<td>信息增益率</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>CART</td>
<td>分类,回归</td>
<td>二叉树</td>
<td>基尼系数,均方差</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody>
</table>

<h1 id="toc_21">案例一:使用鸢尾花数据分类(分类树案例)</h1>

<p>使用决策树算法API对鸢尾花数据进行分类操作,并理解及进行决策树API的相关参数优化</p>

<p><a href="http://archive.ics.uci.edu/ml/datasets/Iris">数据来源</a></p>

<h2 id="toc_22">鸢尾花数据集描述</h2>

<p>Data Set Information:</p>

<p>This is perhaps the best known database to be found in the pattern recognition literature. Fisher&#39;s paper is a classic in the field and is referenced frequently to this day. (See Duda &amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. </p>

<p>Predicted attribute: class of iris plant. </p>

<p>This is an exceedingly simple domain. </p>

<p>This data differs from the data presented in Fishers article (identified by Steve Chadwick, spchadwick &#39;@&#39; espeedaz.net ). The 35th sample should be: 4.9,3.1,1.5,0.2,&quot;Iris-setosa&quot; where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,&quot;Iris-setosa&quot; where the errors are in the second and third features.</p>

<p>Attribute Information:</p>

<ol>
<li>sepal length in cm </li>
<li>sepal width in cm </li>
<li>petal length in cm </li>
<li>petal width in cm </li>
<li>class: 
-- Iris Setosa 
-- Iris Versicolour 
-- Iris Virginica</li>
</ol>

<h1 id="toc_23">分类树和回归树的区别</h1>

<p>分类树采用信息增益,信息增益率,基尼系数来评价树的效果,都是基于概率值进行判断的;而分类树的叶子节点的预测值一般为叶子节点中概率最大的类别作为当前叶子的预测值</p>

<p>在回归树中,叶子节点的预测值一般为叶子节点中所有值的均值来作为当前叶子节点的预测值.所以在回归树中一般采用MSE作为树的评价指标,即均方差.<br/>
\[MSE=\dfrac{1}{n}\sum_{i=1}^n(y_i-\hat y_i)^2\]</p>

<p>一般情况下,只会使用CART算法构建回归树.</p>

<h1 id="toc_24">案例二:波士顿房屋租赁价格预测(回归树案例)</h1>

<h1 id="toc_25">决策树过拟合和欠拟合</h1>

<h1 id="toc_26">决策树优化策略</h1>

<h2 id="toc_27">剪枝优化</h2>

<p>决策树过渡拟合一般情况是由于节点过多导致的,剪枝优化对决策树的正确率影响是比较大的,也是最常用的一种优化方式</p>

<p>决策树的剪枝是决策树算法中最基本,最有用的一种优化方案,主要分为两大类</p>

<h3 id="toc_28">决策树的剪枝方案</h3>

<p><strong>前置剪枝</strong>:在构建决策树的过程中,提前停止.结果是决策树一般比较小,实践证明这种策略无法得到比较好的结果</p>

<p><strong>后置剪枝</strong>:在决策树构建好后,然后再开始裁剪,一般使用两种方式:<br/>
    1. 用单一叶子节点代替整个子树.叶子点的分类采用子树中最主要的分类;<br/>
    2. 将一个子树完全替代另外一颗子树.<br/>
    3. 后置剪枝的主要问题是计算效率问题,存在一定的浪费情况.</p>

<p>后置剪枝总体思路(交叉验证):<br/>
+ 由完全树\(T_0\)开始,剪枝部分节点得到\(T_1\),在此剪枝得到\(T_2\)...直到仅剩树根的树\(T_k\)<br/>
+ 在验证数据集上对这k+1个树进行评价,选择最优树\(T_a\)(损失函数最小的树)</p>

<h3 id="toc_29">决策树剪枝过程</h3>

<p>对于给定的决策树\(T_0\):</p>

<ol>
<li>计算所有内部非叶子节点的<strong>剪枝系数</strong></li>
<li>查找<strong>最小剪枝系数</strong>的节点,将其子节点进行删除操作,进行剪枝得到决策树\(T_k\);如果存在多个最小剪枝系数节点,选择包含<strong>数据项最多</strong>的节点进行剪枝操作</li>
<li>重复上述操作,直到产生的剪枝决策树\(T_k\)只有1个节点</li>
<li>得到决策树\(T_0T_1T_2...T_k\)</li>
<li>使用<strong>验证样本集</strong>选择最优子树\(T_a\)</li>
</ol>

<p>使用验证集选择最优子树的标准,可以使用原始损失函数来考虑:<br/>
\[loss=\sum_{t=1}^{leaf}\dfrac{|D_t|}{|D|}H(t)\]</p>

<h3 id="toc_30">决策树剪枝损失函数及剪枝系数</h3>

<p>原始损失函数<br/>
\[loss=\sum_{t=1}^{leaf}\dfrac{|D_t|}{|D|}H(t)\]</p>

<p>叶节点越多,决策树越复杂,损失越大;修正添加剪枝系数,修改后的损失函数为<br/>
\[loss_{\alpha}=loss+\alpha*leaf\]</p>

<p>考虑根节点为r的子树,剪枝前后的损失函数分别为loss(R)和loss(r),当这两者相等的时候,可以求得剪枝系数<br/>
\[loss_{\alpha}(r)=loss(r)+\alpha\]<br/>
\[loss_{\alpha}(R)=loss(R)+\alpha*R_{leaf}\]<br/>
\[\alpha=\dfrac{loss(r)-loss(R)}{R_{leaf}-1}\]</p>

<h2 id="toc_31">Random Forest(随机森林)</h2>

<p>利用训练数据随机产生多个决策树,形成一个森林.然后使用这个森林对数据进行预测,选取最多结果作为预测结果.</p>

<h1 id="toc_32">总结</h1>

<p>1.分类树和回归树<br/>
区别:<br/>
a. 分类树中使用信息熵,gini系数,错误率作为数&quot;纯度&quot;的度量指标;回归树中使用MSE,MAE作为树的&quot;纯度&quot;度量指标;<br/>
b.分类树使用叶子节点中包含最多那个类别作为当前叶子的预测值;回归树中使用叶子节点中包含的所有样本的目标属性的均值作为当前叶子的预测值.</p>

<p>2.决策树的构建过程<br/>
思想:<br/>
让每次分裂数据集的时候,让分裂之后的数据集更加的&quot;纯&quot;(让数据更有区分能力)</p>

<p>3.决策树分裂属性选择方式<br/>
a.基于最优划分的规则进行选择:迭代计算所有特征属性上所有划分方式后的&quot;纯度&quot;,选择划分后更加&quot;纯&quot;的一种方式(信息增益,信息增益率).---&gt;<br/>
只能说明在当前数据集上是最优的,所以可能会存在一定的过拟合情况.<br/>
b.基于随机的划分规则:每次划分的时候,都是先选择一定数目的特征,然后在这部分特征中选择出一个最优的划分特征.因为每次选的划分特征都是局部最优的,相对来讲,可以增加模型的鲁棒性,降低模型的过拟合性.</p>

<p>4.决策树的欠拟合,过拟合<br/>
a.可以通过增加树的深度来缓解决策树欠拟合这个问题<br/>
b.我们可以通过限制树的复杂程度来缓解这个过拟合的问题<br/>
c.因此也就是找到一个平衡</p>

<p>5.网格交叉验证(GridSearchCV)<br/>
6.决策树的效果评估</p>

<h1 id="toc_33">决策树可视化</h1>

<p>决策树可视化可以方便我们直观的观察所构建的树模型;决策树可视化依赖graphiz服务,所以我们在进行可视化之前,安装对应的服务.</p>

<h2 id="toc_34">安装</h2>

<p>下载地址:<a href="http://www.graphviz.org/">http://www.graphviz.org/</a><br/>
Mac安装步骤</p>

<pre><code># 安装graphviz服务
brew install graphviz

# 安装python的graphviz插件
pip install graphviz

# 安装python的pydotplus插件
pip install pydotplus

</code></pre>

<h2 id="toc_35">使用方式</h2>

<p><strong>方式一:将模型输出dot文件,然后使用graphviz的命令将dot文件转换为pdf格式的文件</strong></p>

<pre><code>from sklearn import tree
with open(&#39;iris.dot&#39;,&#39;w&#39;) as f:
    f = tree.export_graphviz(model,out_file=f)


# 命令行执行dot命令 dot -Tpdf iris.dot -o iris.pdf
</code></pre>

<p><strong>方式二:直接使用pydotplus插件直接生成pdf文件进行保存</strong></p>

<pre><code>from sklearn import tree
import pydotplus
dot_data = tree.export_graphviz(model,out_file=None)
graph=pydotplus.graph_from_dot_data(dot_data)
graph.write_pdf(&quot;iris2.pdf&quot;)
# graph.write_png(&quot;iris3.png&quot;)
</code></pre>

<p><strong>方式三:使用Image对象直接显示pydotplus生成的图片</strong></p>

<pre><code>from sklearn import tree
from IPython.display import Image
import pydotplus

dot_data=tree.export_graphviz(model,put_file=None,
    feature_names=[&#39;sepal length&#39;,&#39;sepal width&#39;,&#39;petal length&#39;,&#39;petal width&#39;],
    class_names=[&#39;Iris-setosa&#39;,&#39;Iris-versicolor&#39;,&#39;Iris-virgincia&#39;],
    filled=True,rounded=True,
    special_characters=True)
    
graph=pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png)
</code></pre>

<h1 id="toc_36">参考</h1>

<p>[1]: </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[逻辑回归]]></title>
    <link href="http://dmlcoding.com/15198753668603.html"/>
    <updated>2018-03-01T11:36:06+08:00</updated>
    <id>http://dmlcoding.com/15198753668603.html</id>
    <content type="html"><![CDATA[
<p>不知道什么是逻辑回归,但是也许看完接下来的文章,你会有个大概的印象吧</p>

<h1 id="toc_0">简单介绍Logistic回归</h1>

<h2 id="toc_1">Logistic回归用到的知识点</h2>

<ul>
<li>Sigmoid函数和Logistic回归分类器</li>
<li>最优化理论初步</li>
<li>梯度下降最优化算法</li>
<li>数据中的缺失项处理</li>
</ul>

<span id="more"></span><!-- more -->

<h2 id="toc_2">Logistic回归的一般过程</h2>

<ul>
<li>1.收集数据:采用任意方法收集数据</li>
<li>2.准备数据:由于需要进行距离计算,因此要求数据类型为数值型.另外,结构化数据格式则最佳.</li>
<li>3.分析数据:采用任意方法对数据进行分析.</li>
<li>4.训练算法:大部分时间将用于训练,训练的目的是为了找到最佳的分类回归系数.</li>
<li>5.使用算法:首先,我们需要一些输入数据,并将其转换成对应的结构化数值;接着,基于训练好的回归系数就可以对这些数值进行简单的回归计算,判定他们属于哪个类别;在这之后,我们就可以在输出的类别上做一些其他分析工作.</li>
</ul>

<h1 id="toc_3">基于Logistic回归和Sigmoid函数的分类</h1>

<h2 id="toc_4">Logistic回归</h2>

<ul>
<li>优点

<ul>
<li>计算代价不高</li>
<li>易于理解和实现</li>
</ul></li>
<li>缺点

<ul>
<li>容易欠拟合</li>
<li>分类精度可能不高</li>
</ul></li>
<li>适用类型

<ul>
<li>数值型(数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析))</li>
<li>标称型数据(标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类))</li>
</ul></li>
</ul>

<p>基本公式:<br/>
Sigmoid函数具体的计算公式</p>

<p>\[p=h_{\theta}(x)=g(\theta^Tx)=\dfrac{1}{1+e^{-\theta^Tx}}\]<br/>
\[g(z)=\dfrac{1}{1+e^{-z}}\]</p>

<p><img src="media/15198753668603/15253390268591.jpg" alt=""/></p>

<p>\[<br/>
\begin{aligned}<br/>
g^{&#39;}(X)&amp; =\left(\dfrac{1}{1+e^{-z}}\right)^{&#39;} \\\<br/>
&amp; = \dfrac{e^{-z}}{(1+e^{-z})^2} \\\<br/>
&amp; = \dfrac{1}{1+e^{-z}}\cdot \dfrac{e^{-z}}{1+e{-z}} \\\<br/>
&amp; = \dfrac{1}{1+e^{-z}}\cdot \left(1-\dfrac{1}{1+e^{-z}}\right) \\\<br/>
&amp; = g(z)\cdot (1-g(z))<br/>
\end{aligned}<br/>
\]</p>

<h2 id="toc_5">logistic 回归及似然函数</h2>

<p>假设<br/>
\[<br/>
\begin{aligned}<br/>
P(y=1|x;\theta)&amp; =h_{\theta}(x) \\\<br/>
P(y=0|x;\theta)&amp; =1-h_{\theta}(x) \\\<br/>
P(y|x;\theta)&amp; =(h_{\theta}(x))^y(1-h_{\theta}(x))^{(1-y)}<br/>
\end{aligned}<br/>
\]</p>

<p>似然函数:<br/>
\[<br/>
\begin{aligned}<br/>
L(\theta) &amp; =p(\vec{y}|X;\theta) \\\<br/>
&amp; =\prod_{i=1}^m p(y^{(i)}|x^{(i)};\theta) \\\<br/>
&amp; = \prod_{i=1}^m (h_{\theta}(x^{(i)}))^{y^{(i)}}(1-h_{\theta}(x^{(i)}))^{(1-y^{(i)})}<br/>
\end{aligned}<br/>
\]</p>

<p>对数似然函数:<br/>
\[<br/>
\begin{aligned}<br/>
\ell(\theta) &amp; =\log L(\theta) \\\<br/>
&amp; = \sum_{i=1}^m\left(y^{(i)}\log h_{\theta}(x^{(i)})+(1-y^{(i)})\log (1-h_{\theta}(x^{(i)}))\right)<br/>
\end{aligned}<br/>
\]</p>

<p>最大似然/极大似然函数的随机梯度</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[回归算法]]></title>
    <link href="http://dmlcoding.com/15248143200628.html"/>
    <updated>2018-04-27T15:32:00+08:00</updated>
    <id>http://dmlcoding.com/15248143200628.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">什么是回归算法</h2>

<ol>
<li>回归算法是一种有监督算法;</li>
<li>回归算法是一种比较常用的机器学习算法,用于建立解释变量(自变量X)和观测值(因变量Y)之间的关系;</li>
<li>从机器学习的角度来讲,用于构建一个算法模型(函数)来做属性(X)与标签(Y)之间的映射关系,在算法的学习过程中,试图寻找一个函数h:使得\(R^d\to R\)使得参数之间的关系拟合性最好;</li>
<li>回归算法中,算法(函数)的最终结果是一个<strong>连续</strong>的数据值,输入值(属性值)是一个d维度的属性/数值向量;</li>
<li>因此,回归算法是用于预测连续型数值输出的算法.</li>
</ol>

<h2 id="toc_1">线性回归</h2>

<span id="more"></span><!-- more -->

<h3 id="toc_2">单变量线性回归</h3>

<p>\[h_{\theta}=\theta_0+ \theta_1x\]</p>

<p>因为只含有一个特征/输入变量,因此这样的问题叫做单变量线性回归问题.</p>

<h3 id="toc_3">代价函数(Cost Function)</h3>

<p>我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度,模型所预测的值与训练集中实际值之间的差距就是建模误差(modeling error).</p>

<p>我们的目标便是选择出可以使得<strong>建模误差的平方和</strong>能够<strong>最小</strong>的模型参数.即使得代价函数最小.<br/>
\[J(\theta_0,\theta_1)=\dfrac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\]</p>

<h3 id="toc_4">多变量线性回归</h3>

<h2 id="toc_5">公式推导</h2>

<p>\[\begin{align}<br/>
y^{(i)}&amp; =\theta ^Tx^{(i)}+\epsilon^{(i)}\\\<br/>
p(\epsilon^{(i)})&amp; =\frac{1}{\sqrt{2\pi}\sigma}e^{\left(-\dfrac{(\epsilon^{(i)})^2}{2\sigma^2}\right)} \\\<br/>
p(y^{(i)}|x^{(i)};\theta)&amp; =\frac{1}{\sqrt{2\pi}\sigma}e^{\left(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)} \\\<br/>
L(\theta)&amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta)\\\<br/>
&amp; = \prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}e^{\left(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)}<br/>
\end{align}\]</p>

<p>最大似然,要使这个方程的结果最大</p>

<p>对数似然,目标函数及最小二乘法</p>

<p>\[<br/>
\begin{align}<br/>
\ell(\theta)&amp; =\log L(\theta) \\\<br/>
&amp; = \log\prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}e^{\Big(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\Big)} \\\<br/>
&amp; = \sum_{i=1}^m\log\frac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^m \log e^{\Big(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\Big)} \\\<br/>
&amp; = m\log\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{\sigma^2}\cdot\frac{1}{2}\sum_{i=1}^m\Big(y^{(i)}-\theta^Tx{(i)}\Big)^2<br/>
\end{align}<br/>
\]</p>

<p>那么就得让这个式子的结果最小</p>

<p>\[loss(y_j,\hat{y_j})=J(\theta)=\frac{1}{2}\sum_{i=1}^{m}\left(h_\theta(x^{(i)-y^{(i)}})\right)^2\]</p>

<p>我们的目标是最小化损失函数.</p>

<p>\[J(\theta)=\cfrac{1}{2}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2=\cfrac{1}{2}(X\theta-Y)^T(X\theta-Y) \to \min \limits_{\theta}J(\theta)\]</p>

<p>既然是求最小值,那么肯定是通过求导来计算.对这个损失函数进行求导运算.</p>

<p>\[<br/>
\begin{aligned}<br/>
\nabla J(\theta)&amp; =\nabla_{\theta}\Big(\cfrac{1}{2}(X\theta-Y)^T(X\theta-Y)\Big) \\\<br/>
&amp; = \nabla_{\theta}\Big(\cfrac{1}{2}(\theta^TX^T-Y^T)(X\theta-Y)\Big) \\\<br/>
&amp; = \nabla_{\theta}\Big(\cfrac{1}{2}(\theta^TX^TX\theta-\theta^TX^TY-Y^TX\theta+Y^TY)\Big) \\\<br/>
&amp; = \cfrac{1}{2}\Big(2X^TX\theta-X^T-(Y^TX)^T\Big) \\\<br/>
&amp; = X^TX\theta-X^TY<br/>
\end{aligned}<br/>
\]</p>

<p>\[\theta=(X^TX)^{-1}X^TY\]</p>

<h2 id="toc_6">简述原理</h2>

<h2 id="toc_7">\(\theta\)值推导过程以及求解</h2>

<h3 id="toc_8">构造数据</h3>

<!-- more -->

<pre><code class="language-python">import numpy as np
import pandas as pd

# 构造测试数据y=3x1+x2
df=pd.DataFrame({
    &quot;x1&quot;:[1,2,3,4,5,6],
    &quot;x2&quot;:[1,2,1,2,1,2],
    &quot;y&quot;:[3,6,7,10,11,14]
})

</code></pre>

<h3 id="toc_9">抽取x和y</h3>

<pre><code class="language-python"># 抽取x和y
x=df[[&#39;x1&#39;,&#39;x2&#39;]]
# 将y转换成n行1列的列向量
y=df[&#39;y&#39;].values.reshape((-1,1))

</code></pre>

<h3 id="toc_10">求解\(\theta\) 值</h3>

<p><em>根据公式计算\(\theta\)</em>值,推导过程如图所示<br/>
\[\theta=(X^TX)^{-1}X^TY\]</p>

<p><em>numpy</em> api说明:<br/>
+ mat:将ndarray转成matrix<br/>
+ dot:矩阵乘法<br/>
+ T:求矩阵的转置<br/>
+ I:求矩阵的逆</p>

<pre><code class="language-python"># 写出公式,计算theta值

np.dot(np.mat(x.T.dot(x)).I,x.T).dot(y)
</code></pre>

<pre><code>matrix([[ 2.],
        [ 1.]])
</code></pre>

<p>很明显,计算结果正确.两个系数分别是2和1</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[学习机器学习]]></title>
    <link href="http://dmlcoding.com/15263722402424.html"/>
    <updated>2018-05-15T16:17:20+08:00</updated>
    <id>http://dmlcoding.com/15263722402424.html</id>
    <content type="html"><![CDATA[
<p>机器不能代替你学习,代替你成长,终归还得自己踏实学习!</p>

<p>对于下面的基础知识,不管是大学的时候没学好,还是由于时间太长了,导致自己忘记了.都无所谓了.既然打算学习机器学习,那么就不得不花时间去重拾这些知识.</p>

<p>至于如何学,很多说法,我在网上看了很多,比如:<br/>
1. 看视频学习;<br/>
2. 看教程学习;<br/>
3. 边学习边看.</p>

<span id="more"></span><!-- more -->

<p>我个人是先回顾一遍,常用的知识点做到心里有数,用到的时候,知道用的什么知识点,去哪里查.然后在学习的过程中巩固,毕竟不是应试考试,没时间也没精力去抠知识点了.</p>

<p>之前总是想要先把数学之类的都复习好,再开始看机器学习算法的.但是每次翻开高数课本,每次第一章的极限没看完,就看不下去了.</p>

<p>所以,这是我自己的问题,我只能想办法,慢慢尝试,看看如何跳过这个坎.</p>

<p>这也是我目前学习中遇到的问题,我会都记录下来,一来是复习,二是帮助大家.</p>

<p>最后,学习缓慢.磕磕碰碰,在所难免,与诸君共勉!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[python-matplotlib画图中文显示不出来]]></title>
    <link href="http://dmlcoding.com/15242825563762.html"/>
    <updated>2018-04-21T11:49:16+08:00</updated>
    <id>http://dmlcoding.com/15242825563762.html</id>
    <content type="html"><![CDATA[
<pre><code>import matplotlib as mpl
import matplotlib.pyplot as plt

## 设置字符集，防止中文乱码
mpl.rcParams[&#39;font.sans-serif&#39;]=[u&#39;simHei&#39;]
mpl.rcParams[&#39;axes.unicode_minus&#39;]=False
</code></pre>

<span id="more"></span><!-- more -->

<p><img src="media/15242825563762/15242826157154.jpg" alt=""/></p>

<p>已经在代码中设置了字符集,但是却仍然无法正确显示.这是因为系统中没有这个字体</p>

<h1 id="toc_0">解决方案</h1>

<h2 id="toc_1">1. 下载SimHei.ttf字体</h2>

<pre><code>http://www.fontpalace.com/font-details/SimHei/
</code></pre>

<h2 id="toc_2">2. 查看matplotlib的字体存放目录</h2>

<pre><code>/Users/hushiwei/anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data
</code></pre>

<pre><code>total 64
drwxr-xr-x   6 hushiwei  staff    192  1 18 12:03 ./
drwxr-xr-x  86 hushiwei  staff   2752  1 18 12:03 ../
drwxr-xr-x   5 hushiwei  staff    160  1 18 12:03 fonts/
drwxr-xr-x  58 hushiwei  staff   1856  1 18 12:03 images/
-rw-rw-r--   2 hushiwei  staff  31975 10 10  2017 matplotlibrc
drwxr-xr-x  27 hushiwei  staff    864  1 18 12:03 stylelib/
</code></pre>

<h2 id="toc_3">3. 导入字体,删除缓存</h2>

<p>将我们刚刚下载好的字体,<code>SimHei.ttf</code>文件​，放在matplotlib的font目录（./matplotlib/mpl-data/fonts/ttf/）或者系统的font目录下都行(/usr/share/fonts/)</p>

<p>接着:<br/>
​删除/Users/hushiwei/.matplotlib/*目录，重新运行你的画图脚本；此时程序会自动在~/.matplotlib目录下生成fontList.json文件；</p>

<h2 id="toc_4">4. 重启jupyter ,重新执行代码.</h2>

<p>OK,完成....<br/>
<img src="media/15242825563762/15242830696194.jpg" alt=""/></p>

<h1 id="toc_5">总结</h1>

<ol>
<li>需要在代码中引入字符集.</li>
<li>系统中需要有这个字体.</li>
<li>导入字体后,若要生效,需要先删除~/.matplotlib目录,让这个目录中的文件重新生成.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Markdown中用LaTex语法写数学公式]]></title>
    <link href="http://dmlcoding.com/15235878044126.html"/>
    <updated>2018-04-13T10:50:04+08:00</updated>
    <id>http://dmlcoding.com/15235878044126.html</id>
    <content type="html"><![CDATA[
<p><img src="media/15235878044126/15249021210382.jpg" alt=""/></p>

<p>最近在学习机器学习和神经网络的一些知识, 在用Markdown做笔记的时候, 发现公式用到LaTeX十分方便, 写篇文章记录在学习过程中的常用的LaTeX公式和用法, 因为本博客支持MathJax, <code>MathJax</code>是一款运行在浏览器中的开源的数学符号渲染引擎，使用MathJax可以方便的在浏览器中显示数学公式，MathJax可以解析<code>Latex</code>、<code>MathML</code>和<code>ASCIIMathML</code>的标记语言。</p>

<h2 id="toc_0">关键字索引</h2>

<span id="more"></span><!-- more -->

<p><code>\</code> 或者<code>~</code>: 空格</p>

<p><code>\verb +text+</code> : 直接打印不执行任何LATEX命令。这里的+仅是分隔符的一个例子, 除了* 或空格，可以使用任意一个字符。</p>

<p><code>\url{www.baidu.com}</code> : 嵌入超链接, 可在文档中点击访问</p>

<p><code>\emph{text}</code> : 强调的内容</p>

<p><code>\section{...}</code> : 章</p>

<p><code>\subsection{...}</code> : 节</p>

<p><code>\subsubsection{...}</code> : 子节</p>

<p><code>\paragraph{...}</code> : 段落</p>

<p><code>\subparagraph{...}</code> : 子段落</p>

<p>`<code>text&#39;</code> : 单引号</p>

<p><code>text&#39;&#39;</code> : 双引号引起来的text</p>

<p><code>--</code> : 折线</p>

<h2 id="toc_1">基本概念</h2>

<ul>
<li><p>控制序列: 以<code>\</code>开头,参数：<code>必须参数{}</code>和<code>可选参数[]</code></p></li>
<li><p>环境: 以<code>bengin 环境名</code>开始，并以<code>end 环境名</code>结束</p></li>
<li><p>文本模式:如果你想要在公式中排版普通的文本，那么你必须要把这些文本放在<code>\textrm{...}</code> 命令中</p></li>
<li><p>数学模式</p></li>
</ul>

<ol>
<li><p>内嵌模式:公式直接放在文字之间，公式高度一般受文本高度限制: <code>$ latex $</code></p>

<blockquote>
<p>文字\(\sum_{i=0}^{n}i^2\) 文字</p>
</blockquote></li>
<li><p>独立模式:公式另起一行，高度可调整</p>

<blockquote>
<p>文字\[\sum_{i=0}^{n}i^2\]文字</p>
</blockquote></li>
</ol>

<blockquote>
<p>在LaTeX中，花括号是用于分组，即花括号内部文本为一组, 大括号能消除二义性, 一个组即单个字符或者使用{..}包裹起来的内容。</p>
</blockquote>

<h3 id="toc_2">上标与下标</h3>

<ul>
<li><p>上标<code>^{角标}</code>，下标<code>_{角标}</code>, 默认情况下，上下标符号仅仅对下一个组起作用。</p>

<p><code>x_1</code> : \(x_1\) </p>

<p><code>x_1^2</code> : \(x_1^2\) </p>

<p><code>x^{2_1}</code> : \(x^{2_1}\) </p>

<p><code>x_{(22)}^{(n)}</code> : \(x_{(22)}^{(n)}\)</p></li>
</ul>

<h3 id="toc_3">分式</h3>

<ul>
<li><p><code>\frac{分子}{分母}</code></p>

<p><code>\frac ab</code> : \(\frac ab\)</p>

<p><code>\frac{x+y}{2}</code> : \(\frac{x+y}{2}\)</p>

<p><code>\frac{1}{1+\frac{1}{2}}</code> : \(\frac{1}{1+\frac{1}{2}}\)</p></li>
</ul>

<h3 id="toc_4">根式</h3>

<ul>
<li><p>开平方：<code>\sqrt{表达式}</code>；开n次方：<code>\sqrt[n]{表达式}</code></p>

<p><code>\sqrt{2}&lt;\sqrt[3]{3}</code> : \(\sqrt{2}&lt;\sqrt[3]{3}\)</p>

<p><code>\sqrt[4]{\frac xy}</code> ：\(\sqrt[4]{\frac xy} \)</p>

<p><code>\sqrt{1+\sqrt[^p]{1+a^2}}</code> : \(\sqrt{1+\sqrt[^p]{1+a^2}}\)</p></li>
</ul>

<h3 id="toc_5">求和与积分</h3>

<ul>
<li><p>求和<code>\sum</code> ; 求积分<code>\int</code>; 上下限就是<code>上标和下标</code></p>

<p><code>\int_1^\infty</code> ：\(\int_1^\infty\)</p>

<p><code>\int_a^b f(x)dx</code> : \(\int_a^b f(x)dx\)</p>

<p><code>\sum_1^n</code> ：\(\sum_1^n\)</p>

<p><code>\sum_{k=1}^n\frac{1}{k}</code> : \(\sum_{k=1}^n\frac{1}{k}\)</p></li>
</ul>

<h3 id="toc_6">微分</h3>

<p><code>\frac{\partial E_w}{\partial w}</code> : \(\frac{\partial E_w}{\partial w}\)</p>

<p>\[\frac{\partial E_\hat{w}}{\partial \hat{w}}= 2X^T(X\vec{\hat{w}}-\vec{y}) = 0\]</p>

<h3 id="toc_7">加粗</h3>

<p><code>\mathbf{x}_i :</code>\(\mathbf{x}_i\)</p>

<h3 id="toc_8">多重积分</h3>

<ul>
<li>对于多重积分，不要使用<code>\int\int</code>此类的表达，应该使用<code>\iint</code>,<code>\iiint</code>等特殊形式。效果如下：</li>
</ul>

<p>\[<br/>
\begin{array}{cc}<br/>
\mathrm{Bad} &amp; \mathrm{Better} \\\\<br/>
\hline \\\\<br/>
\int\int_S f(x)\,dy\,dx &amp; \iint_S f(x)\,dy\,dx \\\\<br/>
\int\int\int_V f(x)\,dz\,dy\,dx &amp; \iiint_V f(x)\,dz\,dy\,dx<br/>
\end{array}<br/>
\]</p>

<ul>
<li>在微分前应该使用<code>\</code>,来增加些许空间，否则\(\TeX\)会将微分紧凑地排列在一起。如下：</li>
</ul>

<p>\[<br/>
\begin{array}{cc}<br/>
\mathrm{Bad} &amp; \mathrm{Better} \\\\<br/>
\hline \\\\<br/>
\iiint_V f(x)dz dy dx &amp; \iiint_V f(x)\,dz\,dy\,dx<br/>
\end{array}<br/>
\]</p>

<h2 id="toc_9">特殊函数与符号</h2>

<ol>
<li>常见的三角函数，求极限符号可直接使用<code>\+</code>缩写即可
<code>\sin x</code> , <code>\arctan x</code>, <code>\lim_{1\to\infty}</code> : \(\sin x\),\(\arctan x\),\(\lim_{1\to\infty}\)</li>
<li>比较运算符：
<code>\lt \gt \le \ge \neq</code> ： \(\lt \gt \le \ge \neq\)

<ul>
<li>在这些运算符前面加上<code>\not</code>
<code>\not\lt</code> ：\(\not\lt\)</li>
</ul></li>
<li><code>\times \div \pm \mp</code> ：\(\times \div \pm \mp\)
<code>\cdot</code>表示居中的点
<code>x \cdot y</code> : \(x \cdot y\)。</li>
<li>集合关系与运算
<code>\cup \cap \setminus \subset \subseteq \subsetneq \supset \in \notin \emptyset \varnothing</code> ：\(\cup 
\cap \setminus \subset \subseteq \subsetneq \supset \in \notin \emptyset \varnothing\)</li>
<li>排列
<code>{n+1 \choose 2k}</code> : \({n+1 \choose 2k}\) 
<code>\binom{n+1}{2k}</code> : \({n+1 \choose 2k}\)</li>
<li>箭头：
<code>\to \rightarrow \leftarrow \Rightarrow \Leftarrow \mapsto</code> : \(\to \rightarrow \leftarrow \Rightarrow \Leftarrow \mapsto\)</li>
<li>逻辑运算符
<code>\land \lor \lnot \forall \exists \top \bot \vdash \vDash</code> ：\(\land \lor \lnot \forall \exists \top \bot \vdash \vDash\)</li>
<li><code>\star \ast \oplus \circ \bullet</code> ： \(\star \ast \oplus \circ \bullet\)</li>
<li><code>\approx \sim \cong \equiv \prec</code> ： \(\approx \sim \cong \equiv \prec\)</li>
<li><code>\infty \aleph_0</code> : \(\infty  \aleph_0\) 
<code>\nabla \partial</code> : \(\nabla \partial\) \Im \Re \(Im \Re\)</li>
<li>模运算 <code>\pmode</code> 
<code>a\equiv b\pmod n</code> ：\(a\equiv b\pmod n\)</li>
<li><code>\ldots与\cdots</code>区别是dots的位置不同，ldots位置稍低，cdots位置居中
<code>a_1+a_2+\cdots+a_n</code> : \(a_1+a_2+\cdots+a_n\)
<code>a_1, a_2, \ldots ,a_n</code> : \(a_1, a_2, \ldots ,a_n\)。</li>
<li><p>一些希腊字母具有变体形式<br/>
<code>\epsilon \varepsilon</code> : \( \epsilon \varepsilon\)<br/>
<code>\phi \varphi</code> : \(\phi \varphi\)</p></li>
</ol>

<ul>
<li>使用<a href="http://detexify.kirelabs.org/classify.html">Detexify</a>在网页上画出符号，Detexify会给出相似的符号及其代码但是不能保证它给出的符号可以在MathJax中使用，你可以参考<a href="http://docs.mathjax.org/en/latest/tex.html#supported-latex-commands">supported-latex-commands</a>确定MathJax是否支持此符号。</li>
</ul>

<h2 id="toc_10">空格 : 美化公式</h2>

<p>紧贴<code>a!b</code> : \(a!b\)<br/>
  没有空格<code>ab</code> : \(ab\)<br/>
  小空格<code>a\,b</code> : \(a\,b\)<br/>
  中等空格<code>a\;b</code> : \(a\;b\)<br/>
  大空格<code>a\ b</code> : \(a\ b\)<br/>
  quad空格<code>a\quad b</code> : \(a\quad b\)<br/>
  两个quad空格<code>a\qquad b</code> : \(a\qquad b\)</p>

<p>原公式:<code>\int_a^b f(x)\mathrm{d}x</code><br/>
  \(\int_a^b f(x)\mathrm{d}x\)</p>

<p>插入空格:<code>\int_a^b f(x)\qquad \mathrm{d}x</code><br/>
  \(\int_a^b f(x)\qquad \mathrm{d}x\)</p>

<h2 id="toc_11">括号</h2>

<ol>
<li>小括号与方括号：使用原始的<code>( )</code>，<code>[ ]</code>即可，如<code>(2+3)[4+4]</code>：\((2+3)[4+4]\)</li>
<li>大括号：时由于大括号{}被用来分组，使用\lbrace 和\rbrace来表示
<code>\lbrace a*b \rbrace</code> ：\(\lbrace a*b \rbrace\)</li>
<li>尖括号：使用<code>\langle</code> 和 <code>\rangle</code>表示左尖括号和右尖括号
<code>\langle x \rangle</code> ：\(\langle x \rangle\)</li>
<li>上取整：使用<code>\lceil</code> 和 <code>\rceil</code> 表示 
<code>\lceil x \rceil</code> ：\(\lceil x \rceil\)</li>
<li>下取整：使用<code>\lfloor</code> 和 <code>\rfloor</code> 表示
<code>\lfloor x \rfloor</code> ：\(\lfloor x \rfloor\)</li>
<li><p>不可见括号：使用<code>.</code>表示</p></li>
</ol>

<ul>
<li><p>注意 : 原始符号并不会随着公式大小缩放。如，<code>(\frac12)</code> ：\((\frac12)\)。可以使用\left(…\right)来自适应的调整括号大小。<br/>
如1.1和1.2公式，公式1.2中的括号是经过缩放的。</p>

<p><code>\lbrace \sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6} \rbrace \tag{1.1}</code><br/>
\[\lbrace\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}\rbrace\tag{1.1}\]</p>

<p><code>\left \lbrace \sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6} \right\rbrace \tag{1.2}</code><br/>
\[\left \lbrace \sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6} \right\rbrace\tag{1.2}\]</p></li>
<li><p>定界符之前冠以 \left（修饰左定界符）或 \right（修饰右定界符），可以得到自适应缩放的定界符，它们会根据定界符所包围的公式大小自适应缩放</p>

<p><code>\left( \sum_{k=\frac{1}{2}}^{N^2}\frac{1}{k} \right)</code><br/>
\[ \left( \sum_{k=\frac{1}{2}}^{N^2}\frac{1}{k} \right) \]</p></li>
<li><p>诸如()、[]、{}、|等分割公式的称为定界符，前面加上\big，\Big，\bigg，\Bigg可以放大这些符号，我比较喜欢用自适应的放大命令，<code>\left...\right</code>，例如</p>

<p><code>$$\left. \frac{\partial f(x, y)}{\partial x}\right|_{x=0}$$</code></p>

<p>\[\left. \frac{\partial f(x, y)}{\partial x}\right|_{x=0}\]</p></li>
</ul>

<h2 id="toc_12">字体</h2>

<ol>
<li>使用<code>\mathbb</code>或<code>\Bbb</code>显示黑板粗体字，此字体经常用来表示代表实数、整数、有理数、复数的大写字母。
<code>\mathbb{CHNQRZ}</code> : \(\mathbb{CHNQRZ}\)。</li>
<li>使用<code>\mathbf</code>显示黑体字
<code>\mathbf{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$，$\mathbf{abcdefghijklmnopqrstuvwxyz}</code>
\(\mathbf{ABCDEFGHIJKLMNOPQRSTUVWXYZ}\)，\(\mathbf{abcdefghijklmnopqrstuvwxyz}\)</li>
<li>使用<code>\mathtt</code>显示打印机字体
<code>\mathtt{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$，$\mathtt{abcdefghijklmnopqrstuvwxyz}</code>
\(\mathtt{ABCDEFGHIJKLMNOPQRSTUVWXYZ}\)，\(\mathtt{abcdefghijklmnopqrstuvwxyz}\)</li>
<li>使用<code>\mathrm</code>显示罗马字体
<code>\mathrm{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$，$\mathrm{abcdefghijklmnopqrstuvwxyz}</code>
\(\mathrm{ABCDEFGHIJKLMNOPQRSTUVWXYZ}\)，\(\mathrm{abcdefghijklmnopqrstuvwxyz}\)</li>
<li>使用<code>\mathscr</code>显示手写体, 无小写
<code>\mathscr{ABCDEFGHIJKLMNOPQRSTUVWXYZ}, $\mathscr{abcdefghijklmnopqrstuvwxyz}</code>
\(\mathscr{ABCDEFGHIJKLMNOPQRSTUVWXYZ}, \)\mathscr{abcdefghijklmnopqrstuvwxyz}$</li>
<li>使用<code>\mathfrak</code>显示Fraktur字母（一种德国字体）
<code>\mathfrak{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$, $\mathfrak{abcdefghijklmnopqrstuvwxyz}</code>
\(\mathfrak{ABCDEFGHIJKLMNOPQRSTUVWXYZ}\),\(\mathfrak{abcdefghijklmnopqrstuvwxyz}\)</li>
</ol>

<h2 id="toc_13">方程组</h2>

<ul>
<li><p>使用<code>\begin{array} ... \end{array}</code>与<code>\left\{…\right.</code>配合，表示方程组</p></li>
<li><p>使用 <code>\being{aligned} .. \end{aligned}</code></p></li>
</ul>

<p>\[<br/>
\begin{aligned}<br/>
\dot{x} &amp; = \sigma(y-x) \\\<br/>
\dot{y} &amp; = \rho x - y - xz \\\<br/>
\dot{z} &amp; = -\beta z + xy<br/>
\end{aligned}<br/>
\]</p>

<ul>
<li>使用 <code>\being{case} .. \end{case}</code></li>
</ul>

<p>\[<br/>
\begin{cases}<br/>
a_1x+b_1y+c_1z=d_1 \\\<br/>
a_2x+b_2y+c_2z=d_2 \\\<br/>
a_3x+b_3y+c_3z=d_3<br/>
\end{cases}<br/>
\]</p>

<ul>
<li>对齐方程组中的<code>=</code>号, 注意<code>{</code>要转义,&#39;\{&#39;</li>
</ul>

<p>\[ \left\\{<br/>
     \begin{aligned} <br/>
       a_1x+b_1y+c_1z &amp;=d_1+e_1 \\\<br/>
       a_2x+b_2y&amp;=d_2 \\\ <br/>
       a_3x+b_3y+c_3z &amp;=d_3 <br/>
\end{aligned} <br/>
\right. <br/>
\]</p>

<ul>
<li>如果要对齐 <code>=</code>号和<code>项</code>，可以使用<code>\being{array}{列样式} .. \end{array}</code></li>
</ul>

<p>\[<br/>
\left\\{<br/>
\begin{array}{ll}<br/>
a_1x+b_1y+c_1z &amp;=d_1+e_1 \\\<br/>
a_2x+b_2y &amp;=d_2 \\\<br/>
a_3x+b_3y+c_3z &amp;=d_3 <br/>
\end{array} <br/>
\right.<br/>
\]</p>

<h3 id="toc_14">上下文字</h3>

<p>\[ \mathop {\arg min }\limits_{(w,b)}^{top} f(x)\]</p>

<h3 id="toc_15">公式标记与引用</h3>

<ul>
<li>使用<code>\tag{tag}</code>来标记公式，如果想在之后引用该公式，则还需要加上<code>\label{label}</code>在<code>\tag</code>之后，如：</li>
<li>需要<code>\*</code>对标签<code>*</code>进行转义</li>
</ul>

<p>\[<br/>
 a := x^2-y^3 \tag{\*}\label{\*}<br/>
\]</p>

<p>\[<br/>
 a := x^2-y^3 \tag{2.1}\label{2.1}<br/>
\]</p>

<ul>
<li>为了引用公式，可以使用<code>\eqref{rlabel}</code>，如：</li>
</ul>

<p>\[a+y^3 \stackrel{\eqref{\*}}= x^2\]</p>

<p>\[a+y^3 \stackrel{\eqref{2.1}}= x^2\]</p>

<ul>
<li>通过超链接可以跳转到被引用公式位置。</li>
</ul>

<h3 id="toc_16"><strong>矩阵</strong></h3>

<ul>
<li><p>使用<code>$$\begin{matrix}…\end{matrix}$$</code>表示矩阵，矩阵的行之间使用<code>\\\</code>分隔，列之间使用<code>&amp;</code>分隔。</p></li>
<li><p>效果如下 :</p></li>
</ul>

<p>\[<br/>
        \begin{matrix}<br/>
        1 &amp; x &amp; x^2 \\\<br/>
        1 &amp; y &amp; y^2 \\\<br/>
        1 &amp; z &amp; z^2 \\\<br/>
        \end{matrix}<br/>
\]</p>

<ul>
<li><strong>加括号</strong>
如果要对矩阵加括号，可以像上文中提到的一样，使用<code>\left</code>与<code>\right</code>配合表示括号符号。也可以使用特殊的<code>matrix</code>。即替换<code>\begin{matrix}...\end{matrix}</code>中的matrix为<code>pmatrix</code>，<code>bmatrix</code>，<code>Bmatrix</code>，<code>vmatrix</code>,<code>Vmatrix</code></li>
</ul>

<p><code>pmatrix</code> : \(\begin{pmatrix}1&amp;2\\\3&amp;4\\\ \end{pmatrix}\) <br/>
<code>bmatrix</code> : \(\begin{bmatrix}1&amp;2\\\3&amp;4\\\ \end{bmatrix}\) <br/>
<code>Bmatrix</code> : \(\begin{Bmatrix}1&amp;2\\\3&amp;4\\\ \end{Bmatrix}\) <br/>
<code>vmatrix</code> : \(\begin{vmatrix}1&amp;2\\\3&amp;4\\\ \end{vmatrix}\) <br/>
<code>Vmatrix</code> : \(\begin{Vmatrix}1&amp;2\\\3&amp;4\\\ \end{Vmatrix}\) </p>

<ul>
<li><strong>省略元素</strong>  使用<code>\cdots</code> : \(\cdots\) <code>\ddots</code> : \(\ddots\)  <code>\vdots</code> : \(\vdots\)来省略矩阵中的元素</li>
</ul>

<p>\[<br/>
    \begin{pmatrix}<br/>
         1 &amp; a_1 &amp; a_1^2 &amp; \cdots &amp; a_1^n \\\<br/>
         1 &amp; a_2 &amp; a_2^2 &amp; \cdots &amp; a_2^n \\\<br/>
         \vdots  &amp; \vdots&amp; \vdots &amp; \ddots &amp; \vdots \\\<br/>
         1 &amp; a_m &amp; a_m^2 &amp; \cdots &amp; a_m^n <br/>
    \end{pmatrix}<br/>
\]</p>

<h3 id="toc_17"><strong>增广矩阵</strong></h3>

<ul>
<li>增广矩阵需要使用前面的<code>array</code>来实现</li>
</ul>

<p>\[ \left[<br/>
      \begin{array}{cc|c}<br/>
        1&amp;2&amp;3\\\<br/>
        4&amp;5&amp;6<br/>
      \end{array}<br/>
    \right]<br/>
\]</p>

<h3 id="toc_18"><strong>对齐公式</strong></h3>

<ul>
<li>使用形如<code>\begin{align}…\end{align}</code>的格式，使用&amp;来指示需要对齐的位置</li>
</ul>

<p>\[<br/>
    \begin{align}<br/>
    \sqrt{37} &amp; = \sqrt{\frac{73^2-1}{12^2}} \\\<br/>
     &amp; = \sqrt{\frac{73^2}{12^2}\cdot\frac{73^2-1}{73^2}} \\\<br/>
     &amp; = \sqrt{\frac{73^2}{12^2}}\sqrt{\frac{73^2-1}{73^2}} \\\<br/>
     &amp; = \frac{73}{12}\sqrt{1 - \frac{1}{73^2}} \\\<br/>
     &amp; \approx \frac{73}{12}\left(1 - \frac{1}{2\cdot73^2}\right)<br/>
    \end{align}<br/>
\]</p>

<h3 id="toc_19"><strong>分类表达式</strong></h3>

<ul>
<li>定义函数时分情况给出表达式，使用<code>\begin{cases}…\end{cases}</code></li>
<li>使用<code>\\\</code>来分类，使用<code>&amp;</code>指示需要对齐的位置</li>
</ul>

<p>\[<br/>
 f(n) =<br/>
    \begin{cases}<br/>
    n/2,  &amp; \text{if $n$ is even} \\\\[2ex]<br/>
    3n+1, &amp; \text{if $n$ is odd}<br/>
    \end{cases}<br/>
\]</p>

<ul>
<li><code>[4ex]</code>控制分类之间的垂直间隔, 这里要用<code>\\\\</code>转义</li>
</ul>

<h3 id="toc_20"><strong>表格</strong></h3>

<ul>
<li>使用<code>$$\begin{array}{列样式}...\end{array}$$</code>创建表格</li>
<li>列样式使用<code>clr</code>表示居中，左，右对齐</li>
<li>使用<code>|</code>表示一条竖线</li>
<li>使用<code>\\\\</code>分隔行，使用<code>&amp;</code>分隔列</li>
<li>使用<code>\hline</code>在本行前加入一条直线</li>
</ul>

<p>\[<br/>
    \begin{array}{c|lcr}<br/>
    n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\\\<br/>
    \hline<br/>
    1 &amp; 0.24 &amp; 1 &amp; 125 \\\\<br/>
    2 &amp; -1 &amp; 189 &amp; -8 \\\\<br/>
    3 &amp; -20 &amp; 2000 &amp; 1+10i \\\\<br/>
    \end{array}<br/>
\]</p>

<ul>
<li>复杂列表</li>
</ul>

<h3 id="toc_21"><strong>希腊字母</strong></h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>大写</th>
<th>Tex</th>
<th>小写</th>
<th>Tex</th>
</tr>
</thead>

<tbody>
<tr>
<td>alpha</td>
<td>\(A\)</td>
<td>A</td>
<td>\(\alpha\)</td>
<td>\alpha</td>
</tr>
<tr>
<td>beta</td>
<td>\(B\)</td>
<td>B</td>
<td>\(\beta\)</td>
<td>\beta</td>
</tr>
<tr>
<td>gamma</td>
<td>\(\Gamma\)</td>
<td>\Gamma</td>
<td>\(\gamma\)</td>
<td>\gamma</td>
</tr>
<tr>
<td>delta</td>
<td>\(\Delta\)</td>
<td>\Delta</td>
<td>\(\delta\)</td>
<td>\delta</td>
</tr>
<tr>
<td>epsilon</td>
<td>\(E\)</td>
<td>E</td>
<td>\(\epsilon\)</td>
<td>\epsilon</td>
</tr>
<tr>
<td>zeta</td>
<td>\(Z\)</td>
<td>Z</td>
<td>\(\zeta\)</td>
<td>\zeta</td>
</tr>
<tr>
<td>eta</td>
<td>\(H\)</td>
<td>H</td>
<td>\(\eta\)</td>
<td>\eta</td>
</tr>
<tr>
<td>theta</td>
<td>\(\Theta\)</td>
<td>\Theta</td>
<td>\(\theta\)</td>
<td>\theta</td>
</tr>
<tr>
<td>iota</td>
<td>\(I\)</td>
<td>I</td>
<td>\(\iota\)</td>
<td>\iota</td>
</tr>
<tr>
<td>kappa</td>
<td>\(K\)</td>
<td>K</td>
<td>\(\kappa\)</td>
<td>\kappa</td>
</tr>
<tr>
<td>lambda</td>
<td>\(\Lambda\)</td>
<td>\Lambda</td>
<td>\(\lambda\)</td>
<td>\lambda</td>
</tr>
<tr>
<td>mu</td>
<td>\(M\)</td>
<td>M</td>
<td>\(\mu\)</td>
<td>\mu</td>
</tr>
<tr>
<td>nu</td>
<td>\(N\)</td>
<td>N</td>
<td>\(\nu\)</td>
<td>\nu</td>
</tr>
<tr>
<td>xi</td>
<td>\(\Xi\)</td>
<td>\Xi</td>
<td>\(\xi\)</td>
<td>\xi</td>
</tr>
<tr>
<td>omicron</td>
<td>\(O\)</td>
<td>O</td>
<td>\(\omicron\)</td>
<td>\omicron</td>
</tr>
<tr>
<td>pi</td>
<td>\(\Pi\)</td>
<td>\Pi</td>
<td>\(\pi\)</td>
<td>\pi</td>
</tr>
<tr>
<td>rho</td>
<td>\(P\)</td>
<td>P</td>
<td>\(\rho\)</td>
<td>\rho</td>
</tr>
<tr>
<td>sigma</td>
<td>\(\Sigma\)</td>
<td>\Sigma</td>
<td>\(\sigma\)</td>
<td>\sigma</td>
</tr>
<tr>
<td>tau</td>
<td>\(T\)</td>
<td>T</td>
<td>\(\tau\)</td>
<td>\tau</td>
</tr>
<tr>
<td>upsilon</td>
<td>\(\Upsilon\)</td>
<td>\Upsilon</td>
<td>\(\upsilon\)</td>
<td>\upsilon</td>
</tr>
<tr>
<td>phi</td>
<td>\(\Phi\)</td>
<td>\Phi</td>
<td>\(\phi\)</td>
<td>\phi</td>
</tr>
<tr>
<td>chi</td>
<td>\(X\)</td>
<td>X</td>
<td>\(\chi\)</td>
<td>\chi</td>
</tr>
<tr>
<td>psi</td>
<td>\(\Psi\)</td>
<td>\Psi</td>
<td>\(\psi\)</td>
<td>\psi</td>
</tr>
<tr>
<td>omega</td>
<td>\(\Omega \)</td>
<td>\Omega</td>
<td>\(\omega\)</td>
<td>\omega</td>
</tr>
</tbody>
</table>

<h3 id="toc_22"><strong>重音符号</strong></h3>

<ul>
<li><p><code>\hat{A}</code> : \( \hat{A} \)</p></li>
<li><p>单字符<br/>
<code>\hat</code> ：\(\hat x\)</p></li>
<li><p>多字符<br/>
<code>\widehat</code> : \(\widehat {xy}\)</p></li>
</ul>

<p><img src="media/15235878044126/15235930010630.jpg" alt=""/></p>

<h3 id="toc_23"><strong>二元关系</strong></h3>

<ul>
<li><code>a\ll{b}</code> : \( a\ll{b} \)</li>
</ul>

<p><img src="media/15235878044126/15235930296134.jpg" alt=""/></p>

<h3 id="toc_24"><strong>二元运算符</strong></h3>

<ul>
<li><code>\pm</code> : \( \pm \)</li>
</ul>

<p><img src="media/15235878044126/15235930579186.jpg" alt=""/></p>

<h3 id="toc_25"><strong>&quot;大&quot;运算符</strong></h3>

<ul>
<li><code>\sum</code> : \( \sum \)</li>
</ul>

<p><img src="media/15235878044126/15235931068818.jpg" alt=""/></p>

<h3 id="toc_26"><strong>箭头</strong></h3>

<ul>
<li><code>\to</code> : \( \to \)</li>
</ul>

<p><img src="media/15235878044126/15235931161176.jpg" alt=""/></p>

<h3 id="toc_27"><strong>定界符</strong></h3>

<ul>
<li><code>\lbrack</code> : \( \lbrack \)</li>
</ul>

<p><img src="media/15235878044126/15235931287395.jpg" alt=""/></p>

<h3 id="toc_28"><strong>大定界符</strong></h3>

<ul>
<li><code>\lgroup</code> : \( \lgroup \)</li>
</ul>

<p><img src="media/15235878044126/15235931644817.jpg" alt=""/></p>

<h3 id="toc_29"><strong>其他符号</strong></h3>

<ul>
<li><code>\dots</code> : \( \dots \)</li>
</ul>

<p><img src="media/15235878044126/15235931801879.jpg" alt=""/></p>

<h3 id="toc_30"><strong>注意事项</strong></h3>

<ul>
<li><p>不要在再指数或者积分中使用 <code>\frac</code></p></li>
<li><p>在指数或者积分表达式中使用<code>\frac</code>会使表达式看起来不清晰，应该使用一个水平的<code>/</code>来代替</p></li>
<li><p>使用 \mid 代替 | 作为分隔符<br/>
符号|作为分隔符时有排版空间大小的问题，应该使用\mid代替。效果如下：</p></li>
</ul>

<p>\[<br/>
\begin{array}<br/>
\mathrm{Bad} &amp; \mathrm{Better} \\\<br/>
\hline \\\<br/>
{x|x^2\in\Bbb Z} &amp; {x\mid x^2\in\Bbb Z} \\\<br/>
\end{array}<br/>
\]</p>

<ul>
<li>连分数
书写连分数表达式时，请使用<code>\cfrac</code>代替<code>\frac</code>或者<code>\over</code>,两者效果对比如下：</li>
</ul>

<p>\[<br/>
x = a_0 + \cfrac{1^2}{a_1<br/>
          \+ \cfrac{2^2}{a_2<br/>
          \+ \cfrac{3^2}{a_3 + \cfrac{4^4}{a_4 + \cdots}}}} \tag{\cfrac}<br/>
\]<br/>
\[<br/>
x = a_0 + \frac{1^2}{a_1<br/>
         \+ \frac{2^2}{a_2<br/>
          \+ \frac{3^2}{a_3 + \frac{4^4}{a_4 + \cdots}}}} \tag{\frac}<br/>
\]</p>

<blockquote>
<p><strong>转义</strong><br/>
  一些MathJax使用的特殊字符，可以使用<code>\</code>或者<code>\\</code>转义为原来的含义。如<code>\$</code>表示<code>$</code>，<code>\\_</code>表示下划线。<br/>
- 注意: 换行和方程组的开始<code>{</code>等, 常常需要转义, 用<code>\</code>或者<code>\\</code>或者<code>\\\</code>或者<code>\\\\</code><br/>
<a href="https://github.com/Simshang/blog/blob/master/source/_posts/Demo-LaTeX.md">Markdown文件</a></p>
</blockquote>

<h3 id="toc_31">转载参考:</h3>

<ul>
<li><a href="http://simtalk.cn/2015/12/21/Demo-LaTeX/">http://simtalk.cn/2015/12/21/Demo-LaTeX/</a></li>
<li><a href="https://www.zybuluo.com/codeep/note/163962">https://www.zybuluo.com/codeep/note/163962</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何优雅的设计数据分层]]></title>
    <link href="http://dmlcoding.com/15228352753621.html"/>
    <updated>2018-04-04T17:47:55+08:00</updated>
    <id>http://dmlcoding.com/15228352753621.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">理论</h1>

<p><img src="media/15228352753621/15231557165878.jpg" alt=""/></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">1.ODS 全称是 Operational Data Store，操作数据存储</h2>

<p>“面向主题的”，数据运营层，也叫ODS层，是最接近数据源中数据的一层，数据源中的数据，经过抽取、洗净、传输，也就说传说中的 ETL 之后，装入本层。本层的数据，总体上大多是按照源头业务系统的分类方式而分类的。</p>

<p>但是，这一层面的数据却不等同于原始数据。在源数据装入这一层时，要进行诸如去噪（例如有一条数据中人的年龄是 300 岁，这种属于异常数据，就需要提前做一些处理）、去重（例如在个人资料表中，同一 ID 却有两条重复数据，在接入的时候需要做一步去重）、字段命名规范等一系列操作。</p>

<h2 id="toc_2">2.数据仓库层(DW)，是数据仓库的主体</h2>

<p>在这里，从 ODS 层中获得的数据按照主题建立各种数据模型。这一层和维度建模会有比较深的联系.</p>

<h2 id="toc_3">3.数据产品层（APP），这一层是提供为数据产品使用的结果数据</h2>

<p>在这里，主要是提供给数据产品和数据分析使用的数据，一般会存放在 ES、Mysql 等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。<br/>
比如我们经常说的报表数据，或者说那种大宽表，一般就放在这里</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark-Metrics 实战]]></title>
    <link href="http://dmlcoding.com/15224029526508.html"/>
    <updated>2018-03-30T17:42:32+08:00</updated>
    <id>http://dmlcoding.com/15224029526508.html</id>
    <content type="html"><![CDATA[
<p><a href="http://metrics.dropwizard.io/3.1.0/getting-started/">http://metrics.dropwizard.io/3.1.0/getting-started/</a><br/>
<a href="http://metrics.dropwizard.io/3.1.0/manual/core/">http://metrics.dropwizard.io/3.1.0/manual/core/</a><br/>
<a href="http://wuchong.me/blog/2015/08/01/getting-started-with-metrics/">http://wuchong.me/blog/2015/08/01/getting-started-with-metrics/</a></p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">使用</h2>

<p>The –files flag will cause /path/to/metrics.properties to be sent to every executor,<br/>
and spark.metrics.conf=metrics.properties will tell all executors to load that file<br/>
when initializing their respective MetricsSystems.</p>

<p>直接添加到命令行后</p>

<pre><code>--files=/yourPath/metrics.properties 
--conf spark.metrics.conf=metrics.properties

</code></pre>

<h2 id="toc_1">小示例</h2>

<p>新建<code>metrics.properties</code>文件,内容如下</p>

<pre><code>
driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource
executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource

*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink
*.sink.console.period=10
*.sink.console.unit=seconds
</code></pre>

<p>全是driver端的信息</p>

<p><img src="media/15224029526508/15224033134708.jpg" alt=""/></p>

<h3 id="toc_2">jmx-sink</h3>

<pre><code>master.source.jvm.class=org.apache.spark.metrics.source.JvmSource
worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource
driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource
executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource
*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink
</code></pre>

<p>spark on yarn 查看 </p>

<p><a href="http://u007:8089/proxy/application_1509616075703_478985/metrics/json">http://u007:8089/proxy/application_1509616075703_478985/metrics/json</a></p>

<h2 id="toc_3">总结</h2>

<p>source里面定义从哪些实例来监控</p>

<p>sink指定你要输出到哪里</p>

<p>刚才这个例子里面,就是sink输出到console</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark Metrics分析]]></title>
    <link href="http://dmlcoding.com/15223141973169.html"/>
    <updated>2018-03-29T17:03:17+08:00</updated>
    <id>http://dmlcoding.com/15223141973169.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">MetricsSystem类注释翻译</h2>

<p><img src="media/15223141973169/15223151043399.jpg" alt=""/></p>

<span id="more"></span><!-- more -->

<p>Spark Metrics System 结合源代码由特定的&quot;实例&quot;创建.<br/>
Sink,定期的拉取source中的度量数据(metrics data)到目标sink中.</p>

<p>&quot;实例&quot;指定&quot;谁&quot;(角色)使用metrics system.在spark中有几个角色,比如master,worker,executor,client driver.这些角色会创建度量系统进行监控.<br/>
所以实例代表这些角色.目前在spark中,已经实现了几个实例:master,worker,executor,driver,application.</p>

<p>&quot;Source&quot;指定&quot;从哪里&quot;(来源)去收集指标数据.在度量系统中,这存在两种来源:<br/>
1.Spark内部源,如MasterSource,WorkerSource等.它们将收集Spark组件的内部状态,这些源与实例相关,并将在创建特定度量标准系统后添加.<br/>
2.通用源,比如JvmSource,这些将收集低级别的状态,由配置进行配置并通过反射加载.</p>

<p>&quot;Sink&quot;指定将Metrics data 输出到哪里(目的地).多个sinks可以共存并且metrics可以都flush到这些sinks中.</p>

<p>Metrics配置格式如下所示</p>

<pre><code>[instance].[sink|source].[name].[options] = xxxx
</code></pre>

<p>[instance]可以是&quot;master&quot;,&quot;worker&quot;,&quot;executor&quot;,&quot;driver&quot;,&quot;applications&quot;这意味着只有指定的实例才具有这个属性.可以用&quot;*&quot;来替换实例名,这意味着所有的这些实例将拥有此属性.</p>

<p>[sink|source]表示此属性是属于source还是sink.这个字段只能是source或者sink.</p>

<p>[name] 指定source或者sink的名字.如果它是自定义的.</p>

<p>[options] 代表这个source或者sink的具体属性</p>

<h2 id="toc_1">Metrics系统</h2>

<p>Spark拥有一个基于Coda Hale Metrics Library的可配置Metrics系统,这个Metrics系统通过配置文件进行配置。</p>

<p>Spark的Metrics系统允许用户把Spark metrics信息报告到各种各样的sink包含HTTP和 JMX、CSV文件。</p>

<p>Spark的metrics系统解耦到每个Spark组件的实例中。每个实例里，你可以配置一组sink（metrics被报告到的地方）。</p>

<p>注：Coda Hale Metrics使用的Yammer.com开发的Metrics框架，官方网址是<a href="https://github.com/dropwizard/metrics">https://github.com/dropwizard/metrics</a> ，相关文档可在<a href="https://dropwizard.github.io/metrics">https://dropwizard.github.io/metrics</a> 查看。</p>

<h2 id="toc_2">配置文件</h2>

<p>默认的配置文件为“$SPARK_HOME/conf/metrics.properties”，Spark启动时候会自动加载它。</p>

<p>如果想修改配置文件位置，可以使用java的运行时属性<code>-Dspark.metrics.conf=xxx</code>进行修改。。</p>

<h2 id="toc_3">Spark的Metrics系统支持的实例：</h2>

<ul>
<li><p>master：Spark standalone模式的 master进程。</p></li>
<li><p>applications：master进程里的一个组件，为各种应用作汇报.</p></li>
<li><p>worker：Spark standalone模式的一个worker进程。</p></li>
<li><p>executor：一个Spark executor.</p></li>
<li><p>driver：Spark driver进程(该进程指创建SparkContext的那个).</p></li>
</ul>

<h2 id="toc_4">Spark的Metrics系统支持的Sink：</h2>

<p>　　Sink指定metrics信息发送到哪，每个instance可以设置一个或多个Sink。</p>

<p>　　Sink源码位于包org.apache.spark.metrics.sink中。</p>

<h3 id="toc_5">ConsoleSink</h3>

<p>　　记录Metrics信息到Console中。</p>

<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>class</td>
<td>org.apache.spark.metrics.sink.ConsoleSink</td>
<td>Sink类</td>
</tr>
<tr>
<td>period</td>
<td>10</td>
<td>轮询间隔</td>
</tr>
<tr>
<td>unit</td>
<td>seconds</td>
<td>轮询间隔的单位</td>
</tr>
</tbody>
</table>

<h3 id="toc_6">CSVSink</h3>

<p>　　定期的把Metrics信息导出到CSV文件中。</p>

<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>class</td>
<td>org.apache.spark.metrics.sink.CsvSink</td>
<td>Sink类</td>
</tr>
<tr>
<td>period</td>
<td>10</td>
<td>轮询间隔</td>
</tr>
<tr>
<td>unit</td>
<td>seconds</td>
<td>轮询间隔的单位</td>
</tr>
<tr>
<td>directory</td>
<td>/tmp</td>
<td>CSV文件存储的位置</td>
</tr>
</tbody>
</table>

<h3 id="toc_7">JmxSink</h3>

<p>可以通过JMX方式访问Mertics信息</p>

<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>class</td>
<td>org.apache.spark.metrics.sink.JmxSink</td>
<td>Sink类</td>
</tr>
</tbody>
</table>

<h3 id="toc_8">MetricsServlet</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>class</td>
<td>org.apache.spark.metrics.sink.MetricsServlet</td>
<td>Sink类</td>
</tr>
<tr>
<td>path</td>
<td>VARIES*</td>
<td>Path prefix from the web server root</td>
</tr>
<tr>
<td>sample</td>
<td>false</td>
<td>Whether to show entire set of samples for histograms (&#39;false&#39; or &#39;true&#39;) ｜</td>
</tr>
</tbody>
</table>

<p>　　除master之外所有实例的默认路径为“/metrics/json”。</p>

<p>　　master有两个路径: “/metrics/aplications/json” App的信息、 “/metrics/master/json” Master的信息</p>

<h3 id="toc_9">GraphiteSink</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>class</td>
<td>org.apache.spark.metrics.sink.GraphiteSink</td>
<td>Sink类</td>
</tr>
<tr>
<td>host</td>
<td>NONE</td>
<td>Graphite服务器主机名</td>
</tr>
<tr>
<td>port</td>
<td>NONE</td>
<td>Graphite服务器端口</td>
</tr>
<tr>
<td>period</td>
<td>10</td>
<td>轮询间隔</td>
</tr>
<tr>
<td>unit</td>
<td>seconds</td>
<td>轮询间隔的单位</td>
</tr>
<tr>
<td>prefix</td>
<td>EMPTY STRING</td>
<td>Prefix to prepend to metric name</td>
</tr>
</tbody>
</table>

<h3 id="toc_10">GangliaSink</h3>

<p>由于Licene限制，默认没有放到默认的build里面。需要自己打包</p>

<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>class</td>
<td>org.apache.spark.metrics.sink.GangliaSink</td>
<td>Sink类</td>
</tr>
<tr>
<td>host</td>
<td>NONE</td>
<td>Ganglia 服务器的主机名或multicast group</td>
</tr>
<tr>
<td>port</td>
<td>NONE</td>
<td>Ganglia服务器的端口</td>
</tr>
<tr>
<td>period</td>
<td>10</td>
<td>轮询间隔</td>
</tr>
<tr>
<td>unit</td>
<td>seconds</td>
<td>轮询间隔的单位</td>
</tr>
<tr>
<td>ttl</td>
<td>1</td>
<td>TTL of messages sent by Ganglia</td>
</tr>
<tr>
<td>mode</td>
<td>multicast</td>
<td>Ganglia网络模式(&#39;unicast&#39; or &#39;multicast&#39;)</td>
</tr>
</tbody>
</table>

<h2 id="toc_11">source：</h2>

<p>第一种为Spark内部source，MasterSource、WorkerSource等，它们会接收Spark组件的内部状态；<br/>
　　第二种为通用source，如：JvmSource，它收集低级别的状态</p>

<h2 id="toc_12">示例</h2>

<h3 id="toc_13">通过类名为所有实例开启ConsoleSink</h3>

<pre><code>*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink

ConsoleSink的轮询周期 *.sink.console.period=10

*.sink.console.unit=seconds

**Master实例重置轮询周期**

master.sink.console.period=15

master.sink.console.unit=seconds
</code></pre>

<h3 id="toc_14">通过类名为所有实例开启JmxSink</h3>

<pre><code>*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink
</code></pre>

<h3 id="toc_15">为所有实例开启CsvSink</h3>

<pre><code>*.sink.csv.class=org.apache.spark.metrics.sink.CsvSink
</code></pre>

<p><strong>CsvSink的轮询周期</strong></p>

<pre><code>*.sink.csv.period=1

*.sink.csv.unit=minutes
</code></pre>

<p>Polling directory for CsvSink *.sink.csv.directory=/tmp/</p>

<p><strong>Worker实例重置轮询周期</strong></p>

<pre><code>worker.sink.csv.period=10

worker.sink.csv.unit=minutes
</code></pre>

<h3 id="toc_16">为master和worker、driver、executor开启jvm source</h3>

<pre><code>
master.source.jvm.class=org.apache.spark.metrics.source.JvmSource

worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource

driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource

executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource
</code></pre>

<h2 id="toc_17">参考文档：</h2>

<pre><code>${SPARK_HOME}/conf/metrics.properties.template
http://spark.apache.org/docs/latest/monitoring.html
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop RPC运行机制]]></title>
    <link href="http://dmlcoding.com/15222053353935.html"/>
    <updated>2018-03-28T10:48:55+08:00</updated>
    <id>http://dmlcoding.com/15222053353935.html</id>
    <content type="html"><![CDATA[
<p>RPC是一种通过网络从远程计算机上请求服务的机制，封装了具体实现，使用户不需要了解底层网络技术。目前存在许多开源RPC框架，比较有名的有Thrift、Protocol Buffers和Avro。Hadoop RPC与他们一样，均由两部分组成：对象序列化和远程过程调用</p>

<p>什么是远程过程调用?</p>

<span id="more"></span><!-- more -->

<p>首先从字面上解释，“过程”在Java中指的就是对象中的方法，“远程”是指不同机器上的进程（狭义），或者不同的进程（广义）（为了简单，下文不对这种情况进行说明）。因此，RPC就是允许程序调用其他机器上的对象方法。</p>

<p>RPC是属于典型的C/S结构，提供服务的一方称为server，请求服务的一方称为client。server端提供对象方法供client端调用，被调用的对象方法的执行发生在server端。</p>

<p>上面这样解释其实已经很明白了,为了更直观的理解.<br/>
那么就不废话了,直接上一个例子,用代码说话.</p>

<h1 id="toc_0">RPC 实例</h1>

<blockquote>
<p>简单来说,就是在client调用远程服务器里面的方法就像在本地调用自己的方法一样.</p>
</blockquote>

<p>我们的实例用hadoop rpc框架,那么我们需要引入对应的依赖</p>

<pre><code>    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
        &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
        &lt;version&gt;2.7.1&lt;/version&gt;
    &lt;/dependency&gt;
</code></pre>

<p>Hadoop RPC主要由三个大类组成，即RPC、Client和Server，分别对应对外编程接口、客户端实现和服务器实现</p>

<p>代码分为两部分</p>

<ul>
<li>服务端的逻辑代码(server-rpc)</li>
<li>客户端调用服务端的逻辑代码(client-rpc)</li>
</ul>

<p><img src="media/15222053353935/15222165453483.jpg" alt=""/></p>

<h3 id="toc_1">服务端server-rpc</h3>

<p>RPCLearningServiceInterface <br/>
定义一个接口,我们想要客户端调用的方法</p>

<pre><code>/**
 * Created by hushiwei on 2018/3/28.
 * desc : RPC协议是client端和server端之间的通信接口，它定义了server端对外提供的服务接口。
 */
public interface RPCLearningServiceInterface {

    // 协议版本号,不同版本号的client和sever之间不能相互通信
    static final long versionID = 1L;

    // 登录方法
    String loging(String name);

    // 乘法
    String multip(int a, int b);
}


</code></pre>

<p>RPCLearningServiceImpl</p>

<p>接口的具体实现类</p>

<pre><code>/**
 * Created by hushiwei on 2018/3/28.
 * desc :Hadoop RPC协议通常是一个Java接口，定义了server端对外提供的服务接口，需要在server端进行实现
 *
 * server端的协议实现中不需要关注Socket通信
 *
 */
public class RPCLearningServiceImpl implements RPCLearningServiceInterface {
    @Override
    public String loging(String name) {
        System.out.println(&quot;Exec Login function ...&quot;);
        return &quot;Hello, &quot; + name + &quot;. Welcome you!&quot;;
    }

    @Override
    public String multip(int a, int b) {
        System.out.println(&quot;Prepare to exec multip function in server ....&quot;);
        return a + &quot; * &quot; + b + &quot; = &quot; + a * b;
    }
}

</code></pre>

<p>RpcLearningServer</p>

<p>server-rpc的启动类</p>

<pre><code>
/**
 * Created by hushiwei on 2018/3/28.
 * desc :
 *
 * java -classpath MapReduce-1.0-SNAPSHOT-jar-with-dependencies.jar com.hushiwei.mr.rpc.rpcserver.RpcLearningServer
 */
public class RpcLearningServer {
    public static void main(String[] args) throws IOException {

        // 创建RPC.Builder实例builder,用于构造RPC server
        RPC.Builder builder = new RPC.Builder(new Configuration());

        // 向builder传递一些必要的参数,如主机,端口号,真实业务逻辑实例,协议接口
        builder.setBindAddress(&quot;localhost&quot;).setPort(45666)
                .setInstance(new RPCLearningServiceImpl())
                .setProtocol(RPCLearningServiceInterface.class);

        // 构造rpc server
        RPC.Server server = builder.build();

        // 启动server
        server.start();

    }
}

</code></pre>

<h3 id="toc_2">客户端client-rpc</h3>

<p>ClientController</p>

<p>客户端的代码里面调用了服务端提供的api</p>

<pre><code>/**
 * Created by hushiwei on 2018/3/28.
 * desc : ClientController is a RPC client
 */
public class ClientController {
    public static void main(String[] args) throws IOException {

        // 通过rpc拿到loginServiceinterface的代理对象
        RPCLearningServiceInterface service = RPC.getProxy(RPCLearningServiceInterface.class, 1L, new InetSocketAddress(&quot;localhost&quot;, 45666), new Configuration());

        // 像本地调用一样,就可以调用服务端的方法
        String result = service.loging(&quot;Hushiwei&quot;);
        System.out.println(&quot;rpc client result: &quot; + result);

        String res = service.multip(6, 8);
        System.out.println(res);


        // 关闭连接
        RPC.stopProxy(service);
    }
}


</code></pre>

<h3 id="toc_3">本地执行</h3>

<ul>
<li>为了方便,我在本机进行测试,服务器地址写的localhost</li>
<li>我在idea中进行开发的,直接run起来</li>
</ul>

<p>运行<code>RpcLearningServer</code>类,启动rpc服务<br/>
<img src="media/15222053353935/15222166749600.jpg" alt=""/></p>

<p>运行<code>ClientController</code>类,启动client,进行远程调用<br/>
<img src="media/15222053353935/15222167326547.jpg" alt=""/></p>

<p>此时,看服务端的输出<br/>
<img src="media/15222053353935/15222167785896.jpg" alt=""/></p>

<p>这个也说明了,远程调用过程是在服务端执行的.</p>

<h3 id="toc_4">远程执行</h3>

<p>刚刚在本地执行的,为了更说明问题.我把服务器地址从<code>localhost</code>改成服务器的主机名<code>u006</code>,然后代码编译打包,上传到服务器上.<br/>
在远程服务器上启动rpc-server.然后再本地执行客户端的代码.<br/>
这样更能清楚的明白rpc的运行过程了</p>

<pre><code>java -classpath MapReduce-1.0-SNAPSHOT-jar-with-dependencies.jar com.hushiwei.mr.rpc.rpcserver.RpcLearningServer
</code></pre>

<p><img src="media/15222053353935/15222171711365.jpg" alt=""/></p>

<p>在服务器上启动了rpc-server,现在客户端还没启动,服务器上也没有任何输出.</p>

<p>接着在本地执行客户端代码<br/>
<img src="media/15222053353935/15222172448137.jpg" alt=""/></p>

<p>紧跟着,服务器上也有相应的输出了.<br/>
<img src="media/15222053353935/15222172751812.jpg" alt=""/></p>

<p>补充:<br/>
在服务器上启动rpcserver后,可以用<code>jps -m</code>查看这个服务器的启动情况</p>

<pre><code>[hadoop@U006 ~]$ jps -m
30432 Jps -m
6979 RpcLearningServer
</code></pre>

<p>或者查看代码里面用的端口是否被占用中</p>

<pre><code>[hadoop@U006 ~]$ netstat -natp | grep 45666
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 ::ffff:10.10.25.13:45666    :::*                        LISTEN      6979/java
</code></pre>

<p>是不是很熟悉,我们曾经安装hadoop后,用<code>jps -m</code>也可以看到hadoop里面的一些进程.比如<br/>
<code>NameNode</code>、<code>DataNode</code>、<code>ResourceManager</code>、<code>NodeManager</code>.</p>

<p>所以这些进程都是作为一个RPCserver,并对外提供RPC服务的.</p>

<h1 id="toc_5">总结</h1>

<p>定义RPC协议,实现RPC协议<br/>
<img src="media/15222053353935/15222165453483.jpg" alt=""/></p>

<p>构造并启动RPC服务<br/>
<img src="media/15222053353935/15222174334242.jpg" alt=""/></p>

<p>构成RPC客户端并发送RPC请求<br/>
<img src="media/15222053353935/15222173920962.jpg" alt=""/></p>

<p>使用Hadoop RPC的4个步骤</p>

<ul>
<li>定义RPC协议</li>
<li>实现RPC协议</li>
<li>构造并启动RPC server</li>
<li>构造RPC client并发送RPC请求</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[概率分布函数和概率密度函数]]></title>
    <link href="http://dmlcoding.com/15221149143615.html"/>
    <updated>2018-03-27T09:41:54+08:00</updated>
    <id>http://dmlcoding.com/15221149143615.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>研究一个随机变量,不只要看它能取哪些值,更重要的是它取各种值的概率如何!</p>
</blockquote>

<ul>
<li>概率分布函数</li>
<li>概率密度函数</li>
</ul>

<h2 id="toc_0">离散型随机变量</h2>

<p>在理解这两个词之前</p>

<span id="more"></span><!-- more --> 

<ul>
<li>概率分布函数</li>
<li>概率密度函数</li>
</ul>

<p>先理解这两个词</p>

<ul>
<li>概率函数: 就是用函数的形式来表达概率.也叫分布律.</li>
<li>概率分布: 表达随机变量所有可能取值的分布情况.注意:是所有的取值</li>
<li>分布函数: 即,概率分布函数,</li>
</ul>

<p><img src="media/15221149143615/15221166166372.png" alt=""/></p>

<p>概率分布函数: 它是概率函数各个取值的累加结果.也叫累积概率函数</p>

<ul>
<li>分布函数</li>
</ul>

<h2 id="toc_1">连续型随机变量</h2>

<ul>
<li>概率密度函数: 等同于概率函数,why?</li>
</ul>

<p>在连续型随机变量中为啥要将概率函数叫成概率密度函数呢?<br/>
参考陈希孺老师所著的《概率论与数理统计》<br/>
<img src="media/15221149143615/15221159306143.png" alt=""/><br/>
<img src="media/15221149143615/15221159405543.png" alt=""/></p>

<p>概率密度函数用数学公式表示就是一个定积分的函数，定积分在数学中是用来求面积的，而在这里，你就把概率表示为面积即可！<br/>
<img src="media/15221149143615/15221159485806.png" alt=""/></p>

<p>左边是F(x)<code>连续型随机变量分布函数</code>画出的图形，右边是f(x)<code>连续型随机变量的概率密度函数</code>画出的图像，它们之间的关系就是，概率密度函数是分布函数的导函数。</p>

<p>两张图一对比，你就会发现，如果用右图中的面积来表示概率，利用图形就能很清楚的看出，哪些取值的概率更大！这样看起来是不是特别直观，特别爽！！所以，我们在表示连续型随机变量的概率时，用f(x)概率密度函数来表示，是非常好的！</p>

<h1 id="toc_2">参考</h1>

<p><a href="https://www.jianshu.com/p/b570b1ba92bb">应该如何理解概率分布函数和概率密度函数?</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式系统的一致性]]></title>
    <link href="http://dmlcoding.com/15220339795263.html"/>
    <updated>2018-03-26T11:12:59+08:00</updated>
    <id>http://dmlcoding.com/15220339795263.html</id>
    <content type="html"><![CDATA[
<p><img src="media/15220339795263/15221454798314.jpg" alt=""/></p>

<p>先上个图,未完待续......</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[docker 错误]]></title>
    <link href="http://dmlcoding.com/15217143404677.html"/>
    <updated>2018-03-22T18:25:40+08:00</updated>
    <id>http://dmlcoding.com/15217143404677.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">net/http: TLS handshake timeout</h2>

<p>下载镜像的时候出现<code>net/http: TLS handshake timeout</code>,<br/>
原因是docker默认镜像拉取地址为国外仓库下载速度较慢，则会报错“net/http: TLS handshake timeout”。</p>

<span id="more"></span><!-- more -->

<p>此时，只需要将拉取地址改为国内镜像仓库即可。</p>

<p>标准格式为：</p>

<pre><code>$ docker pull registry.docker-cn.com/myname/myrepo:mytag
</code></pre>

<p>例：</p>

<pre><code>$ docker pull registry.docker-cn.com/library/ubuntu:16.04
</code></pre>

<p>为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。</p>

<pre><code>{
  &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]
}
</code></pre>

<p>修改保存后重启 Docker 以使配置生效。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mac 搭建 区块链开发环境]]></title>
    <link href="http://dmlcoding.com/15216998348495.html"/>
    <updated>2018-03-22T14:23:54+08:00</updated>
    <id>http://dmlcoding.com/15216998348495.html</id>
    <content type="html"><![CDATA[
<ul>
<li><a href="https://docs.docker.com/docker-for-mac/install/">官方安装文档</a></li>
<li><a href="https://docs.docker.com/docker-for-mac/">官方使用文档</a></li>
</ul>

<span id="more"></span><!-- more -->

<h1 id="toc_0">用docker下载ubuntu镜像</h1>

<pre><code># 下载ubuntu镜像
docker pull ubuntu
# 进入镜像中
docker run -it ubuntu /bin/bash
# 查看ubuntu的发行版本
cat /etc/issue

</code></pre>

<p>新开一个终端查看</p>

<pre><code> hushiwei@hsw  ~/Docker  docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
ubuntu                latest              f975c5035748        2 weeks ago         112MB
</code></pre>

<h2 id="toc_1">进入镜像后,即生成了一个容器.更新容易里面的系统</h2>

<p>跟新apt-get,安装常用开发工具</p>

<pre><code>apt-get update
apt-get install vim
apt-get install sudo
</code></pre>

<h2 id="toc_2">提高安全意识,添加普通用户</h2>

<pre><code>adduser deploy
su deploy
</code></pre>

<h2 id="toc_3">给普通用户sudo权限</h2>

<pre><code># root下执行
chmod 777 /etc/sudoers
vim /etc/sudoers
</code></pre>

<p>在/etc/sudoers文件里面添加一行,表示给deploy用户sudo权限,并且不需要密码<br/>
<img src="media/15216998348495/15217671764613.jpg" alt=""/></p>

<p>把这个文件的权限改回去</p>

<pre><code>chmod 440 /etc/sudoers
</code></pre>

<h1 id="toc_4">在容器中进行区块链环境的搭建</h1>

<p>注意:目前为止,我们还没退出容器过.</p>

<h2 id="toc_5">安装curl,nodejs</h2>

<pre><code>sudo apt-get install curl

# 安装nodejs的版本
root@a43d121b81a0:~# curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -
# 完成后输出
## Run `apt-get install nodejs` (as root) to install Node.js v8.x LTS Carbon and npm

# 然后安装nodejs
apt-get install nodejs

# 查看版本
node -v

npm -v
</code></pre>

<h2 id="toc_6">安装testrpc,truffle</h2>

<pre><code># 安装淘宝镜像,速度快
npm install -g cnpm --registry=https://registry.npm.taobao.org

sudo cnpm install -g ethereumjs-testrpc
# 完成后输入testrpc,进行校验

sudo cnpm install -g truffle

</code></pre>

<h1 id="toc_7">提交安装好环境的容器</h1>

<p>在开一个窗口,输入<code>docker ps</code> 找到正在运行的容器的<code>CONTAINER ID</code><br/>
刚刚在这个容器里面安装好了环境,那么我们需要保存一下,所以用docker commit提交这个<br/>
容器,成为镜像<br/>
<code><br/>
docker commit a43d121b81a0 testrpc-truffle-env:v1<br/>
</code><br/>
提交后,再查看images,比之前的ubuntu大了不少.毕竟装了那么多工具进去了<br/>
<code><br/>
 hushiwei@hsw  ~/Docker  docker images<br/>
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE<br/>
testrpc-truffle-env   v1                  a2073b0b64cc        6 minutes ago       503MB<br/>
ubuntu                latest              f975c5035748        2 weeks ago         112MB<br/>
</code></p>

<h2 id="toc_8">退出再进去</h2>

<p>现在就算退出运行中的容器,之前安装的工具也都还在了.<br/>
执行下面的命令即可进入刚刚提交的镜像中.<code>a2073b0b64cc</code>是刚刚提交的镜像的id</p>

<pre><code>docker run -it a2073b0b64cc /bin/bash
</code></pre>

<h1 id="toc_9">安装idea插件进行开发</h1>

<p>在idea的Plugins中安装插件<code>Intellij-Solidity</code></p>

<h1 id="toc_10">docker挂载本地目录进行开发</h1>

<p>将本地的<code>/Users/hushiwei/BlockChain/ethereum</code>目录,与容器中的<code>/home/deploy</code>进行共享</p>

<pre><code>docker run -it -v /Users/hushiwei/BlockChain/ethereum:/home/deploy a2073b0b64cc /bin/bash

</code></pre>

<h1 id="toc_11">生成truffle代码</h1>

<p>在容器的<code>/home/deploy/demo3</code>目录下执行<code>truffle init</code> 生成项目</p>

<p><img src="media/15216998348495/15217712425759.jpg" alt=""/></p>

<p>本机对应的目录也可以看到<br/>
<img src="media/15216998348495/15217712751901.jpg" alt=""/></p>

<h2 id="toc_12">用idea打开ethereum目录作为项目.</h2>

<p><img src="media/15216998348495/15217713264100.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LeetCode解题思路]]></title>
    <link href="http://dmlcoding.com/15216328231070.html"/>
    <updated>2018-03-21T19:47:03+08:00</updated>
    <id>http://dmlcoding.com/15216328231070.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">Easy</h1>

<span id="more"></span><!-- more -->

<h2 id="toc_1"><u>01</u>TwoSum</h2>

<h2 id="toc_2"><u>07</u>ReverseInteger</h2>

<h2 id="toc_3"><u>09</u>PalindromeNumber</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Macbook 区块链开发]]></title>
    <link href="http://dmlcoding.com/15216132281232.html"/>
    <updated>2018-03-21T14:20:28+08:00</updated>
    <id>http://dmlcoding.com/15216132281232.html</id>
    <content type="html"><![CDATA[
<p>基本概念就不说了,网上一大堆.</p>

<h2 id="toc_0">客户端安装</h2>

<pre><code>brew tap ethereum/ethereum

brew install ethereum

</code></pre>

<span id="more"></span><!-- more -->

<p>很是花了一些时间呢<br/>
<code><br/>
  /usr/local/Cellar/ethereum/1.8.2: 9 files, 54.7MB, built in 26 minutes 26 seconds<br/>
</code></p>

<pre><code>
geth -h
geth console

</code></pre>

<pre><code>
 hushiwei@hsw  ~/BlockChain  geth console
INFO [03-21|15:05:35] Maximum peer count                       ETH=25 LES=0 total=25
INFO [03-21|15:05:35] Starting peer-to-peer node               instance=Geth/v1.8.2-stable/darwin-amd64/go1.10
INFO [03-21|15:05:35] Allocated cache and file handles         database=/Users/hushiwei/Library/Ethereum/geth/chaindata cache=768 handles=1024
INFO [03-21|15:05:35] Initialised chain configuration          config=&quot;{ChainID: 1 Homestead: 1150000 DAO: 1920000 DAOSupport: true EIP150: 2463000 EIP155: 2675000 EIP158: 2675000 Byzantium: 4370000 Constantinople: &lt;nil&gt; Engine: ethash}&quot;
INFO [03-21|15:05:35] Disk storage enabled for ethash caches   dir=/Users/hushiwei/Library/Ethereum/geth/ethash count=3
INFO [03-21|15:05:35] Disk storage enabled for ethash DAGs     dir=/Users/hushiwei/.ethash                      count=2
INFO [03-21|15:05:35] Initialising Ethereum protocol           versions=&quot;[63 62]&quot; network=1
INFO [03-21|15:05:35] Loaded most recent local header          number=0 hash=d4e567…cb8fa3 td=17179869184
INFO [03-21|15:05:35] Loaded most recent local full block      number=0 hash=d4e567…cb8fa3 td=17179869184
INFO [03-21|15:05:35] Loaded most recent local fast block      number=0 hash=d4e567…cb8fa3 td=17179869184
INFO [03-21|15:05:35] Loaded local transaction journal         transactions=0 dropped=0
INFO [03-21|15:05:35] Regenerated local transaction journal    transactions=0 accounts=0
INFO [03-21|15:05:35] Starting P2P networking
INFO [03-21|15:05:37] UDP listener up                          self=enode://239405879cbf4f9d8cfb1dafca4bab87b8f7ce27fbdb486347d7215b1de56663805d520d44044bb5ed324a79e41fbdd0be2adbbe5f31684cf528bf2faef4796f@[::]:30303
INFO [03-21|15:05:37] RLPx listener up                         self=enode://239405879cbf4f9d8cfb1dafca4bab87b8f7ce27fbdb486347d7215b1de56663805d520d44044bb5ed324a79e41fbdd0be2adbbe5f31684cf528bf2faef4796f@[::]:30303
INFO [03-21|15:05:37] IPC endpoint opened                      url=/Users/hushiwei/Library/Ethereum/geth.ipc
Welcome to the Geth JavaScript console!

instance: Geth/v1.8.2-stable/darwin-amd64/go1.10
 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 txpool:1.0 web3:1.0

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[大数据框架-开源协议]]></title>
    <link href="http://dmlcoding.com/15209079363420.html"/>
    <updated>2018-03-13T10:25:36+08:00</updated>
    <id>http://dmlcoding.com/15209079363420.html</id>
    <content type="html"><![CDATA[
<p>知道我们经常用的开源框架的开源协议么?</p>

<span id="more"></span><!-- more -->

<table>
<thead>
<tr>
<th>开源项目</th>
<th>开源协议</th>
</tr>
</thead>

<tbody>
<tr>
<td>Superset</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Yanagishima</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Kibana</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Spark</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Tensorflow</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>PlanOut</td>
<td>BSD License</td>
</tr>
<tr>
<td>Hadoop</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Hive</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Sqoop</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Impala</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Presto</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Hbase</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Mysql</td>
<td>GPL license</td>
</tr>
<tr>
<td>Elasticsearch</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>CDH</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Hue</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Oozie</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Flume</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Kafka</td>
<td>Apache License 2.0</td>
</tr>
<tr>
<td>Logstash</td>
<td>Apache License 2.0</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[fabric自动化部署]]></title>
    <link href="http://dmlcoding.com/15209051281712.html"/>
    <updated>2018-03-13T09:38:48+08:00</updated>
    <id>http://dmlcoding.com/15209051281712.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">简介</h2>

<p>Fabric是一个用Python开发的部署工具，最大特点是不用登录远程服务器，在本地运行远程命令，几行Python脚本就可以轻松部署。</p>

<p>Fabric提供几个简单的API来完成所有的部署，最常用的是local()和run()，分别在本地和远程执行命令，put()可以把本地文件上传到远程，当需要在远程指定当前目录时，只需用with cd(&#39;/path/to/dir/&#39;):即可。</p>

<p>默认情况下，当命令执行失败时，Fabric会停止执行后续命令。有时，我们允许忽略失败的命令继续执行，比如run(&#39;rm /tmp/abc&#39;)在文件不存在的时候有可能失败，这时可以用with settings(warn_only=True):执行命令，这样Fabric只会打出警告信息而不会中断执行。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">Fabric是如何在远程执行命令的呢</h2>

<p>其实Fabric所有操作都是基于SSH执行的，必要时它会提示输入口令，所以非常安全。更好的办法是在指定的部署服务器上用证书配置无密码的ssh连接。</p>

<p>如果是基于团队开发，可以让Fabric利用版本库自动检出代码，自动执行测试、打包、部署的任务。由于Fabric运行的命令都是基本的Linux命令，所以根本不需要用Fabric本身来扩展，会敲Linux命令就能用Fabric部署。</p>

<h1 id="toc_2">安装</h1>

<p>在windows上安装可能会有各种依赖的问题,安装就可能没有那么顺利.</p>

<p>为了减少麻烦.我们直接把你电脑上的原装python都给卸载了吧,无论你是python2还是python3.都卸载了.</p>

<p>我们直接在windows上安装Anaconda包.Anaconda是给机器学习学习者集成的python环境,可以给不想折腾的同学,节省很多安装的时间.</p>

<h2 id="toc_3">下载安装Anaconda</h2>

<p><a href="https://www.anaconda.com/download/#windows">官网下载安装包</a><br/>
<img src="media/15209051281712/15260197981453.jpg" alt=""/></p>

<p>下载python3.6吧,毕竟python2在以后python社区会逐渐的不再维护支持了.另外Anaconda中的python3,可以用虚拟环境创建python2.7的虚拟环境.</p>

<p>下载如图所示后,会有安装包,点击下一步之类的就安装好了,记得在安装的过程中要点上配置环境变量.如果你错过了,那么就只能在安装完成后,自己手动的配置Anaconda的环境变量了.</p>

<p>手动配置Anaconda环境变量参考网上文章,和一般的环境变量没啥区别.</p>

<h2 id="toc_4">创建python2.7的虚拟环境</h2>

<p>因为<code>fabric.py</code>脚本是在python2.7下写的.因此咱们需要创建一个python2.7的环境,然后在这个环境里面下载安装<code>fabric模块</code></p>

<ol>
<li>创建python2.7虚拟环境</li>
</ol>

<pre><code>conda create -n python27 python=2.7
</code></pre>

<ol>
<li>激活python2.7的虚拟环境</li>
</ol>

<pre><code>activate python27
</code></pre>

<ol>
<li>在python2.7环境下安装fabric模块</li>
</ol>

<pre><code>pip install fabric
</code></pre>

<p>到此已经把fabric模块安装完成了.接下来就是使用了.</p>

<ol>
<li>退出python2.7的虚拟环境</li>
</ol>

<pre><code>deactivate
</code></pre>

<h1 id="toc_5">使用</h1>

<ul>
<li><a href="http://www.fabfile.org/installing.html">官网说明</a></li>
</ul>

<h2 id="toc_6">fabric常用api</h2>

<table>
<thead>
<tr>
<th>函数</th>
<th>解释</th>
<th>例子</th>
</tr>
</thead>

<tbody>
<tr>
<td>local</td>
<td>执行本地命令</td>
<td>local(&#39;ls -l&#39;)</td>
</tr>
<tr>
<td>lcd</td>
<td>切换本地目录(需要with包裹)</td>
<td>lcd(&#39;本地目录&#39;)</td>
</tr>
<tr>
<td>run</td>
<td>执行远程命令</td>
<td>run(&#39;ls -l&#39;)</td>
</tr>
<tr>
<td>cd</td>
<td>切换远程目录(需要with包裹)</td>
<td>cd(&#39;远程目录&#39;)</td>
</tr>
<tr>
<td>put</td>
<td>将本地文件上传至远程目录</td>
<td>put(&#39;本地文件&#39;,&#39;远程目录&#39;)</td>
</tr>
<tr>
<td>env</td>
<td>fabric环境，配置远程ip、端口、密码</td>
<td>见下文</td>
</tr>
</tbody>
</table>

<h2 id="toc_7">fabric远程执行例子</h2>

<p>想好你的上线步骤,比如我平时的上线步骤就是这么几步.</p>

<ol>
<li>拉取SVN代码</li>
<li>本地编译打包</li>
<li>上传到服务器</li>
<li>备份服务器上的上一个版本</li>
<li>部署到服务器指定目录</li>
<li>清理多余文件</li>
<li>相关Jar包和文件上传到HDFS</li>
</ol>

<p>如果不符合你的业务需求,可以参考脚本做相应的修改.</p>

<h3 id="toc_8">Mac下的脚本</h3>

<pre><code># -*- coding: utf-8 -*-
&quot;&quot;&quot;
Created by hushiwei on 2017/10/16
desc : 自动化部署上线
1. 更新代码到指定分支
2. 执行 fab deploy
3. OK...
&quot;&quot;&quot;
import os
import datetime
from fabric.api import *
from fabric.contrib.console import confirm
from fabric.colors import blue, red, green
from fabric.contrib.files import *
import sys

local_dir = &quot;/Users/hushiwei/demo/auto_deploy/&quot;
remote_project = &quot;/home/hadoop/statistics/ad/&quot;
remote_dir = &quot;/home/hadoop/statistics/auto_deploy/&quot;
remote_dir_bak = &quot;/home/hadoop/statistics/auto_deploy_bak/&quot;
svn_path = &quot;svn://svn.gm825.com/code/server/bigdata/xxxxxxxxxxx&quot;
hdfs_path = &quot;/user/oozie/ad/&quot;

env.user = &quot;xxxxxxx&quot;

env.hosts = [&#39;***.***.***.***&#39;]
env.password = &#39;**********&#39;


def today():
  return datetime.date.today().strftime(&quot;%Y%m%d&quot;)


def svn_to_local(project_name):
  &#39;&#39;&#39;
  fab svn_to_local:project_name=quickapp
  把项目SVN的trunk代码checkout到本地
  :param project_name:
  :return:
  &#39;&#39;&#39;
  print green(&#39;Checking out the project, SVN Path Is : %s&#39; % svn_path)
  if not os.path.exists(local_dir):
    local(&#39;mkdir &#39; + local_dir)

  with lcd(local_dir):
    local(&#39;rm -rf &#39; + local_dir + project_name)
    local(&#39;svn co &#39; + svn_path, capture=True)
    local(&#39;mv {svn_name} {project_name} &#39;.format(svn_name=svn_path.split(&quot;/&quot;)[-1],project_name=project_name))
  print green(&#39;Checkout The Project --- Finished!&#39;)


def pack_project(project_name):
  &#39;&#39;&#39;
  fab pack_project:project_name=quickapp
  把本地项目打成tar包,准备上传到服务器
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with lcd(local_dir + project_name):
    local(&quot;find &quot; + local_dir + project_name + &quot; -name &#39;.svn&#39; | xargs rm -rf&quot;)
    print(green(&quot;Removed the .svn file --- Finished, Pack the project&quot;))
    local(&#39;mvn clean scala:compile compile package -DskipTests&#39;, capture=True)
    local(&#39;mv oozie %s&#39; % project_name)
    local(&#39;mv target/*-jar-with-dependencies.jar {project_name}/&#39;.format(project_name=project_name))
    local(&#39;mv target/*-SNAPSHOT.jar {project_name}/{project_name}_streaming&#39;.format(project_name=project_name))
    local(&#39;tar cfz {local_dir}{project_name}.tar.gz {project_name}/*&#39;.format(
        project_name=project_name, local_dir=local_dir))

  print green(&#39;Pack the Project --- Finished!&#39;)


def backup_serverfile(project_name):
  &#39;&#39;&#39;
  备份服务器上的项目
  :param project_name:
  :return:
  &#39;&#39;&#39;
  print green(&quot;Back the project on server&quot;)
  with cd(remote_project):
    with settings(warn_only=True):
      # 创建备份文件目录
      if not exists(remote_dir_bak):
        run(&quot;mkdir &quot;+remote_dir_bak)
      run(
          &quot;tar cfz &quot; + remote_dir_bak + project_name + &quot;_&quot; + today() + &quot;.tar.gz --exclude source_log &quot; + project_name + &quot;/&quot;)
      run(&quot;cp -r &quot; + project_name + &quot; &quot; + project_name + &quot;_&quot; + today())
  print green(&quot;Back up the project on server --- Finished!&quot;)


def put_package(project_name):
  &#39;&#39;&#39;
  上传发布包到远程服务器
  :param project_name:
  :return:
  &#39;&#39;&#39;
  if not exists(remote_dir):
    run(&quot;mkdir &quot;+remote_dir)
  print green(&quot;Start upload the Project to the Server ...&quot;)
  with cd(remote_dir):
    with settings(warn_only=True):
      result = put(local_dir + project_name + &quot;.tar.gz&quot;,
                   remote_dir + project_name + &quot;.tar.gz&quot;)
      if result.failed and not confirm(&quot;put file failed,Continue?&quot;):
        abort(&quot;Aborting file put task!&quot;)
  print green(&quot;Put the package to remote server --- Finished!&quot;)


def deploy_project(project_name):
  &#39;&#39;&#39;
  解压线上tar包,进行部署项目
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with cd(remote_dir):
    with settings(warn_only=True):
      result = run(&quot;tar zxf &quot; + project_name + &quot;.tar.gz -C &quot; + remote_project)
    if result.failed:
      print red(&quot;Deploy the Project Failed,Roll backing&quot;)
      roll_back(project_name)
  run(&quot;cd {remote_project} &amp;&amp; chown -R hadoop:hadoop {project_name}&quot;.format(
      remote_project=remote_project, project_name=project_name))
  print(green(&quot;Deploy the package at the server --- Finished&quot;))


def clear_deploy(project_name):
  &#39;&#39;&#39;
  删除部署后留下的多余文件
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with cd(remote_project):
    run(&#39;rm -rf &#39; + project_name + &quot;_&quot; + today())
  with cd(remote_dir):
    run(&quot;rm -rf &quot; + project_name + &quot;.tar.gz&quot;)
  print green(&quot;Clear the files at the server --- Finished&quot;)


def roll_back(project_name):
  &#39;&#39;&#39;
  当部署失败后,回滚到前一个备份版本
  :param project_name:
  :return:
  &#39;&#39;&#39;
  run(&quot;rm -rf &quot; + project_name)
  run(&quot;mv &quot; + project_name + &quot;_&quot; + today() + &quot; &quot; + project_name)
  print red(&quot;Roll back deploy --- Finished&quot;)


@runs_once
@task
def prepare_deploy(project_name=&quot;quickapp&quot;):
  &quot;&quot;&quot;
  部署前准备，下载最新版代码，打包代码
  &quot;&quot;&quot;
  svn_to_local(project_name)
  pack_project(project_name)


def upload_files(project_name):
  hdfs_work=hdfs_path+project_name+&quot;/&quot;
  with cd(remote_project + project_name):
    run(&quot;hadoop fs -put -f ./{wf,hourwf,offlinewf,targetingwf} %s&quot; % hdfs_work)
  print green(&quot;upload files to hdfs --- Finished&quot;)


def upload_jars(project_name):
  hdfs_work=hdfs_path+project_name+&quot;/&quot;
  wfPaths = [&#39;wf&#39;, &#39;hourwf&#39;,&#39;offlinewf&#39;,&#39;targetingwf&#39;]
  with cd(remote_project + project_name):
    for i in range(len(wfPaths)):
      run(&quot;hadoop fs -put -f ./*.jar &quot; + hdfs_work + wfPaths[i] + &quot;/lib&quot;)
  print green(&quot;upload jars to hdfs --- Finished&quot;)


@task
def upload_hdfs(project_name=&quot;quickapp&quot;):
  &#39;&#39;&#39;
  将项目上传到hdfs
  :return:
  &#39;&#39;&#39;
  upload_files(project_name)
  upload_jars(project_name)

@task
def upload_hdfs_by_exec_shell(project_name=&quot;quickapp&quot;):
  &#39;&#39;&#39;
  通过调用项目里面的upgrade.sh脚本来上传项目到hdfs
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with cd(remote_project):
    run(&quot;cd %s/wf/shell &amp;&amp; sh upgrade.sh &quot; % project_name)


@task
def deploy(project_name=&quot;quickapp&quot;, prepated=True):
  &#39;&#39;&#39;
  本地打包,部署到线上服务器,上传到HDFS全流程
  :param project_name:
  :param prepated:
  :return:
  &#39;&#39;&#39;
  if prepated == True:
    prepare_deploy(project_name)
  # 上传
  put_package(project_name)
  # 备份
  backup_serverfile(project_name)
  # 部署
  deploy_project(project_name)
  # 清理
  clear_deploy(project_name)
  # 上传hdfs
  upload_hdfs(project_name)

</code></pre>

<h3 id="toc_9">Windows下的脚本</h3>

<pre><code># -*- coding: utf-8 -*-
&quot;&quot;&quot;
Created by hushiwei on 2017/10/16
desc : 自动化部署上线
1. 更新代码到trunk.
2. 执行 fab deploy
3. OK...
&quot;&quot;&quot;
import os
import datetime
from fabric.api import *
from fabric.contrib.console import confirm
from fabric.colors import blue, red, green
from fabric.contrib.files import *
import os,tarfile


local_dir = &quot;D:\wanka\svn_project\dsp_interact\\&quot;
remote_project = &quot;/home/hadoop/statistics/ad/&quot;
remote_dir = &quot;/home/hadoop/statistics/auto_deploy/&quot;
remote_dir_bak = &quot;/home/hadoop/statistics/auto_deploy_bak/&quot;
svn_path = &quot;svn://svn.gm825.com/code/server/bigdata/xxxxxxxxxx&quot;
hdfs_path = &quot;/user/oozie/ad/&quot;

env.user = &quot;xxxxxxx&quot;

env.hosts = [&#39;***.***.***.***&#39;]
env.password = &#39;**********&#39;

# python在windows环境打tar包.output_filename为tar包文件,source_dir为要打包的目录
def make_targz(output_filename, source_dir):
  with tarfile.open(output_filename, &quot;w:gz&quot;) as tar:
    tar.add(source_dir, arcname=os.path.basename(source_dir))

def today():
  return datetime.date.today().strftime(&quot;%Y%m%d&quot;)


def svn_to_local(project_name):
  &#39;&#39;&#39;
  fab svn_to_local:project_name=dsp_interaction_ad
  把项目SVN的trunk代码checkout到本地
  :param project_name:
  :return:
  &#39;&#39;&#39;
  print green(&#39;Checking out the project, SVN Path Is : %s&#39; % svn_path)
  if not os.path.exists(local_dir):
    local(&#39;mkdir &#39; + local_dir)

  with lcd(local_dir):

    # local(&#39;rm -rf &#39; + local_dir + project_name)

    local(&#39;if exist &#39; + local_dir + project_name + &#39; (rd /s /q &#39; + local_dir + project_name + &#39;)&#39;)
    local(&#39;if exist &#39; + local_dir + project_name + &#39;.tar.gz (del &#39; + local_dir + project_name + &#39;.tar.gz)&#39;)

    local(&#39;svn co &#39; + svn_path, capture=True)
    local(&#39;rename {svn_name} {project_name} &#39;.format(svn_name=svn_path.split(&quot;/&quot;)[-1],project_name=project_name))
  print green(&#39;Checkout The Project --- Finished!&#39;)


def pack_project(project_name):
  &#39;&#39;&#39;
  fab pack_project:project_name=dsp_interaction_ad
  把本地项目打成tar包,准备上传到服务器
  :param project_name:
  :return:
  &#39;&#39;&#39;
  # with lcd(local_dir + project_name):
  with lcd(local_dir):
    
    local(&quot;rd /s /q &quot; + local_dir + project_name + &#39;\\.svn&#39;, capture=True)
    print(green(&quot;Removed the .svn file --- Finished, Pack the project&quot;))

  with lcd(local_dir + project_name):
    local(&#39;mvn clean scala:compile compile package -DskipTests&#39;, capture=True)
    local(&#39;rename oozie %s&#39; % project_name)
    local(&#39;move target\\*-jar-with-dependencies.jar {project_name}\\&#39;.format(project_name=project_name))
    local(&#39;move target\\*-SNAPSHOT.jar {project_name}\\{project_name}_streaming&#39;.format(project_name=project_name))

    make_targz(local_dir + project_name + &#39;.tar.gz&#39;, local_dir + project_name + &#39;\\&#39; + project_name)

  print green(&#39;Pack the Project --- Finished!&#39;)


def backup_serverfile(project_name):
  &#39;&#39;&#39;
  备份服务器上的项目
  :param project_name:
  :return:
  &#39;&#39;&#39;
  print green(&quot;Back the project on server&quot;)
  with cd(remote_project):
    with settings(warn_only=True):
      # 创建备份文件目录
      if not exists(remote_dir_bak):
        run(&quot;mkdir &quot;+remote_dir_bak)
      run(
          &quot;tar cfz &quot; + remote_dir_bak + project_name + &quot;_&quot; + today() + &quot;.tar.gz --exclude source_log &quot; + project_name + &quot;/&quot;)
      run(&quot;cp -r &quot; + project_name + &quot; &quot; + project_name + &quot;_&quot; + today())
  print green(&quot;Back up the project on server --- Finished!&quot;)


def put_package(project_name):
  &#39;&#39;&#39;
  上传发布包到远程服务器
  :param project_name:
  :return:
  &#39;&#39;&#39;
  if not exists(remote_dir):
    run(&quot;mkdir &quot;+remote_dir)
  print green(&quot;Start upload the Project to the Server ...&quot;)
  with cd(remote_dir):
    with settings(warn_only=True):
      result = put(local_dir + project_name + &quot;.tar.gz&quot;,
                   remote_dir + project_name + &quot;.tar.gz&quot;)
      if result.failed and not confirm(&quot;put file failed,Continue?&quot;):
        abort(&quot;Aborting file put task!&quot;)
  print green(&quot;Put the package to remote server --- Finished!&quot;)


def deploy_project(project_name):
  &#39;&#39;&#39;
  解压线上tar包,进行部署项目
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with cd(remote_dir):
    with settings(warn_only=True):
      result = run(&quot;tar zxf &quot; + project_name + &quot;.tar.gz -C &quot; + remote_project)
    if result.failed:
      print red(&quot;Deploy the Project Failed,Roll backing&quot;)
      roll_back(project_name)
  run(&quot;cd {remote_project} &amp;&amp; chown -R hadoop:hadoop {project_name}&quot;.format(
      remote_project=remote_project, project_name=project_name))
  print(green(&quot;Deploy the package at the server --- Finished&quot;))


def clear_deploy(project_name):
  &#39;&#39;&#39;
  删除部署后留下的多余文件
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with cd(remote_project):
    run(&#39;rm -rf &#39; + project_name + &quot;_&quot; + today())
  with cd(remote_dir):
    run(&quot;rm -rf &quot; + project_name + &quot;.tar.gz&quot;)
  print green(&quot;Clear the files at the server --- Finished&quot;)


def roll_back(project_name):
  &#39;&#39;&#39;
  当部署失败后,回滚到前一个备份版本
  :param project_name:
  :return:
  &#39;&#39;&#39;
  run(&quot;rm -rf &quot; + project_name)
  run(&quot;mv &quot; + project_name + &quot;_&quot; + today() + &quot; &quot; + project_name)
  print red(&quot;Roll back deploy --- Finished&quot;)


@runs_once
@task
def prepare_deploy(project_name=&quot;dsp_interaction_ad&quot;):
  &quot;&quot;&quot;
  部署前准备，下载最新版代码，打包代码
  &quot;&quot;&quot;
  svn_to_local(project_name)
  pack_project(project_name)


def upload_files(project_name):
  hdfs_work=hdfs_path+project_name+&quot;/&quot;
  with cd(remote_project + project_name):
    run(&quot;hadoop fs -put -f ./{wf,hourwf,offlinewf,targetingwf} %s&quot; % hdfs_work)
  print green(&quot;upload files to hdfs --- Finished&quot;)


def upload_jars(project_name):
  hdfs_work=hdfs_path+project_name+&quot;/&quot;
  wfPaths = [&#39;wf&#39;, &#39;hourwf&#39;,&#39;offlinewf&#39;,&#39;targetingwf&#39;]
  with cd(remote_project + project_name):
    for i in range(len(wfPaths)):
      run(&quot;hadoop fs -put -f ./*.jar &quot; + hdfs_work + wfPaths[i] + &quot;/lib&quot;)
  print green(&quot;upload jars to hdfs --- Finished&quot;)


@task
def upload_hdfs(project_name=&quot;dsp_interaction_ad&quot;):
  &#39;&#39;&#39;
  将项目上传到hdfs
  :return:
  &#39;&#39;&#39;
  upload_files(project_name)
  upload_jars(project_name)

@task
def upload_hdfs_by_exec_shell(project_name=&quot;dsp_interaction_ad&quot;):
  &#39;&#39;&#39;
  通过调用项目里面的upgrade.sh脚本来上传项目到hdfs
  :param project_name:
  :return:
  &#39;&#39;&#39;
  with cd(remote_project):
    run(&quot;cd %s/wf/shell &amp;&amp; sh upgrade.sh &quot; % project_name)


@task
def deploy(project_name=&quot;dsp_interaction_ad&quot;, prepated=True):
  &#39;&#39;&#39;
  本地打包,部署到线上服务器,上传到HDFS全流程
  :param project_name:
  :param prepated:
  :return:
  &#39;&#39;&#39;
  if prepated == True:
    prepare_deploy(project_name)
  # 上传
  put_package(project_name)
  # 备份
  backup_serverfile(project_name)
  # 部署
  deploy_project(project_name)
  # 清理
  clear_deploy(project_name)
  # 上传hdfs
  upload_hdfs(project_name)

</code></pre>

<h2 id="toc_10">执行命令</h2>

<p>在执行fab命令之前,需要先激活之前安装的python2.7虚拟环境.在这个环境下才可以执行fab命令</p>

<pre><code>activate python27
</code></pre>

<p>激活python2.7环境后,我们就在fabric.py文件的同级目录下执行<strong>fab deploy</strong>即可一键上线</p>

<pre><code>fab deploy
</code></pre>

<p>至于其他更加详细的命令,可以执行<strong>fab -h</strong>参考官方说明.</p>

<pre><code> hushiwei@hsw  ~  fab -h
Usage: fab [options] &lt;command&gt;[:arg1,arg2=val2,host=foo,hosts=&#39;h1;h2&#39;,...] ...

Options:
  -h, --help            show this help message and exit
  -d NAME, --display=NAME
                        print detailed info about command NAME
  -F FORMAT, --list-format=FORMAT
                        formats --list, choices: short, normal, nested
  -I, --initial-password-prompt
                        Force password prompt up-front
  --initial-sudo-password-prompt
                        Force sudo password prompt up-front
  -l, --list            print list of possible commands and exit
  --set=KEY=VALUE,...   comma separated KEY=VALUE pairs to set Fab env vars
  --shortlist           alias for -F short --list
  -V, --version         show program&#39;s version number and exit
  -a, --no_agent        don&#39;t use the running SSH agent
  -A, --forward-agent   forward local agent to remote end
  --abort-on-prompts    abort instead of prompting (for password, host, etc)
  -c PATH, --config=PATH
                        specify location of config file to use
  --colorize-errors     Color error output
  -D, --disable-known-hosts
                        do not load user known_hosts file
  -e, --eagerly-disconnect
                        disconnect from hosts as soon as possible
  -f PATH, --fabfile=PATH
                        python module file to import, e.g. &#39;../other.py&#39;
  -g HOST, --gateway=HOST
                        gateway host to connect through
  --gss-auth            Use GSS-API authentication
  --gss-deleg           Delegate GSS-API client credentials or not
  --gss-kex             Perform GSS-API Key Exchange and user authentication
  --hide=LEVELS         comma-separated list of output levels to hide
  -H HOSTS, --hosts=HOSTS
                        comma-separated list of hosts to operate on
  -i PATH               path to SSH private key file. May be repeated.
  -k, --no-keys         don&#39;t load private key files from ~/.ssh/
  --keepalive=N         enables a keepalive every N seconds
  --linewise            print line-by-line instead of byte-by-byte
  -n M, --connection-attempts=M
                        make M attempts to connect before giving up
  --no-pty              do not use pseudo-terminal in run/sudo
  -p PASSWORD, --password=PASSWORD
                        password for use with authentication and/or sudo
  -P, --parallel        default to parallel execution method
  --port=PORT           SSH connection port
  -r, --reject-unknown-hosts
                        reject unknown hosts
  --sudo-password=SUDO_PASSWORD
                        password for use with sudo only
  --system-known-hosts=SYSTEM_KNOWN_HOSTS
                        load system known_hosts file before reading user
                        known_hosts
  -R ROLES, --roles=ROLES
                        comma-separated list of roles to operate on
  -s SHELL, --shell=SHELL
                        specify a new shell, defaults to &#39;/bin/bash -l -c&#39;
  --show=LEVELS         comma-separated list of output levels to show
  --skip-bad-hosts      skip over hosts that can&#39;t be reached
  --skip-unknown-tasks  skip over unknown tasks
  --ssh-config-path=PATH
                        Path to SSH config file
  -t N, --timeout=N     set connection timeout to N seconds
  -T N, --command-timeout=N
                        set remote command timeout to N seconds
  -u USER, --user=USER  username to use when connecting to remote hosts
  -w, --warn-only       warn, instead of abort, when commands fail
  -x HOSTS, --exclude-hosts=HOSTS
                        comma-separated list of hosts to exclude
  -z INT, --pool-size=INT
                        number of concurrent processes to use in parallel mode
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zookeeper笔记]]></title>
    <link href="http://dmlcoding.com/15205689785115.html"/>
    <updated>2018-03-09T12:16:18+08:00</updated>
    <id>http://dmlcoding.com/15205689785115.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">基础知识</h2>

<h3 id="toc_1">znode</h3>

<span id="more"></span><!-- more -->

<h3 id="toc_2">基础api</h3>

<pre><code># 创建一个test_node节点,并包含数据testdata
[zk: localhost:2181(CONNECTED) 12] create /test_note testdata
Created /test_note
[zk: localhost:2181(CONNECTED) 13] ls /test_note
[]
[zk: localhost:2181(CONNECTED) 14] get /test_note
testdata
cZxid = 0x1cc0015709f
ctime = Fri Mar 09 12:15:41 CST 2018
mZxid = 0x1cc0015709f
mtime = Fri Mar 09 12:15:41 CST 2018
pZxid = 0x1cc0015709f
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 8
numChildren = 0

[zk: localhost:2181(CONNECTED) 15] delete /test_note
[zk: localhost:2181(CONNECTED) 16] get /test_note
Node does not exist: /test_note

</code></pre>

<h2 id="toc_3">主-从模式的例子</h2>

<pre><code># -e 表示临时性
# 创建一个临时性的znode,节点名称为master_example ,数据为master1.example.com:2223
# 一个临时节点会在会话过期或关闭时自动被删除
create -e /master_example &quot;master1.example.com:2223&quot;

# 列出目录树
ls /

# 获取master_example znode的元数据和数据
get /master_example
</code></pre>

<p>如果再次执行创建master_example的命令会报<code>Node already exists: /master_example</code></p>

<pre><code># 在master_example上设置一个监视点
stat /master_example true
</code></pre>

]]></content>
  </entry>
  
</feed>
