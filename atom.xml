<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Time渐行渐远]]></title>
  <link href="http://dmlcoding.com/atom.xml" rel="self"/>
  <link href="http://dmlcoding.com/"/>
  <updated>2019-01-28T18:06:17+08:00</updated>
  <id>http://dmlcoding.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Pandas 中map, applymap and apply的区别]]></title>
    <link href="http://dmlcoding.com/15423390877662.html"/>
    <updated>2018-11-16T11:31:27+08:00</updated>
    <id>http://dmlcoding.com/15423390877662.html</id>
    <content type="html"><![CDATA[
<p>Summing up, apply works on a row / column basis of a DataFrame, applymap works element-wise on a DataFrame, and map works element-wise on a Series.</p>

<span id="more"></span><!-- more -->

<h1 id="toc_0">1.apply()</h1>

<p>当想让方程作用在一维的向量上时，可以使用apply来完成，如下所示</p>

<pre class="line-numbers"><code class="language-text">In [116]: frame = DataFrame(np.random.randn(4, 3), columns=list(&#39;bde&#39;), index=[&#39;Utah&#39;, &#39;Ohio&#39;, &#39;Texas&#39;, &#39;Oregon&#39;])

In [117]: frame
Out[117]: 
               b         d         e
Utah   -0.029638  1.081563  1.280300
Ohio    0.647747  0.831136 -1.549481
Texas   0.513416 -0.884417  0.195343
Oregon -0.485454 -0.477388 -0.309548

In [118]: f = lambda x: x.max() - x.min()

In [119]: frame.apply(f)
Out[119]: 
b    1.133201
d    1.965980
e    2.829781
dtype: float64

</code></pre>

<p>但是因为大多数的列表统计方程 (比如 sum 和 mean)是DataFrame的函数，所以apply很多时候不是必须的</p>

<h1 id="toc_1">2.applymap()</h1>

<p>如果想让方程作用于DataFrame中的每一个元素，可以使用applymap().用法如下所示</p>

<pre class="line-numbers"><code class="language-text">In [120]: format = lambda x: &#39;%.2f&#39; % x

In [121]: frame.applymap(format)
Out[121]: 
            b      d      e
Utah    -0.03   1.08   1.28
Ohio     0.65   0.83  -1.55
Texas    0.51  -0.88   0.20
Oregon  -0.49  -0.48  -0.31

</code></pre>

<h1 id="toc_2">3.map()</h1>

<p>map()只要是作用将函数作用于一个Series的每一个元素，用法如下所示</p>

<pre class="line-numbers"><code class="language-text">In [122]: frame[&#39;e&#39;].map(format)
Out[122]: 
Utah       1.28
Ohio      -1.55
Texas      0.20
Oregon    -0.31
Name: e, dtype: object
</code></pre>

<p>总的来说就是apply()是一种让函数作用于列或者行操作，applymap()是一种让函数作用于DataFrame每一个元素的操作，而map是一种让函数作用于Series每一个元素的操作</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Objective vs. Cost vs. Loss vs. Error Function]]></title>
    <link href="http://dmlcoding.com/15420931314995.html"/>
    <updated>2018-11-13T15:12:11+08:00</updated>
    <id>http://dmlcoding.com/15420931314995.html</id>
    <content type="html"><![CDATA[
<p><strong><u>The function we want to minimize or maximize is called the objective function, or criterion. When we are minimizing it, we may also call it the cost function, loss function, or error function - these terms are synonymous. The cost function is used more in optimization problem and loss function is used in parameter estimation.</u></strong></p>

<span id="more"></span><!-- more -->

<p>The loss function (or error) is for a single training example, while the cost function is over the entire training set (or mini-batch for mini-batch gradient descent). Therefore, a loss function is a part of a cost function which is a type of an objective function.  Objective function, cost function, loss function: are they the same thing? | </p>

<p>StackExchange</p>

<ul>
<li> Loss function is usually a function defined on a data point, prediction and label, and measures the penalty. For example:
<ul>
<li> square loss l(f(xi|θ),yi)=(f(xi|θ)−yi)2, used in linear regression</li>
<li> hinge loss l(f(xi|θ),yi)=max(0,1−f(xi|θ)yi), used in SVM</li>
<li> 0/1 loss l(f(xi|θ),yi)=1⟺f(xi|θ)≠yi, used in theoretical analysis and definition of accuracy</li>
</ul></li>
<li> Cost function is usually more general. It might be a sum of loss functions over your training set plus some model complexity penalty (regularization). For example:
<ul>
<li> Mean Squared Error MSE(θ)=1N∑Ni=1(f(xi|θ)−yi)2</li>
<li> SVM cost function SVM(θ)=∥θ∥2+C∑Ni=1ξi (there are additional constraints connecting ξi with C and with training set)</li>
</ul></li>
<li> Objective function is the most general term for any function that you optimize during training. For example, a probability of generating training set in maximum likelihood approach is a well defined objective function, but it is not a loss function nor cost function (however you could define an equivalent cost function). For example:
<ul>
<li> MLE is a type of objective function (which you maximize)</li>
<li>Divergence between classes can be an objective function but it is barely a cost function, unless you define something artificial, like 1-Divergence, and name it a cost</li>
</ul></li>
<li> Error function - Backpropagation; or automatic differentiation, is commonly used by the gradient descent optimization algorithm to adjust the weight of neurons by calculating the gradient of the loss function. This technique is also sometimes called backward propagation of errors, because the error is calculated at the output and distributed back through the network layers. Backpropagation | Wikipedia</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[将python生成的base64图片,在浏览器上展示出来]]></title>
    <link href="http://dmlcoding.com/15402913817590.html"/>
    <updated>2018-10-23T18:43:01+08:00</updated>
    <id>http://dmlcoding.com/15402913817590.html</id>
    <content type="html"><![CDATA[
<p>方便调试</p>

<pre class="line-numbers"><code class="language-text">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;show base64 pic&lt;/title&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id=&#39;root&#39;&gt;
        &lt;img src=&quot;data:image/png;base64,这里是base64的内容,替换掉即可(中文部分)&quot; /&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<span id="more"></span><!-- more -->

<pre class="line-numbers"><code class="language-text">#!/usr/bin/env python 

import base64

import pandas as pd
import pydotplus
from IPython.display import Image
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier

data = pd.read_csv(&quot;./datas/demos.csv&quot;)
train_data = data.drop(&quot;label&quot;, axis=1)
target = data[&quot;label&quot;]

DTmodel = DecisionTreeClassifier(max_depth=4)
DTmodel = DTmodel.fit(train_data, target)
print(DTmodel)

# 将决策树的图片转成base64
dot_data = tree.export_graphviz(DTmodel, out_file=None)
graph = pydotplus.graph_from_dot_data(dot_data)
pic_base64 = base64.b64encode(Image(graph.create_png()).data).decode(&#39;utf8&#39;)

print(pic_base64)

</code></pre>

<p>将打印出来的pic_base64的内容替换到html里面的中文部分,然后用浏览器打开这个html文件即可看到图片</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Isolation Forest]]></title>
    <link href="http://dmlcoding.com/15398508250689.html"/>
    <updated>2018-10-18T16:20:25+08:00</updated>
    <id>http://dmlcoding.com/15398508250689.html</id>
    <content type="html"><![CDATA[
<p>scikit-learn返回:是异常点(-1)或者不是异常点(1)</p>

<p><img src="media/15398508250689/15398521143637.jpg" alt=""/></p>

<p>孤立森林--&gt;查看数据页面,如上所示<br/>
原始数据的所有列,预测出来是否是异常值,也即是是否偏离(偏移即是-1),偏移度也就是decision_function算出来的值,返回样本的异常评分，值越小表示越有可能是异常样本<br/>
data,model.predict(X_train),model.decision_function(X_train)</p>

<pre class="line-numbers"><code class="language-text">df=pd.concat([pd.DataFrame(X_train),pd.Series(clf.predict(X_train)), pd.Series(clf.decision_function(X_train))], axis=1)

df.columns = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[聚类算法评估指标]]></title>
    <link href="http://dmlcoding.com/15396891344806.html"/>
    <updated>2018-10-16T19:25:34+08:00</updated>
    <id>http://dmlcoding.com/15396891344806.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">Not Given Label</h1>

<h2 id="toc_1">1、Compactness(紧密性)(CP)</h2>

<span id="more"></span><!-- more -->

<h1 id="toc_2">代码实现</h1>

<pre class="line-numbers"><code class="language-text"># -*- coding: utf-8 -*-
&#39;&#39;&#39;
    Created by hushiwei on 2018/10/16
    Desc : 进行聚类算法的评估指标计算
    Note : CP指数,SP指数,DB,DVI
&#39;&#39;&#39;

# 导入包
from numpy import *
import numpy as np
import pandas as pd
from sklearn.datasets import make_blobs  # 导入产生模拟数据的方法
from sklearn.cluster import KMeans  # 导入kmeans 类
import time
from MachineLearning.cluster_evaluate.calculate_dvi import dunn

def distEclud(vecA, vecB, axis=None):
    &#39;&#39;&#39;
    求两个向量之间的距离,计算欧几里得距离
    same as : np.linalg.norm(np.asarray(datas[0].iloc[0].values) - np.asarray(datas[0].iloc[1].values))
    :param vecA: 中心点
    :param vecB: 数据点
    :param axis: np.sum的参数
    :return:
    &#39;&#39;&#39;
    return np.sqrt(np.sum(np.power(vecA - vecB, 2), axis=axis))


def calculate_cp_i(cluster_center, cluster_point):
    &#39;&#39;&#39;
    计算聚类类各点到聚类中心的平均距离
    :param cluster_center: 聚类中心点
    :param cluster_point: 聚类样本点
    :return:
    &#39;&#39;&#39;
    return np.average(distEclud(cluster_center, cluster_point, axis=1))


def calculate_cp(cluster_centers, cluster_points):
    &#39;&#39;&#39;
    CP,计算每一个类各点到聚类中心的平均距离
    CP越低意味着类内聚类距离越近
    :param cluster_centers: 聚类中心点
    :param cluster_points: 聚类样本点
    :return:
    &#39;&#39;&#39;

    cps = [calculate_cp_i(cluster_centers[i], cluster_points[i]) for i in arange(len(cluster_centers))]
    cp = np.average(cps)
    return cp


def calculate_sp(cluster_centers):
    &#39;&#39;&#39;
    SP,计算各聚类中心两两之间的平均距离
    SP越高意味类间聚类距离越远
    :param cluster_centers:
    :return:
    &#39;&#39;&#39;
    k = len(cluster_centers)
    res = []
    for i in arange(k):
        tmp = []
        for j in arange(i + 1, k):
            tmp.append(distEclud(cluster_centers[i], cluster_centers[j]))
        res.append(np.sum(tmp))

    sp = (2 / (k * k - k)) * np.sum(res)
    return sp


def calculate_db(cluster_centers, cluster_points):
    &#39;&#39;&#39;
    DB,计算任意两类别的类内距离平均距离(CP)之和除以两聚类中心距离求最大值
    DB越小意味着类内距离越小 同时类间距离越大
    :param cluster_centers: 聚类中心点
    :param cluster_points: 聚类样本点
    :return:
    &#39;&#39;&#39;
    n_cluster = len(cluster_centers)
    cps = [calculate_cp_i(cluster_centers[i], cluster_points[i]) for i in arange(n_cluster)]
    db = []

    for i in range(n_cluster):
        for j in range(n_cluster):
            if j != i:
                db.append((cps[i] + cps[j]) / distEclud(cluster_centers[i], cluster_centers[j]))
    db = (np.max(db) / n_cluster)
    return db


def calculate_dvi(cluster_points):
    &#39;&#39;&#39;
    DVI计算,任意两个簇元素的最短距离(类间)除以任意簇中的最大距离(类内).
    DVI越大意味着类间距离越大 同时类内距离越小。
    :param cluster_points:
    :return:
    &#39;&#39;&#39;
    # calcuation of maximum distance
    d1 = []
    d2 = []
    d3 = []
    # 类内最大距离
    for k, cluster_point in cluster_points.items():
        # 遍历每一个簇中每一个元素
        for i in range(len(cluster_point)):
            temp1 = cluster_point.iloc[i].values
            for j in range(len(cluster_point)):
                temp2 = cluster_point.iloc[j].values

                # 求簇内两元素的距离
                dist = distEclud(temp1, temp2)
                d1.insert(j, dist)

            d2.insert(i, max(d1))
            d1 = []

        d3.insert(k, max(d2))
        d2 = []
    xmax = max(d3)

    # calcuation of minimun distance
    d1 = []
    d2 = []
    d3 = []
    d4 = []
    # 类间最小距离
    for k, cluster_point in cluster_points.items():
        # 遍历每一个簇中每一个元素
        for j in range(len(cluster_point)):
            temp1 = cluster_point.iloc[j].values
            for key in cluster_points.keys():
                if not key == k:
                    other_cluster_df = cluster_points[key]
                    for index in range(len(other_cluster_df)):
                        temp2 = other_cluster_df.iloc[index].values
                        dist = distEclud(temp1, temp2)
                        d1.insert(index, dist)

                    d2.insert(key, min(d1))
                    d1 = []
            d3.insert(j, min(d2))
            d2 = []
        d4.insert(k, min(d3))
    xmin = min(d4)

    dunn_index = xmin / xmax
    return dunn_index


if __name__ == &#39;__main__&#39;:
    # 1. 产生模拟数据
    N = 1000
    centers = 4
    X, Y = make_blobs(n_samples=N, n_features=2, centers=centers, random_state=28)
    # df = pd.DataFrame(X, columns=list(&#39;abcdefghij&#39;))
    # df.to_csv(
    #     &#39;/Users/hushiwei/PycharmProjects/gai_platform/data/data_spliter/local_debug_data/cluster_data/cluster_data.csv&#39;,
    #     sep=&#39;,&#39;, index=False)
    # sys.exit()

    # 2. 模型构建
    km = KMeans(n_clusters=centers, init=&#39;random&#39;, random_state=28)
    km.fit(X)

    # 模型的预测
    y_hat = km.predict(X[:10])
    print(y_hat)

    print(&quot;所有样本距离所属簇中心点的总距离和为:%.5f&quot; % km.inertia_)
    print(&quot;所有样本距离所属簇中心点的平均距离为:%.5f&quot; % (km.inertia_ / N))

    print(&quot;所有的中心点聚类中心坐标:&quot;)
    cluster_centers = km.cluster_centers_
    print(cluster_centers)

    print(&quot;score其实就是所有样本点离所属簇中心点距离和的相反数:&quot;)
    print(km.score(X))

    # 统计各个聚簇点的类别数目
    r1 = pd.Series(km.labels_).value_counts()

    kmlabels = km.labels_  # 得到类别，label_ 是内部变量
    X = pd.DataFrame(X, columns=list(&#39;ab&#39;))
    r = pd.concat([X, pd.Series(kmlabels, index=X.index)], axis=1)  # 详细输出每个样本对应的类别，横向连接（0是纵向），得到聚类中心对应的类别下的数目

    r.columns = list(X.columns) + [&#39;class&#39;]  # 重命名表头  加一列的表头
    print(r.head())

    # 根据聚类信息,将数据进行分类{聚类id:聚类点}
    cluster_centers = {k: value for k, value in enumerate(cluster_centers)}
    cluster_points = {label: r[r[&#39;class&#39;] == label].drop(columns=[&#39;class&#39;]) for label in np.unique(km.labels_)}

    print(&#39;~&#39; * 10, &#39;evaluate kmeans&#39;, &#39;~&#39; * 10)

    cp = calculate_cp(cluster_centers, cluster_points)
    print(&#39;cp : &#39;, cp)

    sp = calculate_sp(cluster_centers)
    print(&#39;sp : &#39;, sp)

    dp = calculate_db(cluster_centers, cluster_points)
    print(&#39;dp : &#39;, dp)

    start=time.time()
    # dvi = calculate_dvi(cluster_points)
    # print(&#39;dvi : &#39;, dvi)


    a = [point.values for point in cluster_points.values()]
    di=dunn(a)
    print(&#39;di : &#39;,di)

    print(&quot;dvi cost &quot;,time.time()-start)

</code></pre>

<p>dvi的计算,代码2</p>

<pre class="line-numbers"><code class="language-text"># -*- coding: utf-8 -*-
&#39;&#39;&#39;
    Created by hushiwei on 2018/10/23
    Desc : 计算dvi
    Note : 这个和那个,有区别
&#39;&#39;&#39;

import numpy as np
from sklearn.metrics.pairwise import euclidean_distances


def delta(ck, cl):
    values = np.ones([len(ck), len(cl)]) * 10000

    for i in range(0, len(ck)):
        for j in range(0, len(cl)):
            values[i, j] = np.linalg.norm(ck[i] - cl[j])

    return np.min(values)


def big_delta(ci):
    values = np.zeros([len(ci), len(ci)])

    for i in range(0, len(ci)):
        for j in range(0, len(ci)):
            values[i, j] = np.linalg.norm(ci[i] - ci[j])

    return np.max(values)


def dunn(k_list):
    &quot;&quot;&quot; Dunn index [CVI]

    Parameters
    ----------
    k_list : list of np.arrays
        A list containing a numpy array for each cluster |c| = number of clusters
        c[K] is np.array([N, p]) (N : number of samples in cluster K, p : sample dimension)
    &quot;&quot;&quot;
    deltas = np.ones([len(k_list), len(k_list)]) * 1000000
    big_deltas = np.zeros([len(k_list), 1])
    l_range = list(range(0, len(k_list)))

    for k in l_range:
        for l in (l_range[0:k] + l_range[k + 1:]):
            deltas[k, l] = delta(k_list[k], k_list[l])

        big_deltas[k] = big_delta(k_list[k])

    di = np.min(deltas) / np.max(big_deltas)
    return di


def delta_fast(ck, cl, distances):
    values = distances[np.where(ck)][:, np.where(cl)]
    values = values[np.nonzero(values)]

    return np.min(values)


def big_delta_fast(ci, distances):
    values = distances[np.where(ci)][:, np.where(ci)]
    values = values[np.nonzero(values)]

    return np.max(values)


def dunn_fast(points, labels):
    &quot;&quot;&quot; Dunn index - FAST (using sklearn pairwise euclidean_distance function)

    Parameters
    ----------
    points : np.array
        np.array([N, p]) of all points
    labels: np.array
        np.array([N]) labels of all points
    &quot;&quot;&quot;
    distances = euclidean_distances(points)
    ks = np.sort(np.unique(labels))

    deltas = np.ones([len(ks), len(ks)]) * 1000000
    big_deltas = np.zeros([len(ks), 1])

    l_range = list(range(0, len(ks)))

    for k in l_range:
        for l in (l_range[0:k] + l_range[k + 1:]):
            deltas[k, l] = delta_fast((labels == ks[k]), (labels == ks[l]), distances)

        big_deltas[k] = big_delta_fast((labels == ks[k]), distances)

    di = np.min(deltas) / np.max(big_deltas)
    return di


def big_s(x, center):
    len_x = len(x)
    total = 0

    for i in range(len_x):
        total += np.linalg.norm(x[i] - center)

    return total / len_x


def davisbouldin(k_list, k_centers):
    &quot;&quot;&quot; Davis Bouldin Index

    Parameters
    ----------
    k_list : list of np.arrays
        A list containing a numpy array for each cluster |c| = number of clusters
        c[K] is np.array([N, p]) (N : number of samples in cluster K, p : sample dimension)
    k_centers : np.array
        The array of the cluster centers (prototypes) of type np.array([K, p])
    &quot;&quot;&quot;
    len_k_list = len(k_list)
    big_ss = np.zeros([len_k_list], dtype=np.float64)
    d_eucs = np.zeros([len_k_list, len_k_list], dtype=np.float64)
    db = 0

    for k in range(len_k_list):
        big_ss[k] = big_s(k_list[k], k_centers[k])

    for k in range(len_k_list):
        for l in range(0, len_k_list):
            d_eucs[k, l] = np.linalg.norm(k_centers[k] - k_centers[l])

    for k in range(len_k_list):
        values = np.zeros([len_k_list - 1], dtype=np.float64)
        for l in range(0, k):
            values[l] = (big_ss[k] + big_ss[l]) / d_eucs[k, l]
        for l in range(k + 1, len_k_list):
            values[l - 1] = (big_ss[k] + big_ss[l]) / d_eucs[k, l]

        db += np.max(values)
    res = db / len_k_list
    return res
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[模型评估 K-S值和AUC的区别]]></title>
    <link href="http://dmlcoding.com/15395734385439.html"/>
    <updated>2018-10-15T11:17:18+08:00</updated>
    <id>http://dmlcoding.com/15395734385439.html</id>
    <content type="html"><![CDATA[
<p>在模型建立之后，必须对模型的效果进行评估，因为数据挖掘是一个探索的过程，评估-优化是一个永恒的过程。在分类模型评估中，最常用的两种评估标准就是K-S值和AUC值。</p>

<p>可能有人会问了，为什么不直接看正确率呢？你可以这么想，如果一批样本中，正样本占到90%，负样本只占10%，那么我即使模型什么也不做，把样本全部判定为正，也能有90%的正确率咯？所以，用AUC值够保证你在样本不均衡的情况下也能准确评估模型的好坏，而K-S值不仅能告诉你准确与否，还能告诉你模型对好坏客户是否有足够的区分度。</p>

<p>下面分别看两种评估指标的概念。</p>

<span id="more"></span><!-- more -->

<h1 id="toc_0">一、ROC曲线和AUC值</h1>

<p>在逻辑回归、随机森林、GBDT、XGBoost这些模型中，模型训练完成之后，每个样本都会获得对应的两个概率值，一个是样本为正样本的概率，一个是样本为负样本的概率。把每个样本为正样本的概率取出来，进行排序，然后选定一个阈值，将大于这个阈值的样本判定为正样本，小于阈值的样本判定为负样本，然后可以得到两个值，<strong>一个是真正率，一个是假正率。</strong></p>

<p>真正率即判定为正样本且实际为正样本的样本数/所有的正样本数，假正率为判定为正样本实际为负样本的样本数/所有的负样本数。每选定一个阈值，就能得到一对真正率和假正率，由于判定为正样本的概率值区间为[0,1]，那么阈值必然在这个区间内选择，因此在此区间内不停地选择不同的阈值，重复这个过程，就能得到一系列的真正率和假正率，以这两个序列作为横纵坐标，即可得到ROC曲线了。<strong>而ROC曲线下方的面积，即为AUC值。</strong></p>

<p>对于AUC值，也许有一个更直观的理解，那就是，在按照正样本概率值对所有样本排序后，任意选取一对正负样本，正样本排在负样本之前的概率值，即为AUC值。也就是说，当所有的正样本在排序后都能排在负样本之前时，就证明所有的样本都被正确分类了，此时的AUC值也会为1。那么AUC值也就很好算了，如果有N个负样本，其中正样本有M个，那么可取的所有带正样本的样本对数对于排在第一位的正样本来说，有M+N-1个，但其中包含M-1对（正，正）的样本，而对于后面所有的正样本而言，能够取到的正样本概率大于负样本对数肯定小于其位置-1。</p>

<h1 id="toc_1">K-S曲线</h1>

<p>KS(Kolmogorov-Smirnov)值越大，表示模型能够将正、负客户区分开的程度越大。KS值的取值范围是[0，1] </p>

<p>通常来讲，KS&gt;0.2即表示模型有较好的预测准确性。</p>

<p>K-S曲线其实数据来源和本质和ROC曲线是一致的，只是ROC曲线是把真正率和假正率当作横纵轴，而K-S曲线是把真正率和假正率都当作是纵轴，横轴则由选定的阈值来充当。</p>

<p>下面这一段解释得更详细的K-S和AUC的区别是参考的这篇博客：</p>

<p><a href="https://blog.csdn.net/sinat_30316741/article/details/80018932">https://blog.csdn.net/sinat_30316741/article/details/80018932</a></p>

<blockquote>
<p>由于ks值能找出模型中差异最大的一个分段，因此适合用于cut_off，像评分卡这种就很适合用ks值来评估。但是ks值只能反映出哪个分段是区分最大的，而不能总体反映出所有分段的效果，因果AUC值更能胜任。 <br/>
ROC值一般在0.5-1.0之间。值越大表示模型判断准确性越高，即越接近1越好。ROC=0.5表示模型的预测能力与随机结果没有差别。 <br/>
KS值表示了模型将+和-区分开来的能力。值越大，模型的预测准确性越好。一般，KS&gt;0.2即可认为模型有比较好的预测准确性。</p>
</blockquote>

<p>好了，引用结束。 <br/>
K-S值一般是很难达到0.6的，在0.2~0.6之间都不错。一般如果是如果负样本对业务影响极大，那么区分度肯定就很重要，此时K-S比AUC更合适用作模型评估，如果没什么特别的影响，那么用AUC就很好了。</p>

<h1 id="toc_2">三、KS的计算和曲线绘制</h1>

<p>代码如果要用，最好自己改改，因为这个数据格式是我自己用的，计算方式也是跟数据格式有关系的，工作中用的可能不一样，所以最好是自己根据自己的写一个，这个也只是我根据自己的数据格式来写的，重要的是思路，不是代码本身。而且我画的曲线是折线，最好是自己考虑写一个平滑曲线的。</p>

<pre class="line-numbers"><code class="language-text">import matplotlib.pyplot as plt
#第一个参数是模型的预测值，第二个参数是模型的真实值
def draw_ks_curve(predict_result,true_result):
    tpr_list = []  #存放真正率数据
    fpr_list = []  #存放假正率数据
    dif_list = []  #存放真假正率差值
    max_ks_dot = []

    for i in np.arange(0,1.1,0.1):
        tpr = 0
        fpr = 0
        for j in range(len(predict_result)):
            if list(predict_result[j])[0]&gt;i and true_result[j]==1:
               tpr = tpr+1
               tpr_list.append(tpr)
            if list(predict_result[j])[0]&gt;i and true_result[j]==0:
               fpr = fpr+1
               fpr_list.append(fpr)
        tpr = tpr/sum(true_result)
        fpr = fpr/(len(true_result)-sum(true_result))
    fig = plt.figure(num=1, figsize=(15, 8),dpi=80)     #开启一个窗口，同时设置大小，分辨率
    plt.plot(np.arange(0,1,0.1),tpr_list)
    plt.plot(np.arange(0,1,0.1),fpr_list)

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mac 下高速免费下载百度云文件]]></title>
    <link href="http://dmlcoding.com/15343116796404.html"/>
    <updated>2018-08-15T13:41:19+08:00</updated>
    <id>http://dmlcoding.com/15343116796404.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">下载安装Aira2客户端</h1>

<p>地址: <a href="https://github.com/yangshun1029/aria2gui/releases">https://github.com/yangshun1029/aria2gui/releases</a></p>

<span id="more"></span><!-- more -->

<p><img src="media/15343116796404/15343175848538.jpg" alt="" style="width:900px;"/></p>

<h1 id="toc_1">安装Ghrome插件 BaiduExporter</h1>

<p>下载地址: <a href="https://github.com/acgotaku/BaiduExporter/archive/master.zip">https://github.com/acgotaku/BaiduExporter/archive/master.zip</a></p>

<p>这个只能这样安装<br/>
<img src="media/15343116796404/15343119219617.jpg" alt="" style="width:941px;"/></p>

<p><img src="media/15343116796404/15343119745283.jpg" alt="" style="width:1343px;"/><br/>
<img src="media/15343116796404/15343122583040.jpg" alt="" style="width:614px;"/></p>

<p><img src="media/15343116796404/15343121945795.jpg" alt="" style="width:743px;"/></p>

<p>ok,搞定了</p>

<h1 id="toc_2">总结</h1>

<p>所有的包上传百度云备份一份</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[windows10和mac共享文件]]></title>
    <link href="http://dmlcoding.com/15317970391028.html"/>
    <updated>2018-07-17T11:10:39+08:00</updated>
    <id>http://dmlcoding.com/15317970391028.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">一,windows10访问mac电脑</h1>

<h2 id="toc_1">1,先新建一个用于共享的登录账户</h2>

<p>在系统偏好设置-&gt;用户与群组-&gt;点击黄色的锁-&gt;输入当前账户密码-&gt;点击左侧➕ ,新建一个<em>仅限共享</em>的用户(注意:是将普通账户改为仅限共享,记住密码)。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_2">2,开启共享</h2>

<p>系统偏好设置 -&gt; 共享 -&gt; 点开黄色的锁输入密码 -&gt; 勾选文件共享和远程登录 -&gt; 选中共享文件 -&gt; 点击共享文件夹的➕，添加要共享的文件夹 -&gt; 点击用户➕添加新建的第1步中添加的帐号 -&gt; 点击选项勾选使用SMB -&gt; 勾选windows文件共享中的新添加的账户点击完成.</p>

<h2 id="toc_3">3,将mac加入到windows的工作组中</h2>

<p>系统偏好设置-&gt;网络-&gt;选择你所要设置的网络-右侧下方的高级按钮-wins选项卡.注意工作组要在windows上查找，wins服务器也要在windows上查找匹配。</p>

<h2 id="toc_4">4,windows中访问共享文件</h2>

<p>windows+R -&gt; 输入:&quot;\mac ip地址&quot; ,如 \192.168.1.102 -&gt; 在弹出的对话框中输入mac中添加的账户和密码就能访问了.</p>

<h1 id="toc_5">二，Mac访问windows10:</h1>

<h2 id="toc_6">1,打开共享设置</h2>

<p>1，控制面板-&gt; 网络和Internet -&gt; 网络和共享中心 -&gt; 高级共享设置 中专用和所有网络的都开启共享的设置.<br/>
2，文件资源管理器（默认选中快速访问）-&gt; 查看 -&gt; 选项 -&gt; 查看 -&gt; 勾选 使用共享向导(推荐).</p>

<h2 id="toc_7">2,在windows上新建用于mac登录的账户</h2>

<p>windows+R -&gt; 输入:netplwiz -&gt; 点击添加 -&gt; 选择不使用Microsoft帐户 -&gt; 本地账户 -&gt; 输入用户名，密码等信息（注意记住用于mac登录）.</p>

<h2 id="toc_8">3,设置要共享的文件夹</h2>

<p>1,选中文件夹右键 -&gt; 属性 -&gt; 共享 -&gt; 高级共享 -&gt; 勾选共享此文件夹 -&gt; 选中权限 进行相应的权限设置 -&gt; 点击应用，确定.<br/>
2,再次右键要共享的文件夹 -&gt; 属性 -&gt; 共享 -&gt; 共享(s) -&gt; 下拉箭头，添加之前第2部中增加的账户 -&gt; 设置权限级别.</p>

<h2 id="toc_9">4,mac中访问windows中的共享文件夹</h2>

<p>点击Finder -&gt; 左侧会有共享的设备 -&gt; 点击 连接身份 -&gt;输入第2步中创建的账户名和密码就可以访问了.</p>

<h2 id="toc_10">注意:</h2>

<p>2.3.4步就可以了</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HMM(摘自:统计学习方法)]]></title>
    <link href="http://dmlcoding.com/15299155104492.html"/>
    <updated>2018-06-25T16:31:50+08:00</updated>
    <id>http://dmlcoding.com/15299155104492.html</id>
    <content type="html"><![CDATA[
<p>HMM(隐马尔可夫模型的定义):隐马尔可夫模型是关于时序的概率模型,描述由一个隐藏的马尔可夫链随机生成不可观察的状态随机序列,再由各个状态生成一个观测而产生观测随机序列的过程.隐藏的马尔可夫链随机生成的状态的序列,称为状态序列(state sequence);每个状态生成一个观测,而由此产生的观测的随机序列,称为观测序列(observation sequence).序列的每一个位置又可以看作是一个时刻.</p>

<span id="more"></span><!-- more -->

<p><img src="media/15299155104492/15299160364725.jpg" alt=""/></p>

<h1 id="toc_0">隐马尔可夫模型的相关定义</h1>

<p>隐马尔可夫模型由初始概率分布,状态转移概率分布以及观测概率分布确定.隐马尔可夫模型的形式定义如下:<br/>
   设Q是所有可能的状态集合,V是所有可能的观测的集合,其中,N是可能的状态数,M是可能的观测数.</p>

<p>\[\begin{aligned}<br/>
   Q &amp; = {q_1,q_2,\cdots,q_N}  &amp;\text{Q是所有可能的状态集合} \\<br/>
   V &amp; = {v_1,v_2,\cdots,v_M} &amp; \text{V是所有可能的观测的集合} <br/>
\end{aligned}\]</p>

<p>I是长度为T的状态序列,O是对应的观测序列<br/>
  \[\begin{aligned}<br/>
   I &amp; = {i_1,i_2,\cdots,i_T}  &amp;\text{I是长度为T的状态序列} \\<br/>
   O &amp; = {o_1,o_2,\cdots,o_T} &amp; \text{O是对应的长度为T的观测序列} <br/>
\end{aligned}\]</p>

<p>A是状态转移概率矩阵:<br/>
\[A=[a_{ij}]_{N*N} \\\<br/>
其中,a_{ij}=P(i_{t+1}=q_j|i_t=q_i),\qquad i=1,2,\cdots,N;j=1,2,\cdots,N \\\<br/>
表示在时刻t处于状态q_i的条件下在时刻t+1转移到状态q_j的概率\]</p>

<p>B是观测概率矩阵:<br/>
\[B=[b_j(k)]_{N*M} \\\<br/>
其中,b_j(k)=P(o_t=v_k|i_t=q_j),\qquad k=1,2,\cdots,M;j=1,2,\cdots,N \\\<br/>
表示在时刻t处于状态q_j的条件下生成观测v_k的概率\]</p>

<p>\(\pi\)是初始状态概率向量<br/>
\[\pi=(\pi_i) \\\<br/>
其中,\pi_i=P(i_1=q_i),\qquad i=1,2,\cdots,N \\\<br/>
表示在时刻t=1处于状态q_i的概率\]</p>

<p>隐马尔可夫模型由初始状态概率向量\(\pi\),状态转移概率矩阵A和观测概率矩阵B决定,\(\pi\)和A决定状态序列,B决定观测序列.因此,隐马尔可夫模型\(\lambda\)可以用三元符合表示,即<br/>
\[\lambda=(\pi,A,B) \\\<br/>
A,B,\pi 称为隐马尔可夫模型的三要素\]</p>

<p>状态转移概率矩阵A与初始状态概率向量\(\pi\)确定了隐藏的马尔可夫链,生成不可观测的状态序列.观测概率矩阵B确定了如何从状态生成观测,与状态序列综合确定了如何产生观测序列.</p>

<p>从定义可知,隐马尔可夫模型作了两个基本假设:<br/>
(1)齐次马尔可夫假设,即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于前一时刻的状态,与其他时刻的状态及观测无关,也与时刻t无关.<br/>
   \[P(i_t|i_{t-1},o_{t-1},\cdots,i_1,o_1)=P(i_t|i_{t-1}),t=1,2,\cdots,T\]<br/>
(2)观测独立性假设,即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态,与其他观测及状态无关.<br/>
\[P(o_t|i_T,o_T,i_{T-1},o_{T-1},\cdots,i_{t+1},o_{t+1},i_t,o_t,i_{t-1},o_{t-1},\cdots,i_1,o_1)=P(o_t|i_t)\]</p>

<p>观测序列的生成过程</p>

<p>根据隐马尔可夫模型定义,可以将一个长度为T的观测序列\(O=(o_1,o_2,\cdots,o_T)\)的生成过程描述如下:<br/>
输入:隐马尔可夫模型\(\lambda=(A,B,\pi)\),观测序列长度T;<br/>
输出:观测序列\(O=(o_1,o_2,\cdots,o_T)\)<br/>
(1) 按照初始状态分布\(\pi\)产生状态\(i_1\)<br/>
(2) 令t=1<br/>
(3) 按照状态\(i_t\)的观测概率分布\(b_{i_t}(k)生成o_t\)<br/>
(4) 按照状态\(i_t\)的状态转移概率分布\({a_{i_t j_{t+1}}}产生状态i_{t+1},i_{t+1}=1,2,\cdots,N\)<br/>
(5) 令t=t+1;如果t&lt;T,转步(3);否则,终止</p>

<h1 id="toc_1">前向算法</h1>

<p>首先定义前向概率:给定隐马尔可夫模型\(\lambda\),定义到时刻t部分观测序列\(o_1,o_2,\cdots,o_t\)且状态为\(q_i\)的概率为前向概率,记作<br/>
\[\alpha_t(i)=P(o_1,o_2,\cdots,o_t,i_t=q_i|\lambda)\]<br/>
可以递推地求得前向概率\( \alpha_t(i)\) 及观测序列概率 \(P(O|\lambda)\)</p>

<p><strong>观测序列概率的前向算法:</strong><br/>
输入:隐马尔可夫模型\(\lambda\),观测序列O;<br/>
输出:观测序列概率\(P(O|\lambda)\)<br/>
(1) 初值<br/>
\[\alpha_1(i)=\pi_ib_i(o_1),\qquad  i=1,2,\cdots,N\]<br/>
(2) 递推 <br/>
\[对t=1,2,\cdots,T-1, \\\<br/>
\alpha_{t+1}(i)= \bigg[\sum_{j=1}^N\alpha_t(j)\alpha_{ji} \bigg] b_i(\alpha_{t+1}),\qquad i=1,2,\cdots,N\]<br/>
(3) 终止<br/>
\[P(O|\lambda)=\sum_{i=1}^N\alpha_T(i)\]</p>

<p>前向算法,步骤(1)初始化前向概率,是初始时刻的状态\(i_1=q_i\)和观测\(o_1\)的联合概率.步骤(2)是前向概率的递推公式,计算到时刻t+1部分观测序列为\(o_1,o_2,\cdots,o_t,o_{t+1}\)且在时刻t+1处于状态\(q_i\)的前向概率,</p>

<p><img src="media/15299155104492/15299161632092.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EM算法]]></title>
    <link href="http://dmlcoding.com/15299156181001.html"/>
    <updated>2018-06-25T16:33:38+08:00</updated>
    <id>http://dmlcoding.com/15299156181001.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[拉格朗日乘子法&KKT条件]]></title>
    <link href="http://dmlcoding.com/15289333499679.html"/>
    <updated>2018-06-14T07:42:29+08:00</updated>
    <id>http://dmlcoding.com/15289333499679.html</id>
    <content type="html"><![CDATA[
<p>如果不理解拉格朗日乘子法和KKT条件的相关原理,则不可能真正理解SVM的计算方法.</p>

<p>这是我们学习SVM的大前提</p>

<h1 id="toc_0">优化问题</h1>

<p>通常,我们要求解的函数优化问题,大致可分为以下3类</p>

<ul>
<li>无约束条件的优化问题:<br/>
\[min f(X)\]</li>
<li>只有等式约束的优化问题:<br/>
\[min f(X) \\\<br/>
s.t: h_i(X)=0,i \in {1,2,...,n}\]</li>
<li><p>含有不等式约束的优化问题:<br/>
\[min f(X) \\\<br/>
s.t: h_i(X)=0,i \in {1,2,...,n} \\\<br/>
     g_j(X) \leq 0, j \in {1,2,...,n} \]</p>
<span id="more"></span><!-- more -->        </li>
</ul>

<p>其中大写的X表示所有自变量的集合(也可以说是所有样本点的集合),\(h_i(X)\)表示等式约束条件,\(g_i(X)\)表示不等式约束条件.这里用\(min f(X)\)表示求取最优值的目标函数,其实不一定是求取最小值,求最大值也是可以的(取相反数即可).但是一般最优化都是取小值.</p>

<p>注意:默认所有解决的最优问题都是凸优化问题(即求取凸函数的最优解).拉格朗日乘子法一定是适用于凸优化问题,而不一定适用于其他非凸问题.</p>

<p>回到最上面的三类优化问题,解决方法是明确的,参考如下(注意:默认都是针对凸优化问题):</p>

<ul>
<li>对于无约束条件的优化问题,直接对其各个自变量求导,令导数为0,得全局最优解.</li>
<li>对于只有等式约束的优化问题,利用拉格朗日乘子法,得到全局最优解.</li>
<li>对于含不等式约束的优化问题,利用KKT条件,得全局最优解.</li>
</ul>

<h1 id="toc_1">拉格朗日乘子法</h1>

<p>举个例子来描述拉格朗日乘子法的基本思路:<br/>
\[min f(X)=2x_1^2+3x_2^2+7x_3^2 \\\<br/>
s.t : 2x_1+x_2=1,\quad 2x_2+3x_3=2\]</p>

<p>这个例子正式只有等式约束条件的优化问题,求解思路如下:<br/>
首先想到直接对3个自变量分别求偏导,令其偏导数都为0,则此时\(x_1,x_2,x_3\)都是0,看函数也是这样,当3个自变量都是0时,函数取得最小值0.但是这显然不符合约束条件的.</p>

<p>怎么把约束条件考虑进去呢?用拉格朗日乘子法,把改写后的约束条件乘以一个系数,然后以加的形式带入目标函数,该函数称之为拉格朗日函数.先看看改写后的约束条件:<br/>
\[s.t : 2x_1+x_2-1=0,\quad 2x_2+3x_3-2=0\]<br/>
左右移项,实际上没发生任何变化.其后,将改写后的约束条件带入目标函数,构造拉格朗日函数:<br/>
\[L(X,\alpha)=2x_1^2+3x_2^2+7x_3^2+\alpha_1(2x_1+x_2-1)+\alpha_2(2x_2+3x_3-2)\]</p>

<p>可见,当求得的最优解满足约束条件时,\(L(x,\alpha)\)与原始的目标函数并没有差别(后面都是0).这样,我们再对这个拉格朗日函数求关于各个自变量的偏导,并令这些偏导数为0.<br/>
\[<br/>
\begin{aligned}<br/>
\dfrac{\partial f(X)}{\partial x_1} &amp; =4x_1+2\alpha_1=0 \implies  x_1=-\frac12\alpha_1 \\<br/>
 \dfrac{\partial f(X)}{\partial x_2} &amp; =6x_2+\alpha_1+2\alpha_2=0 \implies  x_2=-\frac16\alpha_1 - \frac13\alpha_2 \\ <br/>
\dfrac{\partial f(X)}{\partial x_3} &amp; =14x_3+3\alpha_2=0 \implies  x_3=-\frac{3}{14}\alpha_2<br/>
\end{aligned}\]</p>

<p>现在,将用系数\(\alpha_1,\alpha_2\)表示的3个自变量带入约束条件,可得如下方程:<br/>
\[<br/>
\begin{aligned}<br/>
-\dfrac{7}{6}\alpha1 - \dfrac{1}{3}\alpha_2 -1 &amp; =0 \\<br/>
-\dfrac{1}{3}\alpha1 - \dfrac{55}{44}\alpha_2 -2 &amp; =0 <br/>
\end{aligned}\]</p>

<p>两个未知数,两个方程,可以求解得到\(\alpha_1=-0.45,\alpha_2=-1.41\),再带入自变量的表达式,即求得最优解.</p>

<h1 id="toc_2">拉格朗日乘子法的形式化描述</h1>

<p>用拉格朗日乘子法解决只有等式约束条件的优化问题,可以被如下形式化的描述:<br/>
现有优化问题:<br/>
    \[min f(X) \\<br/>
    s.t: h_i(X)=0,i \in {1,2,...,n}\]<br/>
则需要先得到拉格朗日函数\(L(X,\alpha)=f(X)+\sum_{i=1}^n \alpha_i \cdot h_i(X)\),对该函数的各个自变量求偏导,令偏导数为0,则可以求出各个自变量的含系数\(\alpha\)的代数式,再带入约束条件,解得\(\alpha\)后,可最终得到最优解.</p>

<h1 id="toc_3">KKT条件</h1>

<p>上面说的拉格朗日乘子法,解决的是只有等式约束条件的优化问题,而现实中更普遍的情况是求解含有不等式约束条件的问题.</p>

<p>还是通过一个例子讲解,优化问题如下:<br/>
\[min f(X)=x_1^2-2x_1+1+x_2^2+4x_2+4 \\\<br/>
s.t : x_1+10x_2 &gt; 10 \\\<br/>
10x_1-x_2 &lt; 10\]</p>

<p>第一步:把约束条件改写如下:<br/>
\[s.t : 10-x_1-10x_2&lt;0 \\\<br/>
10x_1-x_2-10&lt;0\]</p>

<p>改写的目的是方便后面的计算,且这种改写没有改变约束条件本身,所以不影响.</p>

<p>第二步:与拉格朗日乘子法相同,给约束条件乘以系数后加入目标函数,构成拉格朗日函数\(L(X,\beta)\)<br/>
\[L(X,\beta)=x_1^2-2x_1+1+x_2^2+4x_2+4+\beta_1(10-x_1-10x_2)+\beta_2(10x_1-x_2-10)\]</p>

<p>第三步:对拉格朗日函数的各个自变量求偏导:<br/>
\[<br/>
\begin{aligned}<br/>
\dfrac{\partial f(X)}{\partial x_1} &amp; =2x_1-\beta_1+10\beta_2 -2 \\<br/>
 \dfrac{\partial f(X)}{\partial x_2} &amp; =2x_2-10\beta_1-10\beta_2+4<br/>
\end{aligned}\]</p>

<p>做完以上3步,先不往下进行了.先给出KKT条件的形式化描述如下.</p>

<h1 id="toc_4">KKT条件的形式化描述</h1>

<p>KKT条件用于解决带有不等式约束条件的优化问题,可以被如下形式化描述:<br/>
现有优化问题:<br/>
\[min f(X) \\\<br/>
    s.t: h_i(X)=0,i \in {1,2,...,n} \\\<br/>
         g_j(X) \leq 0, j \in {1,2,...,n} \]<br/>
根据这个优化问题可以得到拉格朗日函数:<br/>
\[L(X,\alpha,\beta)=f(X)+\sum_{i=1}^m\alpha_i \cdot h_i(X)+\sum_{j=1}^m\beta_j \cdot g_j(X)\]</p>

<p>那么KKT条件就是函数的最优值必定满足下面3个条件(这3个条件是重点中的重点)</p>

<ul>
<li>\(L(X,\alpha,\beta)\)对各个自变量求导为0</li>
<li>h(X)=0</li>
<li>\(\sum_{i=1}^m\beta_j \cdot g_j(X)=0,\beta_j \geq 0\)</li>
</ul>

<p>3个条件中,前两个很好理解,不说了.关键在于第3个条件,这也是这篇文章中最难理解的部分.我尝试解释一下这个条件的原理.</p>

<p>首先,我们已知\(\beta_j \geq0,而g_j(X)\leq 0\)(这样设计的目的是要求目标函数的梯度和约束条件的梯度必须反向).也就是说,想要条件3成立,则每一项\(\beta_j \cdot g_j(X)都等于0\),再换个说法,对于每一项来说,要么\(\beta_j=0\),要么\(g_j(X)=0\).这就是条件3所要表达的真实含义.</p>

<p>下面解释为什么这样的条件可以用来寻找最优解.</p>

<p>假设X由2个自变量\(x_1,x_2\)组成,那么我们很容易想象出目标函数f(X)的图像,它就是一个三维空间中的曲面;再假设此时优化问题有3个不等式约束条件\(g_1(X),g_2(X),g_3(X)\).那现在可以把优化问题的图像画出来,如下图所示.画的是该问题再\(x_1 x_2\)平面上的投影,虚线为f(X)的等高线,那现在就有左图和右图两种不同情况了.<br/>
<img src="media/15289333499679/15289408757643.jpg" alt=""/></p>

<p>左图表示的是min f(X)在不等式的约束范围内,且不在不等式的约束面上.这时,f(X)的最优解与不等式的约束实际上没关系了,我们就令\(\beta_1=\beta_2=\beta3=0\)成立,而且此时,\(L(X,\alpha,\beta)\)对各个自变量求导为0的解就是最优解.换句话说,这种情况需要条件1,3同时成立.</p>

<h1 id="toc_5">参考</h1>

<p><a href="https://blog.csdn.net/on2way/article/details/47729419">https://blog.csdn.net/on2way/article/details/47729419</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SVM(支持向量机)]]></title>
    <link href="http://dmlcoding.com/15285262100303.html"/>
    <updated>2018-06-09T14:36:50+08:00</updated>
    <id>http://dmlcoding.com/15285262100303.html</id>
    <content type="html"><![CDATA[
<p>支持向量机(Support Vecor Machine,SVM)本身是一个<strong>二元分类算法</strong>,是对感知器算法模型的一种扩展,现在的SVM算法支持线性分类和非线性分类的分类应用,并且也能够直接将SVM应用于回归应用中.同时通过OvR或者OvO的方式我们也可以将SVM应用在多元分类领域中.在不考虑集成算法,不考虑特定的数据集的时候,在分类算法中SVM可以说是特别优秀的.</p>

<p><strong>线性可分(Linearly Separable)</strong>:在数据集中,如果可以找出一个超平面,将两组数据分开,那么这个数据集叫做线性可分数据.</p>

<p><strong>线性不可分(Linear Inseparable)</strong>:在数据集中,没法找出一个超平面,能够将两组数据分开,那么这个数据集就叫做线性不可分数据.</p>

<p><strong>分割超平面(Separating Hyperplane)</strong>:将数据集分割开来的直线/平面叫做分割超平面.</p>

<p><strong>间隔(Margin)</strong>:数据点到分割超平面的距离称为间隔.</p>

<p><strong>支持向量(Support Vector)</strong>:离分割超平面最近的那些点叫做支持向量.</p>

<span id="more"></span><!-- more -->

<h1 id="toc_0">线性可分SVM</h1>

<p>在感知器模型中,算法是在数据中找出一个划分超平面,让尽可能多的数据分布在这个平面的两侧,从而达到分类的效果,但是在实际数据中这个符合我们要求的超平面是可能存在多个的.<br/>
<img src="media/15285262100303/15285276077823.jpg" alt=""/></p>

<p>在感知器模型中,我们可以找到多个可以分类的超平面将数据分开,并且优化时希望所有的点都离超平面尽可能的远,但是实际上离超平面足够远的点基本上都是被正确分类的,所以这个是没有意义的;反而比较关心那些离超平面很近的点,这些点比较容易分错.所以说我们只要让离超平面比较近的点尽可能的远离这个超平面,那么我们的模型分类效果应该就会比较不错了.(这个就是SVM的思想)<br/>
<img src="media/15285262100303/15285279858682.jpg" alt=""/></p>

<h2 id="toc_1">超平面和法向量</h2>

<p>先回顾一下同济高数上的一个例题,求解点到平面的距离.<br/>
<img src="media/15285262100303/15285475518085.jpg" alt=""/></p>

<p>常见的平面概念是在三维空间中定义的:\(Ax+By+Cz+D=0\).<br/>
而d维空间中的超平面由下面的方程确定:\(w^Tx+b=0\),其中w和x都是d维列向量,\(x=(x_1,x_2,...,x_d)^T\)为平面上的点,\(w=(w_1,w_2,...,w_d)^T\)为平面的法向量.b是一个实数,代表平面与原点之间的距离.</p>

<p><strong>点到超平面的距离</strong></p>

<p>假设点\(x^{&#39;}为超平面A:w^Tx+b=0上的任意一点,则点x到A的距离为x-x^{&#39;}在超平面法向量w上的投影长度:\)</p>

<p>\[d=\dfrac{|w^T(x-x^{&#39;})|}{||w||}=\dfrac{|w^Tx+b|}{||w||} \qquad 注意:w^Tx^{&#39;}=-b,x^{&#39;}为超平面上一点\]</p>

<p>这里,\(||w||是w的L_2范数\)</p>

<p><strong>超平面的正面和反面</strong><br/>
一个超平面可以将它所在的空间分为两半,它的法向量指向的那一半对应的一面是它的正面,另一面则是它的反面.</p>

<p><strong>法向量的意义</strong><br/>
法向量的大小是坐标原点到分离超平面的距离,垂直于分离超平面,方向由分离超平面决定.</p>

<h2 id="toc_2">线性可分SVM</h2>

<p>支持向量到超平面的距离为:<br/>
\[\because w^Tx+b=\pm1 \\\<br/>
\because y \in \{+1,-1\} \\\<br/>
\therefore \dfrac{|y(w^Tx+b)|}{||w||}=\dfrac{1}{||w||}\]</p>

<p>备注:在SVM中支持向量到超平面的函数距离一般设置为1<br/>
<img src="media/15285262100303/15285491659569.jpg" alt=""/></p>

<p>SVM模型是让所有的分类点在各自类别的支持向量的两边,同时要求支持向量尽可能的远离这个超平面,用数学公式表示如下:</p>

<p>注意:<br/>
\[<br/>
\begin{cases}<br/>
w^T=(w_1,w_2,\cdots,w_n)\\\ <br/>
||w||=\sqrt{w_1^2+w_2^2+\cdots+w_n^2}<br/>
\end{cases}<br/>
\]</p>

<p>\[<br/>
\begin{cases}<br/>
\max \limits_{w,b}\dfrac{1}{||w||} &amp;\text {目标}\\\ <br/>
s.t:y^{(i)}\left(w^Tx^{(i)}+b\right) \geq 1,i=1,2,...,m &amp;\text {限制条件}<br/>
\end{cases}<br/>
\]</p>

<p>一般求最优化问题,都是求最小值,因此稍微将这个优化问题转换一下<br/>
\[<br/>
\begin{cases}<br/>
\min \limits_{w,b}\dfrac12||w||^2 &amp;\text {目标}\\\ <br/>
s.t:y^{(i)}\left(w^Tx^{(i)}+b\right) \geq 1,i=1,2,...,m &amp;\text {限制条件}<br/>
\end{cases}<br/>
\]</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[聚类算法]]></title>
    <link href="http://dmlcoding.com/15284222434956.html"/>
    <updated>2018-06-08T09:44:03+08:00</updated>
    <id>http://dmlcoding.com/15284222434956.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h1 id="toc_0">什么是聚类算法</h1>

<h1 id="toc_1">聚类算法的度量</h1>

<h1 id="toc_2">聚类的思想</h1>

<h1 id="toc_3">K-Means算法</h1>

<h1 id="toc_4">K-Means++算法</h1>

<h1 id="toc_5">K-Means||算法</h1>

<h1 id="toc_6">Canopy算法</h1>

<h1 id="toc_7">Mini Batch K-Means算法</h1>

<h1 id="toc_8">聚类算法的衡量指标</h1>

<h1 id="toc_9">层次聚类方法</h1>

<p>层次聚类方法对给定的数据集进行层次的分解,直到满足某种条件为止,传统的层次聚类算法主要分为两大类算法:<br/>
凝聚的层次聚类(AGNES算法:AGglomerative NESting):采用自底向上的策略.最初将每个对象作为一个簇,然后这些簇根据某些准则被一步一步合并,两个簇间的距离可以由这两个不同簇中距离最近的数据点的相似度来确定;聚类的合并过程反复进行直到所有的对象满足簇数目.</p>

<p>分裂的层次聚类(DIANA算法:DIvisive ANALysis):采用自顶向下的策略.首先将所有对象置于一个簇中,然后按照某种既定的规则逐渐细分为越来越小的簇(比如最大的欧式距离),直到达到某个终结条件(簇数目或者簇距离达到阈值).</p>

<p>AGNES和DIANA算法优缺点:</p>

<ul>
<li>简单,理解容易</li>
<li>合并点/分裂点选择不太容易</li>
<li>合并/分类的操作不能进行撤销</li>
<li>大数据集不太适合</li>
<li>执行效率较低</li>
</ul>

<p>AGNES算法中簇间距离</p>

<ul>
<li>最小距离(SL聚类)
<ul>
<li>两个聚簇中最近的两个样本之间的距离(single/word-linkage聚类法)</li>
<li>最终得到模型容易形成链式结构</li>
</ul></li>
<li>最大距离(CL聚类)
<ul>
<li>两个聚簇中最远的两个样本的距离(complete-linkage聚类法)</li>
<li>如果存在异常值,那么构建可能不太稳定</li>
</ul></li>
<li>平均距离(AL聚类)
<ul>
<li>两个聚类中样本间两两距离的平均值(average-linkage聚类法)</li>
<li>两个聚簇中样本间两两距离的中值(median-linkage聚类法)</li>
</ul></li>
</ul>

<h1 id="toc_10">密度聚类方法</h1>

<h1 id="toc_11">谱聚类</h1>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[集成学习]]></title>
    <link href="http://dmlcoding.com/15255701784620.html"/>
    <updated>2018-05-06T09:29:38+08:00</updated>
    <id>http://dmlcoding.com/15255701784620.html</id>
    <content type="html"><![CDATA[
<p>集成学习的思想是将若干个学习器(分类器&amp;回归器)组合之后产生一个新学习器.弱分类器(weak learner)指那些分类准确率只稍微好于随机猜测的分类器(error rate&lt; 0.5).</p>

<p>集成算法的成功在于保证弱分类器的多样性(Diversity).而且集成不稳定的算法也能够得到一个比较明显的性能提升.</p>

<p>常见的集成学习思想有:</p>

<ul>
<li>Bagging</li>
<li>Boosting</li>
<li>Stacking</li>
</ul>

<span id="more"></span><!-- more -->

<h2 id="toc_0">为什么需要集成学习</h2>

<ol>
<li>弱分类器间存在一定的差异性,这会导致分类的边界不同,也就是说可能存在错误.那么将多个弱分类器合并后,就可以得到更加合理的边界,减少整体的错误率,实现更好的效果.</li>
<li>对于数据集过大或者过小,可以分别进行划分和有放回的操作产生不同的数据子集,然后使用数据子集训练不同的分类器,最终再合并成为一个大的分类器.</li>
<li>如果数据的划分边界过于复杂,使用线性模型很难描述情况,那么可以训练多个模型,然后再进行模型的融合.</li>
<li>对于多个异构的特征集的时候,很难进行融合,那么可以考虑每个数据集构建一个分类模型,然后将多个模型融合.</li>
</ol>

<h1 id="toc_1">Bagging方法</h1>

<p>Bagging方法又叫自举汇聚法(Bootstrap Aggregating),思想是:在原始数据集上通过有放回的抽样的方式,重新选择出S个新数据集来分别训练S个分类器的集成技术.也就是说这些模型的训练数据中允许存在重复数据.</p>

<p>Bagging方法训练出来的模型在预测新样本分类的时候,会使用<strong>多数投票</strong>或者求<strong>均值</strong>的方式来统计最终的分类结果.</p>

<p>Bagging方法的弱学习器可以是基本的算法模型,eg:Linear,Ridge,Lasso,Logistic,Softmax,ID3,C4.5,CART,SVM,KNN等</p>

<p>备注:Bagging方式是有放回的抽样,并且每个子集的样本数量必须和原始样本数量一致,但是子集中允许存在重复数据.</p>

<p><img src="media/15255701784620/15259417755837.jpg" alt="Bagging方法-训练过程"/></p>

<h2 id="toc_2">随机森林(Random Forest)</h2>

<p>在Bagging策略的基础上进行修改后的一种算法</p>

<ol>
<li>从原始样本集(n个样本)中用Bootstrap采样(有放回重采样)选出n个样本;</li>
<li>从所有属性中随机选择k个属性,选择出最佳分割属性作为节点创建决策树;</li>
<li>重复以上两步m次,即建立m棵决策树;</li>
<li>这m个决策树形成随机森林,通过投票表决结果决定数据属于哪一类.</li>
</ol>

<h2 id="toc_3">随机森林的推广算法</h2>

<p>RF(随机森林)算法在实际应用中具有比较好的特性,应用也比较广泛,主要应用在:分类,回归,特征转换,异常点检测.常见的RF变种算法如下:</p>

<ul>
<li>Extra Tree</li>
<li>Totally Random Trees Embedding(TRTE)</li>
<li>lsolation Forest</li>
</ul>

<h2 id="toc_4">Extra Tree</h2>

<p>Extra Tree是RF的一个变种,原理基本和RF一样,区别如下:</p>

<ol>
<li>RF会随机采样作为子决策树的训练集,而Extra Tree每个子决策树采样原始数据集训练;</li>
<li>RF在选择划分特征点的时候会和传统决策树一样,会基于信息增益,信息增益率,基尼系数,均方差等原则来选择最优特征值;而Extra Tree会随机的选择一个特征值来划分决策树,</li>
</ol>

<p>Extra Tree因为是随机选择特征值的划分点,这样会导致决策树的规模一般大于RF所生成的决策树.也就是说Extra Tree模型的方差相对于RF进一步减少.在某些情况下,Extra Tree的泛华能力比RF的强.</p>

<h2 id="toc_5">Totally Random Trees Embedding(TRTE)</h2>

<p>TRTE是一种非监督的数据转化方式.将低维的数据集映射到高维,从而让映射到高维的数据更好的应用于分类回归模型.</p>

<p>TRTE算法的转换过程类似RF算法的方法,建立T个决策树来拟合数据.当决策树构建完成后,数据集里的每个数据在T个决策树叶子节点的位置就定下来了,将位置信息转换为向量就完成了特征转换操作.</p>

<h2 id="toc_6">Isolation Forest(IForest)</h2>

<p>IForest是一种异常点检测算法,使用类似RF的方式来检测异常点;IForest算法和RF算法的区别在于:</p>

<ol>
<li>在随机采样的过程中,一般只需要少量数据即可;</li>
<li>在进行决策树构建过程中,IForest算法会随机选择一个划分特征,并对划分特征随机选择一个划分阈值.</li>
<li>IForest算法构建的决策树一般深度max_depth是比较小的</li>
</ol>

<p>区别原因:目的是异常点检测,所以只要能够区分异常的即可,不需要大量数据;另外在异常点检测的过程中,一般不需要太大规模的决策树.</p>

<p>对于异常点的判断,则是将测试样本x拟合到T棵决策树上.计算在每棵树上该样本的叶子节点的深度\(h_t(x)\).从而计算出平均深度\(h(x)\);然后就可以使用下列公式计算样本点x的异常概率值,p(s,m)的取值范围为[0,1],越接近于1,则是异常点的概率越大.</p>

<p>\[p(x,m)=2^{-\dfrac{h(x)}{c(m)}}\]<br/>
\[c(m)=2\ln(m-1)+\xi-2\dfrac{m-1}{m} : m为样本个数,\xi为欧拉常数\]</p>

<h2 id="toc_7">RF随机森林总结</h2>

<ul>
<li><p>RF的主要优点</p>
<ul>
<li>1. 训练可以并行化,对于大规模样本的训练具有速度的优势;</li>
<li>2. 由于进行随机选择决策树划分特征列表,这样在样本维度比较高的时候,仍然具有比较高的训练性能;</li>
<li>3. 可以给出各个特征的重要性列表;</li>
<li>4. 由于存在随机抽样,训练出来的模型方差小,泛化能力强;</li>
<li>5. RF实现简单;</li>
<li>6. 对于部分特征的缺失不敏感.</li>
</ul></li>
<li><p>RF的主要缺点</p>
<ul>
<li>1. 在某些噪音比较大的特征上,RF模型容易陷入过拟合;</li>
<li>2. 取值比较多的划分特征对RF的决策会产生更大的影响,从而有可能影响模型的效果.</li>
</ul></li>
</ul>

<h2 id="toc_8">随机森林算法案例</h2>

<pre class="line-numbers"><code class="language-text">```
```
</code></pre>

<h2 id="toc_9">RF scikit-learn相关参数</h2>

<p><img src="media/15255701784620/15260264540993.jpg" alt=""/></p>

<h2 id="toc_10">随机森林的思考</h2>

<p>在随机森林的构建过程中,由于各棵树之间是没有关系的,相对独立的;在构建的过程中,构建第m棵子树的时候,不会考虑前面的m-1棵树.</p>

<p>思考:</p>

<ol>
<li>如果在构建第m棵子树的时候,考虑到前m-1棵子树的结果,会不会对最终结果产生有益的影响?</li>
<li>各个决策树组成随机森林后,在形成最终结果的时候能不能给定一种既定的决策顺序呢?</li>
</ol>

<h1 id="toc_11">Boosting</h1>

<p>提升学习(Boosting)是一种机器学习技术,可以用于回归和分类的问题,它每一步产生弱预测模型(如决策树),并加权累加到总模型中;如果每一步的弱项模型的生成都是依据损失函数的梯度方式的,那么就称为梯度提升(Gradient boosting).</p>

<p>提升技术的意义:如果一个问题存在弱预测模型,那么可以通过提升技术的方法得到一个强预测模型.</p>

<p>常见的模型有:</p>

<ul>
<li>Adaboost</li>
<li>Gradient Boosting(GBT/GBDT/GBRT)</li>
</ul>

<p><img src="media/15255701784620/15260302457703.jpg" alt=""/></p>

<h2 id="toc_12">Adaboost算法公式</h2>

<p>Adaboost算法将基分类器的线性组合作为强分类器,同时给分类误差率较小的基本分类器以大的权重,给分类误差率较大的基分类器以小的权重值;构建的线性组合为:<br/>
\[f(x)=\sum_{m=1}^M\alpha_mG_m(x)\]</p>

<p>最终分类器是在线性组合的基础上进行Sign函数转换:<br/>
\[G(x)=sign(f(x))=sign \left[\sum_{m=1}^M\alpha_mG_m(x) \right]\]</p>

<p>Sign函数<br/>
<img src="media/15255701784620/15260310974094.jpg" alt="Sign函数"/></p>

<h2 id="toc_13">AdaBoost算法原理</h2>

<p>Adaptive Boosting是一种迭代算法.每轮迭代中会在训练集上产生一个新的学习器,然后使用该学习器对所有样本进行预测,以评估每个样本的重要性(Informative).换句话来讲就是,算法会为每个样本赋予一个权重,每次用训练好的学习器标注/预测各个样本,如果某个样本点被预测的越正确,则将其权重降低;否则提高样本的权重.权重越高的样本在下一个迭代训练中所占的比重就越大,也就是说越难区分的样本在训练过程中会变得越重要.</p>

<p>整个迭代过程直到错误率足够小或者达到一定的迭代次数为止.</p>

<p>样本加权</p>

<p><img src="media/15255701784620/15260307178045.jpg" alt="样本加权"/></p>

<p>最终的强学习器<br/>
\[G(x)=sign(f(x))=sign \left[\sum_{m=1}^M\alpha_mG_m(x) \right]\]</p>

<p>损失函数<br/>
\[loss=\dfrac{1}{n}\sum_{i=1}^nI(G(x_i)\neq y_i)\]</p>

<p>损失函数<br/>
\[loss=\dfrac{1}{n}\sum_{i=1}^nI(G(x_i)\neq y_i) \leq \dfrac{1}{n}\sum_{i=1}^ne^{(-y_if(x))}\]</p>

<p>第k-1轮的强学习器<br/>
\[f_{k-1}(x)=\sum_{j=1}^{k-1}\alpha_jG_j(x)\]</p>

<p>第k轮的强学习器<br/>
\[f_{k}(x)=\sum_{j=1}^{k}\alpha_jG_j(x) \qquad<br/>
f_k(x)=f_{k-1}(x)+\alpha_kG_k(x)<br/>
\]</p>

<p>损失函数<br/>
\[loss(\alpha_m,G_m(x))=\dfrac{1}{n}\sum_{i=1}^ne^{(-y_i(f_{n-1}(x)+\alpha_mG_m(x)))}\]</p>

<p>未完待续</p>

<h2 id="toc_14">...</h2>

<h2 id="toc_15">AdaBoost总结</h2>

<ul>
<li><p>daBoost的优点如下:</p>
<ul>
<li>可以处理连续值和离散值;</li>
<li>模型的鲁棒性比较强;</li>
<li>解释强,结构简单.</li>
</ul></li>
<li><p>AdaBoost的缺点如下:</p>
<ul>
<li>对异常样本敏感,异常样本可能会在迭代过程中获得较高的权重值,最终影响模型效果.</li>
</ul></li>
</ul>

<h1 id="toc_16">Stacking</h1>

<p>Stacking是指训练一个模型用于组合(combine)其他模型(基模型/基学习器)的技术.即首先训练出多个不同的模型,然后再以之前训练的各个模型的输出作为输入来新训练一个新的模型,从而得到一个最终的模型.一般情况下使用单层的Logistic回归作为组合模型<br/>
<img src="media/15255701784620/15260322012383.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[决策树]]></title>
    <link href="http://dmlcoding.com/15255685118456.html"/>
    <updated>2018-05-06T09:01:51+08:00</updated>
    <id>http://dmlcoding.com/15255685118456.html</id>
    <content type="html"><![CDATA[
<p>在决策树算法的学习过程中,信息增益是特征选择的一个重要指标.它定义为一个特征能够为分类系统带来多少信息,带来的信息越多,说明该特征越重要,相应的信息增益也就越大<br/>
<img src="media/15255685118456/15256176444642.jpg" alt=""/></p>

<h1 id="toc_0">信息熵(Entropy)</h1>

<p>\[H(X)=-\sum_{i=1}^mp_i\log_2(p_i)\]</p>

<span id="more"></span><!-- more -->

<ul>
<li>信息量:指的是一个样本/事件所蕴含的信息,如果一个事件的概率越大,那么就可以认为该事件所蕴含的信息越少.比如:总所周知的&quot;太阳从东方升起&quot;.因为是确定事件,所以不携带任何信息量.</li>
<li>信息熵:1948年,香农引入信息熵;<strong>一个系统越是有序,信息熵就越低;一个系统越是混乱,信息熵就越高.</strong> 所以,信息熵被认为是一个系统有序程度的度量</li>
<li>信息熵就是用来描述系统信息量的不确定度(复杂度)的.</li>
</ul>

<p>High Entropy(高信息熵):表示随机变量X是均匀分布的,各种取值情况是等概率出现的.<br/>
Low Entropy(低信息熵):表示随机变量X各种取值不是等概率出现.可能出现有的事件概率很大,有的事件概率很小.</p>

<h2 id="toc_1">条件熵H(Y|X)</h2>

<blockquote>
<p>给定条件X的情况下,随机变量Y的信息熵就叫做条件熵</p>
</blockquote>

<p>在计算条件熵的情况下,先计算一个小例子.看下面这张图<br/>
<img src="media/15255685118456/15256671505083.jpg" alt=""/></p>

<p>我们可以得出<br/>
P(X=数学)=4/8=0.5<br/>
P(Y=M)=4/8=0.5<br/>
P(X=数学,Y=F)=2/8=0.25<br/>
p(Y=M|X=英语)=0(由图可知,英语专业的都是女生)</p>

<p>根据这个公式,计算H(X)和H(Y)<br/>
\[H(X)=-\sum_{i=1}^mp_i\log_2(p_i)\]<br/>
因为:<br/>
P(X=数学)=0.5<br/>
P(X=英语)=0.25<br/>
P(X=IT)=0.25<br/>
所以:<br/>
\[H(X)=-0.5log_2{0.5}-0.25log_2{0.25}-0.25log_2{0.25}=1.5\]</p>

<p>因为:<br/>
P(Y=M)=4/8=0.5<br/>
P(Y=F)=4/8=0.5<br/>
\[H(Y)=-0.5log_2{0.5}-0.5log_2{0.5}=1\]</p>

<p>比如:当专业(X)为数学的时候,Y的信息熵的值为:H(Y|X=数学)</p>

<p><img src="media/15255685118456/15256671787875.jpg" alt=""/></p>

<p>摘出专业都是数学的这部分,性别符合均匀分布.因此条件熵为1<br/>
\[H(Y|X=数学)=1\]</p>

<p>给定条件X的情况下,所有不同X值情况下Y的信息熵的平均值叫做条件熵.<br/>
\[H(Y|X)=\sum_{j=1}P(X=v_j)H(Y|X=v_j)\]</p>

<p><img src="media/15255685118456/15256888532803.jpg" alt=""/></p>

<p>\[H(Y|X)=0.5*1+0.25*0+0.25*0=0.5\]</p>

<p>给定条件X的情况下,所有不同X值情况下Y的信息熵的平均值叫做条件熵.另外一个公司如下所示:<br/>
\[H(Y|X)=H(X,Y)-H(X)\]<br/>
事件(X,Y)发生所包含的熵,减去事件X单独发生的熵,即为在事件X发生的前提下,Y发生&quot;新&quot;带来的熵,这个也就是条件熵本身的概念.</p>

<p>参考:<a href="https://blog.csdn.net/pipisorry/article/details/51695283">https://blog.csdn.net/pipisorry/article/details/51695283</a></p>

<h2 id="toc_2">条件熵H(Y|X)公式推导</h2>

<p>\[<br/>
\begin{aligned}<br/>
H(Y|X) &amp; = \sum_{j=1}P(X=v_j)H(Y|X=v_j) \\\<br/>
&amp; = \sum_xP(X)H(Y|X) \\\<br/>
&amp; = \sum_xp(x)\left(-\sum_yp(y|x)\log(p(y|x))\right) \\\<br/>
&amp; = -\sum_x\sum_yp(x,y)log\left(\dfrac{p(x,y)}{p(x)}\right) \\\<br/>
&amp; = -\sum_x\sum_yp(x,y)log(p(x,y))-\left [-\sum_x \left (\sum_yp(x,y) \right )\log(p(x)) \right ] \\\<br/>
&amp; = H(X,Y)- \left [-\sum_xp(x)\log(p(x)) \right ] \\\<br/>
&amp; = H(X,Y)-H(X)<br/>
\end{aligned} <br/>
\]</p>

<h2 id="toc_3">信息增益</h2>

<p>信息增益恰好是:信息熵-条件熵</p>

<p>也就是说,信息增益代表了在一个条件下,信息复杂度(不确定性)减少的程度.</p>

<p>那么我们现在也很好理解了,在决策树算法中,我们的关键就是每次选择一个特征,特征有多个,那么到底按照什么标准来选择哪一个特征.</p>

<p>这个问题就可以用信息增益率来度量.如果选择一个特征后,信息增益率最大(信息不确定性减少的程度最大),那么我们就选取这个特征</p>

<h1 id="toc_4">决策树(Decision Tree)</h1>

<h2 id="toc_5">什么是决策树</h2>

<p>决策树是在已知各种情况发生概率的基础上,通过构建决策树来进行分析的一种方式,是一种直观应用概率分析的一种图解法;决策树是一种预测模型,代表的是对象属性与对象值之间的映射关系;决策树是一种树形结构,其中每个内部节点表示一个属性的测试,每个分支表示一个测试输出,每个叶节点代表一种类别;决策树是一种非常常用的有监督的分类算法.</p>

<p>决策树的决策过程就是从根节点开始,测试待分类项中对应的特征属性,并按照其值选择输出分支,直到叶子节点,将叶子节点的存放的类别作为决策结果.</p>

<p>决策树分为两大类:分类树和回归树,前者用于分类标签值,后者用于预测连续值,常用算法有ID3,C4.5,CART等</p>

<h2 id="toc_6">决策树的构建过程</h2>

<p>决策树算法的重点是决策树的构造;决策树的构造就是进行属性选择度量,确定各个特征属性之间的拓扑结构(树结构);构建决策树的关键步骤就是分裂属性,分裂属性是指在某个节点按照某一个类特征属性的不同划分构建不同的分支,其目标就是让各个分裂子集尽可能的&quot;纯&quot;(让一个分类子类中待分类的项尽可能的属于同一个类别).</p>

<p>构建步骤如下:</p>

<ol>
<li>将所有的特征看成一个一个的节点;</li>
<li>遍历每个特征的每一种分割方式,找到最好的分割点;将数据划分为不同的子节点.eg:\(N_1,N_2...N_m\);计算划分之后所有子节点的&quot;纯度&quot;信息;</li>
<li>对第二步产生的分割,选择出最优的特征以及最优的划分方式;得出最终的子节点:\(N_1,N_2...N_m\);</li>
<li>对子节点\(N_1,N_2...N_m\)分别继续执行2-3步,直到每个最终的子节点都足够&quot;纯&quot;.</li>
</ol>

<h2 id="toc_7">决策树特征属性类型</h2>

<p>属性类型当然可以是离散型和连续型.</p>

<p>根据特征属性的类型不同,在构建决策树的时候,采用不同的方式,具体如下:</p>

<ol>
<li>属性是离散值,而且不要求生成的是二叉决策树,此时一个属性就是一个分支.</li>
<li>属性是离散值,而且要求生成的是二叉决策树,此时使用属性划分的子集进行测试,按照&quot;属于此子集&quot;和&quot;不属于此子集&quot;分成两个分支.</li>
<li>属性是连续值,可以确定一个值作为分裂点split_point,按照&gt;split_point和&lt;=split_point生成两个分支.</li>
</ol>

<h2 id="toc_8">决策树分割属性选择</h2>

<p>决策树算法是一种&quot;贪心&quot;算法策略,只考虑在当前数据特征情况下的<strong>最好分割方式</strong>,不能进行回溯操作.</p>

<p>对于整体的数据集而言,按照所有的特征属性进行划分操作,对所有的划分操作的结果集的&quot;<strong>纯度</strong>&quot;进行比较.选择&quot;纯度&quot;越高的特征属性作为当前需要分割的数据集进行分割操作,持续迭代,直到得到最终结果.决策树是通过&quot;纯度&quot;来选择分割特征属性点的.</p>

<p>说了这么多&quot;纯&quot;,那么究竟该如何量化纯度值呢?</p>

<h2 id="toc_9">决策树量化纯度</h2>

<p>决策树的构建是基于<strong>样本概率</strong>和<strong>纯度</strong>进行构建操作的,那么进行判断数据集是否&quot;纯&quot;可以通过三个公式进行判断,分别是<strong>Gini系数</strong>,<strong>熵(Entropy)</strong>,<strong>错误率</strong>.<strong>这三个公式值越大,表示数据越&quot;不纯&quot;.越小表示越&quot;纯&quot;</strong>;实践证明这三个公式效果差不多,一般情况使用熵公式</p>

<p>\[Gini=1-\sum_{i=1}^nP(i)^2\]</p>

<p>\[H(Entropy)=-\sum_{i=1}^nP(i)\log_2(P(i))\]</p>

<p>\[Error=1-max  \sideset{_{i=1}^n}{}\lbrace P(i) \rbrace\]</p>

<h2 id="toc_10">决策树量化纯度</h2>

<p>当计算出各个特征属性的量化纯度值后使用<strong>信息增益度</strong>来选择出当前数据集的分割特征属性;<strong>如果信息增益度的值越大,表示在该特征属性上会损失的纯度越大,那么该属性就越应该在决策树的上层</strong>,计算公式为:<br/>
\[Gain=\Delta=H(D)-H(D|A)\]</p>

<p>Gain为A为特征对训练数据集D的信息增益,它为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差</p>

<h2 id="toc_11">决策树算法的停止条件</h2>

<p>决策树构建的过程是一个递归的过程,所以必须给定停止条件,否则过程将不会进行停止,一般情况有两种停止条件:</p>

<ol>
<li>当每个子节点只有一种类型的时候停止构建;</li>
<li>当前节点中记录数小于某个阈值,同时迭代次数达到给定值时,停止构建过程,此时使用\(\max(p(i))\)作为节点的对应类型</li>
</ol>

<p>方式一可能会使树的节点过多,导致过拟合(Overfiting)等问题;<br/>
比较常用的方式是使用方式二作为停止条件</p>

<h2 id="toc_12">决策树算法效果评估(重新听,补充这里的推导算法)</h2>

<p>决策树的效果评估和一般的分类算法一样,采用<strong>混淆矩阵</strong>来进行计算准确率,召回率,精确率等指标.</p>

<p>也可以采用叶子节点的纯度值总和来评估算法的效果.值越小,效果越好.</p>

<p>也就是决策树的损失函数(该值越小,算法效果越好)<br/>
\[C(T)=\sum_{t=1}^{leaf}\dfrac{|D_t|}{|D|}H(t)\]</p>

<h3 id="toc_13">决策树直观理解结果计算</h3>

<p><img src="media/15255685118456/15256176444642.jpg" alt=""/></p>

<h1 id="toc_14">决策树生成算法</h1>

<p>建立决策树的主要是以下三种算法</p>

<ul>
<li>ID3</li>
<li>C4.5</li>
<li>CART(Classification And Regression Tree)</li>
</ul>

<h2 id="toc_15">ID3算法</h2>

<p>ID3算法是决策树的一个经典的构造算法,内部使用信息熵以及信息增益来进行构建;每次迭代选择信息增益最大的特征属性作为分割属性.</p>

<p>也就是会用到前面写到的两个公式</p>

<p>\[H(D)=-\sum_{i=1}^nP(i)\log_2(P(i))\]<br/>
\[Gain=\Delta=H(D)-H(D|A)\]</p>

<h2 id="toc_16">ID3算法优缺点</h2>

<ul>
<li><p>优点</p>
<ul>
<li>决策树构建速度快,实现简单</li>
</ul></li>
<li><p>缺点</p>
<ul>
<li>计算依赖于特征数目较多的特征,而属性值最多的属性并不一定最优</li>
<li>ID3算法不是递增算法</li>
<li>ID3算法是单变量决策树,对于特征属性之间的关系不会考虑</li>
<li>抗噪性差</li>
<li>只适合小规模数据集,需要将数据放到内存中</li>
</ul></li>
</ul>

<h2 id="toc_17">C4.5算法</h2>

<p>在ID3算法的基础上,进行算法优化提出的一种算法(C4.5);现在C4.5已经是特别经典的一种决策树构造算法;使用<strong>信息增益率</strong>来取代ID3算法中的信息增益,在树的构造过程中会<strong>进行剪枝操作进行优化</strong>;能够自动完成对连续属性的离散化处理;C4.5算法在选中分割属性的时候选择信息增益率最大的属性,涉及到的公式为:<br/>
\[H(D)=-\sum_{i=1}^nP(i)\log_2(P(i))\]<br/>
\[Gain=\Delta=H(D)-H(D|A)\]<br/>
\[Gain\_ration(A)=\dfrac{Gain(A)}{H(A)}\]</p>

<h2 id="toc_18">C4.5算法优缺点</h2>

<ul>
<li><p>优点</p>
<ul>
<li>产生的规则易于理解</li>
<li>准确率较高</li>
<li>实现简单</li>
</ul></li>
<li><p>缺点</p>
<ul>
<li>对数据集需要进行多次顺序扫描和排序,所以效率较低</li>
<li>只适合小规模数据集,需要将数据放到内存中</li>
</ul></li>
</ul>

<p>总结:属性越多,信息增益率越大</p>

<h2 id="toc_19">CART算法</h2>

<p>使用<strong>基尼系数</strong>作为数据纯度的量化指标来构建的决策树算法就叫做CART(Classification And Regression Tree,分类回归树)算法.CART算法使用<strong>GINI增益</strong>作为分割属性选择的标准,选择GINI增益最大的作为当前数据集的分割属性;可用于分类和归类两类问题.强调备注:CART构建的是二叉树.</p>

<p>\[Gini=1-\sum_{i=1}^nP(i)^2\]<br/>
\[Gain=\Delta=Gini(D)-Gini(D|A)\]</p>

<h2 id="toc_20">ID3,C4.5,CART分类算法总结</h2>

<ol>
<li>ID3和C4.5算法只适合在小规模数据集上使用</li>
<li>ID3和C4.5算法都是单变量决策树</li>
<li>当属性值取值比较多的时候,最好考虑C4.5算法,ID3得出的效果会比较差</li>
<li>决策树分类一般情况只适合小数据量的情况(数据可以放内存)</li>
<li>CART算法是三种算法中最常用的一种决策树构建算法</li>
<li>三种算法的区别仅仅只是对于当前树的评价标准不同而已,<em>ID3使用信息增益</em>,<em>C4.5使用信息增益率</em>,<em>CART使用基尼系数</em></li>
<li>CART算法构建的一定是二叉树,ID3和C4.5构建的不一定是二叉树</li>
</ol>

<table>
<thead>
<tr>
<th>算法</th>
<th>支持模型</th>
<th>树结构</th>
<th>特征选择</th>
<th>连续值处理</th>
<th>缺失值处理</th>
<th>剪枝</th>
<th>特征属性多次使用</th>
</tr>
</thead>

<tbody>
<tr>
<td>ID3</td>
<td>分类</td>
<td>多叉树</td>
<td>信息增益</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr>
<td>C4.5</td>
<td>分类</td>
<td>多叉树</td>
<td>信息增益率</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>CART</td>
<td>分类,回归</td>
<td>二叉树</td>
<td>基尼系数,均方差</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody>
</table>

<h1 id="toc_21">案例一:使用鸢尾花数据分类(分类树案例)</h1>

<p>使用决策树算法API对鸢尾花数据进行分类操作,并理解及进行决策树API的相关参数优化</p>

<p><a href="http://archive.ics.uci.edu/ml/datasets/Iris">数据来源</a></p>

<h2 id="toc_22">鸢尾花数据集描述</h2>

<p>Data Set Information:</p>

<p>This is perhaps the best known database to be found in the pattern recognition literature. Fisher&#39;s paper is a classic in the field and is referenced frequently to this day. (See Duda &amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. </p>

<p>Predicted attribute: class of iris plant. </p>

<p>This is an exceedingly simple domain. </p>

<p>This data differs from the data presented in Fishers article (identified by Steve Chadwick, spchadwick &#39;@&#39; espeedaz.net ). The 35th sample should be: 4.9,3.1,1.5,0.2,&quot;Iris-setosa&quot; where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,&quot;Iris-setosa&quot; where the errors are in the second and third features.</p>

<p>Attribute Information:</p>

<ol>
<li>sepal length in cm </li>
<li>sepal width in cm </li>
<li>petal length in cm </li>
<li>petal width in cm </li>
<li>class: <br/>
-- Iris Setosa <br/>
-- Iris Versicolour <br/>
-- Iris Virginica</li>
</ol>

<h1 id="toc_23">分类树和回归树的区别</h1>

<p>分类树采用信息增益,信息增益率,基尼系数来评价树的效果,都是基于概率值进行判断的;而分类树的叶子节点的预测值一般为叶子节点中概率最大的类别作为当前叶子的预测值</p>

<p>在回归树中,叶子节点的预测值一般为叶子节点中所有值的均值来作为当前叶子节点的预测值.所以在回归树中一般采用MSE作为树的评价指标,即均方差.<br/>
\[MSE=\dfrac{1}{n}\sum_{i=1}^n(y_i-\hat y_i)^2\]</p>

<p>一般情况下,只会使用CART算法构建回归树.</p>

<h1 id="toc_24">案例二:波士顿房屋租赁价格预测(回归树案例)</h1>

<h1 id="toc_25">决策树过拟合和欠拟合</h1>

<h1 id="toc_26">决策树优化策略</h1>

<h2 id="toc_27">剪枝优化</h2>

<p>决策树过渡拟合一般情况是由于节点过多导致的,剪枝优化对决策树的正确率影响是比较大的,也是最常用的一种优化方式</p>

<p>决策树的剪枝是决策树算法中最基本,最有用的一种优化方案,主要分为两大类</p>

<h3 id="toc_28">决策树的剪枝方案</h3>

<p><strong>前置剪枝</strong>:在构建决策树的过程中,提前停止.结果是决策树一般比较小,实践证明这种策略无法得到比较好的结果</p>

<p><strong>后置剪枝</strong>:在决策树构建好后,然后再开始裁剪,一般使用两种方式:<br/>
    1. 用单一叶子节点代替整个子树.叶子点的分类采用子树中最主要的分类;<br/>
    2. 将一个子树完全替代另外一颗子树.<br/>
    3. 后置剪枝的主要问题是计算效率问题,存在一定的浪费情况.</p>

<p>后置剪枝总体思路(交叉验证):</p>

<ul>
<li>由完全树\(T_0\)开始,剪枝部分节点得到\(T_1\),在此剪枝得到\(T_2\)...直到仅剩树根的树\(T_k\)</li>
<li>在验证数据集上对这k+1个树进行评价,选择最优树\(T_a\)(损失函数最小的树)</li>
</ul>

<h3 id="toc_29">决策树剪枝过程</h3>

<p>对于给定的决策树\(T_0\):</p>

<ol>
<li>计算所有内部非叶子节点的<strong>剪枝系数</strong></li>
<li>查找<strong>最小剪枝系数</strong>的节点,将其子节点进行删除操作,进行剪枝得到决策树\(T_k\);如果存在多个最小剪枝系数节点,选择包含<strong>数据项最多</strong>的节点进行剪枝操作</li>
<li>重复上述操作,直到产生的剪枝决策树\(T_k\)只有1个节点</li>
<li>得到决策树\(T_0T_1T_2...T_k\)</li>
<li>使用<strong>验证样本集</strong>选择最优子树\(T_a\)</li>
</ol>

<p>使用验证集选择最优子树的标准,可以使用原始损失函数来考虑:<br/>
\[loss=\sum_{t=1}^{leaf}\dfrac{|D_t|}{|D|}H(t)\]</p>

<h3 id="toc_30">决策树剪枝损失函数及剪枝系数</h3>

<p>原始损失函数<br/>
\[loss=\sum_{t=1}^{leaf}\dfrac{|D_t|}{|D|}H(t)\]</p>

<p>叶节点越多,决策树越复杂,损失越大;修正添加剪枝系数,修改后的损失函数为<br/>
\[loss_{\alpha}=loss+\alpha*leaf\]</p>

<p>考虑根节点为r的子树,剪枝前后的损失函数分别为loss(R)和loss(r),当这两者相等的时候,可以求得剪枝系数<br/>
\[loss_{\alpha}(r)=loss(r)+\alpha\]<br/>
\[loss_{\alpha}(R)=loss(R)+\alpha*R_{leaf}\]<br/>
\[\alpha=\dfrac{loss(r)-loss(R)}{R_{leaf}-1}\]</p>

<h2 id="toc_31">Random Forest(随机森林)</h2>

<p>利用训练数据随机产生多个决策树,形成一个森林.然后使用这个森林对数据进行预测,选取最多结果作为预测结果.</p>

<h1 id="toc_32">总结</h1>

<p>1.分类树和回归树<br/>
区别:<br/>
a. 分类树中使用信息熵,gini系数,错误率作为数&quot;纯度&quot;的度量指标;回归树中使用MSE,MAE作为树的&quot;纯度&quot;度量指标;<br/>
b.分类树使用叶子节点中包含最多那个类别作为当前叶子的预测值;回归树中使用叶子节点中包含的所有样本的目标属性的均值作为当前叶子的预测值.</p>

<p>2.决策树的构建过程<br/>
思想:<br/>
让每次分裂数据集的时候,让分裂之后的数据集更加的&quot;纯&quot;(让数据更有区分能力)</p>

<p>3.决策树分裂属性选择方式<br/>
a.基于最优划分的规则进行选择:迭代计算所有特征属性上所有划分方式后的&quot;纯度&quot;,选择划分后更加&quot;纯&quot;的一种方式(信息增益,信息增益率).---&gt;<br/>
只能说明在当前数据集上是最优的,所以可能会存在一定的过拟合情况.<br/>
b.基于随机的划分规则:每次划分的时候,都是先选择一定数目的特征,然后在这部分特征中选择出一个最优的划分特征.因为每次选的划分特征都是局部最优的,相对来讲,可以增加模型的鲁棒性,降低模型的过拟合性.</p>

<p>4.决策树的欠拟合,过拟合<br/>
a.可以通过增加树的深度来缓解决策树欠拟合这个问题<br/>
b.我们可以通过限制树的复杂程度来缓解这个过拟合的问题<br/>
c.因此也就是找到一个平衡</p>

<p>5.网格交叉验证(GridSearchCV)<br/>
6.决策树的效果评估</p>

<h1 id="toc_33">决策树可视化</h1>

<p>决策树可视化可以方便我们直观的观察所构建的树模型;决策树可视化依赖graphiz服务,所以我们在进行可视化之前,安装对应的服务.</p>

<h2 id="toc_34">安装</h2>

<p>下载地址:<a href="http://www.graphviz.org/">http://www.graphviz.org/</a><br/>
Mac安装步骤</p>

<pre class="line-numbers"><code class="language-text"># 安装graphviz服务
brew install graphviz

# 安装python的graphviz插件
pip install graphviz

# 安装python的pydotplus插件
pip install pydotplus

</code></pre>

<h2 id="toc_35">使用方式</h2>

<p><strong>方式一:将模型输出dot文件,然后使用graphviz的命令将dot文件转换为pdf格式的文件</strong></p>

<pre class="line-numbers"><code class="language-text">from sklearn import tree
with open(&#39;iris.dot&#39;,&#39;w&#39;) as f:
    f = tree.export_graphviz(model,out_file=f)


# 命令行执行dot命令 dot -Tpdf iris.dot -o iris.pdf
</code></pre>

<p><strong>方式二:直接使用pydotplus插件直接生成pdf文件进行保存</strong></p>

<pre class="line-numbers"><code class="language-text">from sklearn import tree
import pydotplus
dot_data = tree.export_graphviz(model,out_file=None)
graph=pydotplus.graph_from_dot_data(dot_data)
graph.write_pdf(&quot;iris2.pdf&quot;)
# graph.write_png(&quot;iris3.png&quot;)
</code></pre>

<p><strong>方式三:使用Image对象直接显示pydotplus生成的图片</strong></p>

<pre class="line-numbers"><code class="language-text">from sklearn import tree
from IPython.display import Image
import pydotplus

dot_data=tree.export_graphviz(model,put_file=None,
    feature_names=[&#39;sepal length&#39;,&#39;sepal width&#39;,&#39;petal length&#39;,&#39;petal width&#39;],
    class_names=[&#39;Iris-setosa&#39;,&#39;Iris-versicolor&#39;,&#39;Iris-virgincia&#39;],
    filled=True,rounded=True,
    special_characters=True)
    
graph=pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png)
</code></pre>

<h1 id="toc_36">参考</h1>

<p>[1]: </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[KNN]]></title>
    <link href="http://dmlcoding.com/15277324362749.html"/>
    <updated>2018-05-31T10:07:16+08:00</updated>
    <id>http://dmlcoding.com/15277324362749.html</id>
    <content type="html"><![CDATA[
<p>K近邻(K-nearst neighbors,KNN)是一种基本的机器学习算法,所谓K近邻,就是K个最近的邻居的意思,说的是每个样本都可以用它最接近的K个邻居来代表.</p>

<p>比如:判断一个人的人品,只需要观察与他来往最密切的几个人的人品好坏就可以得出,即,&quot;近朱者赤,近墨者黑&quot;.</p>

<p>KNN算法既可以应用于分类应用中,也可以应用在回归应用中.KNN在做回归和分类的主要区别在于最后做预测的时候决策方式不同,<strong>KNN在分类预测时,一般采用多数表决法;而在做回归预测时,一般采用平均值法.</strong></p>

<span id="more"></span><!-- more -->

<h1 id="toc_0">KNN算法原理</h1>

<ol>
<li>从训练集合中获取K个离待预测样本距离最近的样本数据;</li>
<li>根据获取得到的K个样本数据来预测当前待预测样本的目标属性值</li>
</ol>

<p><img src="media/15277324362749/15277329582308.jpg" alt=""/></p>

<p>如上图所示,绿色圆要被决定赋予那一个类呢,是红色三角形还是蓝色矩形?</p>

<ol>
<li>如果K=3,由于红色三角形所占比例为2/3,绿色圆将被赋予红色三角形这个类.(多数投票)</li>
<li>如果K=5,由于蓝色四方形比例为3/5,因此绿色圆被赋予蓝色矩形.</li>
</ol>

<h1 id="toc_1">KNN三要素</h1>

<p>在KNN算法中,非常重要的主要是三个因素:</p>

<ul>
<li><strong>K值的选择</strong>:对于K值的选择,一般根据样本分布选择一个较小的值,然后通过<strong>交叉验证</strong>来选择一个比较合适的最终值;当选择比较小的K值的时候,表示使用较小领域中的样本进行预测,训练误差会减小,但是会导致模型变得复杂,容易过拟合;当选择较大的K值的时候,表示使用较大领域中的样本进行预测,训练误差会增大,同时会使模型变得简单,容易导致欠拟合.</li>
<li><strong>距离的度量</strong>:一般使用欧式距离(即,欧几里得距离);</li>
<li><strong>决策规则</strong>:在分类模型中,主要使用多数表决法或者加权多数表决法;在回归模型中,主要使用平均值法或者加权平均值法.加权的时候,可以认为距离越近的权重也应该越大.</li>
</ul>

<p>\[D(x,y) = \sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + ... + (x_n-y_n)^2} = \sqrt{\sum\limits_{i=1}^{n}(x_i-y_i)^2}\]</p>

<h1 id="toc_2">KNN预测规则</h1>

<p>既然KNN算法既可以用在分类场景中,也可以用在回归场景中,那么针对不同的场景,KNN也有不同的预测规则</p>

<h2 id="toc_3">KNN分类预测规则</h2>

<p>在KNN分类应用中,一般采用对数投票或者加权多数表决法.</p>

<p><img src="media/15277324362749/15277370065477.jpg" alt=""/></p>

<ul>
<li><p><strong>多数表决法</strong>: 每个邻近样本的权重是一样的,也就是说最终预测的结果为出现类别最多的那个类,比如上图中蓝色矩形的最终类别为红色圆;</p></li>
<li><p><strong>加权多数表决法</strong>:每个邻近样本的权重是不一样的,一般情况下采用权重和距离成反比的方式来计算,也就是说最终预测结果是出现权重最大的那个类别:比如上图中,假设三个红色圆点到预测样本点的距离均为2,两个黄色星到预测样本点距离为1,那么蓝色圆圈的最终类别为黄色.(\(\frac12*3 &lt; 1*2\))</p></li>
</ul>

<h2 id="toc_4">KNN回归预测规则</h2>

<p>在KNN回归应用中,一般采用平均值法或者加权平均值法.<br/>
<img src="media/15277324362749/15277369863901.jpg" alt=""/></p>

<ul>
<li><p><strong>平均值法</strong>: 每个邻近样本的权重是一样的,也就是说最终预测的结果为所有邻近样本的目标属性值的均值;比如上图中,蓝色方块的最终预测值为\((3+3+3+2+2)/5=2.6\).</p></li>
<li><p><strong>加权平均值法</strong>:每个邻近样本的权重是不一样的,一般情况下采用权重和距离成反比的方式来计算,也就是说在计算均值的时候进行加权操作;比如上图中,假设上面三个点到待预测样本点的距离均为2,下面两个点到待预测样本点距离为1.那么蓝色方块的最终预测值为2.43.</p></li>
</ul>

<h1 id="toc_5">KNN算法实现方式</h1>

<p>KNN算法的重点在于找出K个最近邻的点,主要方式有一下几种:</p>

<ul>
<li><strong>蛮力实现(brute)</strong>:计算预测样本到所有训练集样本的距离,然后选择最小的K个距离即可得到K个最近邻点.缺点在于当特征数比较多,样本数比较多的时候,算法的执行效率比较低;</li>
<li><strong>KD树(kd_tree)</strong>:KD树算法中,首先是对训练数据进行建模,构建KD树,然后再根据建好的模型来获取邻近样本数据.</li>
<li>除此之外,还有一些从kd_tree修改后的求解最邻近点的算法,比如:Ball Tree,BBF Tree,MVP tree等</li>
</ul>

<p>接下来重点说一下KD树的构建过程</p>

<h1 id="toc_6">KD Tree</h1>

<p>KD Tree是KNN算法中用于计算最近邻的快速,便捷构建方式.</p>

<p>当样本数据量少的时候,我们可以使用brute这种暴力的方式进行求解最近邻,即计算到所有样本的距离.但是当样本量比较大的时候,直接计算所有样本的距离,工作量有点大,所以在这种情况下,我们可以使用kd_tree来快速的计算.</p>

<h2 id="toc_7">KD Tree构建方式</h2>

<p>KD树采用从m个样本的n维特征中,分别计算n个特征取值的方差,用方差最大的第k维特征\(n_k\)作为根节点.对于这个特征,选择取值的中位数\(n_{kv}\)作为样本的划分点,对于小于该值的样本划分到左子树,对于大于等于该值的样本划分到右子树,对于左右子树采用同样的方式找方差最大的特征最为根节点,递归即可产生KD树.(可以认为方差越大,越具有区分能力)</p>

<p><img src="media/15277324362749/15277383424878.jpg" alt="KD树构建过程"/></p>

<p>比如我们有二维样本6个，{(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)}，构建kd树的具体步骤如草稿所示<br/>
<img src="media/15277324362749/15277404253921.jpg" alt=""/></p>

<p>构建的完整子树就如图所示<br/>
<img src="media/15277324362749/15278193600353.jpg" alt=""/></p>

<h2 id="toc_8">KD Tree查找最近邻</h2>

<p>当我们生成KD树以后,就可以去预测测试集里面的样本目标点了.对于一个目标点,我们首先在KD树里面找到包含目标点的叶子节点.以目标点为圆心,以目标点到叶子节点样本实例的距离为半径,得到一个超球体,最近邻的点一定在这个超球体内部.然后返回叶子节点的父节点,检查另一个子节点包含的超矩形体是否和超球体相交,如果相交就到这个子节点寻找是否有更加近的近邻,有的话就更新最近邻.如果不相交那就简单了,我们直接返回父节点的父节点,在另一个子树继续搜索最近邻.当回溯到根节点时,算法结束,此时保存的最近邻节点就是最终的最近邻.</p>

<p>具体过程如图所示<br/>
<img src="media/15277324362749/15277426727922.jpg" alt=""/></p>

<p><img src="media/15277324362749/15278221391077.jpg" alt=""/></p>

<h1 id="toc_9">参考引用</h1>

<ul>
<li><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E8%BF%91%E9%84%B0%E5%B1%85%E6%B3%95">KNN wiki</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/6061661.html">K近邻法(KNN)原理小结</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[逻辑回归]]></title>
    <link href="http://dmlcoding.com/15198753668603.html"/>
    <updated>2018-03-01T11:36:06+08:00</updated>
    <id>http://dmlcoding.com/15198753668603.html</id>
    <content type="html"><![CDATA[
<p>不知道什么是逻辑回归,但是也许看完接下来的文章,你会有个大概的印象吧</p>

<h1 id="toc_0">简单介绍Logistic回归</h1>

<h2 id="toc_1">Logistic回归用到的知识点</h2>

<ul>
<li>Sigmoid函数和Logistic回归分类器</li>
<li>最优化理论初步</li>
<li>梯度下降最优化算法</li>
<li>数据中的缺失项处理</li>
</ul>

<span id="more"></span><!-- more -->

<h2 id="toc_2">Logistic回归的一般过程</h2>

<ul>
<li>1.收集数据:采用任意方法收集数据</li>
<li>2.准备数据:由于需要进行距离计算,因此要求数据类型为数值型.另外,结构化数据格式则最佳.</li>
<li>3.分析数据:采用任意方法对数据进行分析.</li>
<li>4.训练算法:大部分时间将用于训练,训练的目的是为了找到最佳的分类回归系数.</li>
<li>5.使用算法:首先,我们需要一些输入数据,并将其转换成对应的结构化数值;接着,基于训练好的回归系数就可以对这些数值进行简单的回归计算,判定他们属于哪个类别;在这之后,我们就可以在输出的类别上做一些其他分析工作.</li>
</ul>

<h1 id="toc_3">基于Logistic回归和Sigmoid函数的分类</h1>

<h2 id="toc_4">Logistic回归</h2>

<ul>
<li>优点
<ul>
<li>计算代价不高</li>
<li>易于理解和实现</li>
</ul></li>
<li>缺点
<ul>
<li>容易欠拟合</li>
<li>分类精度可能不高</li>
</ul></li>
<li>适用类型
<ul>
<li>数值型(数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析))</li>
<li>标称型数据(标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类))</li>
</ul></li>
</ul>

<p>基本公式:<br/>
Sigmoid函数具体的计算公式</p>

<p>\[p=h_{\theta}(x)=g(\theta^Tx)=\dfrac{1}{1+e^{-\theta^Tx}}\]<br/>
\[g(z)=\dfrac{1}{1+e^{-z}}\]</p>

<p><img src="media/15198753668603/15253390268591.jpg" alt=""/></p>

<p>\[<br/>
\begin{aligned}<br/>
g^{&#39;}(X)&amp; =\left(\dfrac{1}{1+e^{-z}}\right)^{&#39;} \\\<br/>
&amp; = \dfrac{e^{-z}}{(1+e^{-z})^2} \\\<br/>
&amp; = \dfrac{1}{1+e^{-z}}\cdot \dfrac{e^{-z}}{1+e{-z}} \\\<br/>
&amp; = \dfrac{1}{1+e^{-z}}\cdot \left(1-\dfrac{1}{1+e^{-z}}\right) \\\<br/>
&amp; = g(z)\cdot (1-g(z))<br/>
\end{aligned}<br/>
\]</p>

<h2 id="toc_5">logistic 回归及似然函数</h2>

<p>假设<br/>
\[<br/>
\begin{aligned}<br/>
P(y=1|x;\theta)&amp; =h_{\theta}(x) \\\<br/>
P(y=0|x;\theta)&amp; =1-h_{\theta}(x) \\\<br/>
P(y|x;\theta)&amp; =(h_{\theta}(x))^y(1-h_{\theta}(x))^{(1-y)}<br/>
\end{aligned}<br/>
\]</p>

<p>似然函数:<br/>
\[<br/>
\begin{aligned}<br/>
L(\theta) &amp; =p(\vec{y}|X;\theta) \\\<br/>
&amp; =\prod_{i=1}^m p(y^{(i)}|x^{(i)};\theta) \\\<br/>
&amp; = \prod_{i=1}^m (h_{\theta}(x^{(i)}))^{y^{(i)}}(1-h_{\theta}(x^{(i)}))^{(1-y^{(i)})}<br/>
\end{aligned}<br/>
\]</p>

<p>对数似然函数:<br/>
\[<br/>
\begin{aligned}<br/>
\ell(\theta) &amp; =\log L(\theta) \\\<br/>
&amp; = \sum_{i=1}^m\left(y^{(i)}\log h_{\theta}(x^{(i)})+(1-y^{(i)})\log (1-h_{\theta}(x^{(i)}))\right)<br/>
\end{aligned}<br/>
\]</p>

<p>最大似然/极大似然函数的随机梯度</p>

<p><img src="media/15198753668603/15350010973220.jpg" alt="" style="width:809px;"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[梯度下降笔记]]></title>
    <link href="http://dmlcoding.com/15277385790025.html"/>
    <updated>2018-05-31T11:49:39+08:00</updated>
    <id>http://dmlcoding.com/15277385790025.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[什么是最小二乘法]]></title>
    <link href="http://dmlcoding.com/15299158833805.html"/>
    <updated>2018-06-25T16:38:03+08:00</updated>
    <id>http://dmlcoding.com/15299158833805.html</id>
    <content type="html"><![CDATA[
<p>最小二乘法(又称最小平方法)是一种数学优化技术.他通过最小化误差的平方和寻找数据的最佳函数匹配.</p>

<p>利用最小二乘法可以简便地求得未知的数据,并使得这些求得的数据与实际数据之间误差的平方和为最小.</p>

<p><img src="media/15294841337807/15296334116393.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[回归算法]]></title>
    <link href="http://dmlcoding.com/15248143200628.html"/>
    <updated>2018-04-27T15:32:00+08:00</updated>
    <id>http://dmlcoding.com/15248143200628.html</id>
    <content type="html"><![CDATA[
<p>总结一下,这一节主要记录了下面的内容</p>

<ol>
<li>什么是回归算法.</li>
<li>线性回归,单变量线性回归,多变量线性回归</li>
<li>代价函数</li>
<li>过拟合与欠拟合</li>
<li>正则项</li>
</ol>

<p>在这篇文章中,主要介绍了什么是回归算法,以及简单的线性回归.包括单变量线性回归和多变量线性回归.</p>

<p>同时介绍了用最小二乘法求解\(\theta\)值.接下介绍了防止过拟合问题,加入正则项.</p>

<p>最后介绍了如何评价模型的效果.</p>

<h1 id="toc_0">什么是回归算法</h1>

<ol>
<li>回归算法是一种有监督算法;</li>
<li>回归算法是一种比较常用的机器学习算法,用于建立解释变量(自变量X)和观测值(因变量Y)之间的关系;</li>
<li>从机器学习的角度来讲,用于构建一个算法模型(函数)来做属性(X)与标签(Y)之间的映射关系,在算法的学习过程中,试图寻找一个函数h:使得\(R^d\to R\)使得参数之间的关系拟合性最好;</li>
<li>回归算法中,算法(函数)的最终结果是一个<strong>连续</strong>的数据值,输入值(属性值)是一个d维度的属性/数值向量;</li>
<li>因此,回归算法是用于预测连续型数值输出的算法.</li>
</ol>

<p>常用的回归算法有几种:比如,线性回归,Logistic回归,Softmax回归等等.先说最简单的线性回归算法.</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">线性回归</h2>

<p>一个很常见的例子,根据房屋面积来预测房价(不考虑其他的环境因素).</p>

<p>假如我们有一些关于房屋面积和租赁价格的数据,比如</p>

<table>
<thead>
<tr>
<th>房屋面积(m<sup>2)</sup></th>
<th>租赁价格(1000/元)</th>
</tr>
</thead>

<tbody>
<tr>
<td>10</td>
<td>0.8</td>
</tr>
<tr>
<td>15</td>
<td>1</td>
</tr>
<tr>
<td>20</td>
<td>1.8</td>
</tr>
<tr>
<td>30</td>
<td>2</td>
</tr>
<tr>
<td>50</td>
<td>3.2</td>
</tr>
<tr>
<td>60</td>
<td>3</td>
</tr>
<tr>
<td>60</td>
<td>3.1</td>
</tr>
<tr>
<td>70</td>
<td>3.5</td>
</tr>
</tbody>
</table>

<p>那么一个问题来了,请问,如果现在有一个房屋面积为55平,请问最终的租赁价格是多少比较合适呢?</p>

<p>这个数据里面只有1个条件.很显然,在生活中,房价是和很多因素相关,比如房屋的面积,房间的数量,地理位置等等.</p>

<p>那么第一个例子,其实就是单变量线性回归.第二个当然就是多变量线性回归了.</p>

<p>公式描述如下:</p>

<p>\[<br/>
\begin{aligned}<br/>
h_{\theta}(x)&amp; =\theta_0+\theta_1x_1+\cdots+\theta_nx_n \\\<br/>
&amp; = \theta_01+\theta_1x_1+\cdots+\theta_nx_n \\\<br/>
&amp; = \theta_0x_0+\theta_1x_1+\cdots+\theta_nx_n \\\<br/>
&amp; = \sum_{i=0}^n\theta_ix_i \\\<br/>
&amp; = \theta^Tx<br/>
\end{aligned}<br/>
\]</p>

<p>所以在线性回归中,最终的要求也就是计算出\(\theta\)值,并选择最优的\(\theta\)值构成算法公式.</p>

<p>这里就涉及到两个问题:</p>

<ol>
<li>计算出\(\theta\)值;</li>
<li>选择最优的\(\theta\)值.</li>
</ol>

<p>对于第一个问题,在机器学习中,一般都是用列向量表示数据,因此公式的最后两行,也就是将第一个列向量转置成为行向量.这样就可以转换成一个行向量与列向量相乘,也就是矩阵相乘了.公式描述就能直观了.</p>

<p>对于第二个问题,就是找代价函数的最小值.后面会说到.</p>

<h3 id="toc_2">单变量线性回归</h3>

<p>因为只含有一个特征/输入变量,因此这样的问题叫做单变量线性回归问题.</p>

<p>公式描述如下:</p>

<p>\[h_{\theta}=\theta_0+ \theta_1x\]</p>

<h3 id="toc_3">多变量线性回归</h3>

<p>公式如下:<br/>
\[h_{\theta}(x) =\theta_0+\theta_1x_1+\cdots+\theta_nx_n\]</p>

<h1 id="toc_4">代价函数(Cost Function)</h1>

<p>我们选择的参数\(\theta\)决定了我们得到的直线相对于我们的训练集的准确程度,模型所预测的值与训练集中实际值之间的差距就是建模误差(modeling error).</p>

<p>我们的目标便是选择出可以使得<strong>建模误差的平方和</strong>能够<strong>最小</strong>的<strong>模型参数</strong>.<strong>即使得代价函数最小</strong>.</p>

<p>\[J(\theta_0,\theta_1)=\dfrac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\]</p>

<p>\(h_{\theta}(x^{(i)})\)也就是我们的回归函数,即预测值.\(y^{(i)}\)是数据给定的真实值.</p>

<p>接下来说一下公式的推导过程</p>

<h1 id="toc_5">公式推导</h1>

<h2 id="toc_6">原理说明</h2>

<p>很显然,不可能找到一个算法可以百分百的预测正确,而且在实际问题中,总会有一些因素会造成误差.因此我们给线性回归的公式加上一个误差函数\(\epsilon^{(i)}\),这样就更合理了.</p>

<p>\[y^{(i)}=\theta^Tx^{(i)}+\epsilon^{(i)}\]</p>

<p><strong>补充说明</strong>:\(\epsilon^{(i)}(1\leq i \leq n)\)是独立同分布的,服从均值为0,方差为某定值\(\sigma^2\)的高斯分布.实际问题中,很多随机现象可以看到看到众多因素的独立影响的综合反应,往往服从正态分布.原理是因为中心极限定理.</p>

<p>因为,误差函数服从高斯分布,因此\(p(\epsilon^{(i)})=\frac{1}{\sqrt{2\pi}\sigma}e^{\left(-\dfrac{(\epsilon^{(i)})^2}{2\sigma^2}\right)}\)</p>

<p>因此,咱们也可以说是在某个因素发生的条件下,y发生的概率.所以可以改写成\(p(y^{(i)}|x^{(i)};\theta)=\frac{1}{\sqrt{2\pi}\sigma}e^{\left(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)}\)</p>

<p>最后,根据极大似然函数方法,咱们来求解这个\(\theta\)值.</p>

<h2 id="toc_7">\(\theta\)值推导过程以及求解</h2>

<p>根据极大似然函数,来求解\(\theta\)值,那么将公式改写成</p>

<p>\[\begin{aligned}<br/>
L(\theta)&amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta)\\\<br/>
&amp; = \prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}e^{\left(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)}<br/>
\end{aligned}\]</p>

<p>最大似然,也就是要使这个方程的结果最大.连乘不好求,一般都是对连乘取对数.</p>

<p>现在转成求对数似然</p>

<p>\[<br/>
\begin{align}<br/>
\ell(\theta)&amp; =\log L(\theta) \\\<br/>
&amp; = \log\prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}e^{\Big(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\Big)} \\\<br/>
&amp; = \sum_{i=1}^m\log\frac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^m \log e^{\Big(-\dfrac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\Big)} \\\<br/>
&amp; = m\log\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{\sigma^2}\cdot\frac{1}{2}\sum_{i=1}^m\Big(y^{(i)}-\theta^Tx{(i)}\Big)^2<br/>
\end{align}<br/>
\]</p>

<p>因为\(m\log\frac{1}{\sqrt{2\pi}\sigma}\)是一个常数,要使\(\ell(\theta)\)最大,那么也就是使这个式子的结果最小.保留\(\dfrac 12\)是因为求导求最小值的时候会约去参数.</p>

<p>这样就得到了我们的损失函数:<br/>
\[loss(y_j,\hat{y_j})=J(\theta)=\frac{1}{2}\sum_{i=1}^{m}\left(h_\theta(x^{(i)}-y^{(i)})\right)^2\]</p>

<p>我们的目标是最小化损失函数.</p>

<p>注意:矩阵的平方也等于矩阵的转置乘以矩阵.</p>

<p>\[J(\theta)=\cfrac{1}{2}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2=\cfrac{1}{2}(X\theta-Y)^T(X\theta-Y) \to \min \limits_{\theta}J(\theta)\]</p>

<p>既然是求最小值,那么肯定是通过求导来计算.对这个损失函数进行求导运算.</p>

<p>\[<br/>
\begin{aligned}<br/>
\nabla J(\theta)&amp; =\nabla_{\theta}\Big(\cfrac{1}{2}(X\theta-Y)^T(X\theta-Y)\Big) \\\<br/>
&amp; = \nabla_{\theta}\Big(\cfrac{1}{2}(\theta^TX^T-Y^T)(X\theta-Y)\Big) \\\<br/>
&amp; = \nabla_{\theta}\Big(\cfrac{1}{2}(\theta^TX^TX\theta-\theta^TX^TY-Y^TX\theta+Y^TY)\Big) \\\<br/>
&amp; = \cfrac{1}{2}\Big(2X^TX\theta-X^T-(Y^TX)^T\Big) \\\<br/>
&amp; = X^TX\theta-X^TY<br/>
\end{aligned}<br/>
\]</p>

<p>因此求解\(\theta\)的公式就推导出来了(最小二乘法).</p>

<p>\[\theta=(X^TX)^{-1}X^TY\]</p>

<h2 id="toc_8">公式验证</h2>

<p>求解\(\theta\)值的公式已经推导出来了,那让我们来校验一下,是否正确呢?</p>

<p>用python的科学计算包可以很方便的来做科学计算,废话不多说看代码吧.</p>

<p>1.构造测试数据</p>

<pre class="line-numbers"><code class="language-python">import numpy as np
import pandas as pd

# 构造测试数据y=3x1+x2
df=pd.DataFrame({
    &quot;x1&quot;:[1,2,3,4,5,6],
    &quot;x2&quot;:[1,2,1,2,1,2],
    &quot;y&quot;:[3,6,7,10,11,14]
})

</code></pre>

<p>2.抽取x和y</p>

<pre class="line-numbers"><code class="language-python"># 抽取x和y
x=df[[&#39;x1&#39;,&#39;x2&#39;]]
# 将y转换成n行1列的列向量
y=df[&#39;y&#39;].values.reshape((-1,1))

</code></pre>

<p>3.求解\(\theta\) 值</p>

<p><em>根据公式计算\(\theta\)</em>值,推导过程上面已经详述了.<br/>
\[\theta=(X^TX)^{-1}X^TY\]</p>

<p><em>numpy</em> api说明:</p>

<ul>
<li>mat:将ndarray转成matrix</li>
<li>dot:矩阵乘法</li>
<li>T:求矩阵的转置</li>
<li>I:求矩阵的逆</li>
</ul>

<pre class="line-numbers"><code class="language-python"># 将公式转成python代码,计算theta值

np.dot(np.mat(x.T.dot(x)).I,x.T).dot(y)
</code></pre>

<p>4.结果输出</p>

<pre class="line-numbers"><code class="language-text">    matrix([[ 2.],
            [ 1.]])
</code></pre>

<p>很明显,计算结果正确.两个系数分别是2和1</p>

<h1 id="toc_9">最小二乘法的参数最优解</h1>

<p>求解\(\theta\)的公式为\(\theta=(X^TX)^{-1}X^TY\).但是最小二乘法的使用要求矩阵\(X^TX\)是可逆的.</p>

<p>为了防止不可逆或者过拟合的问题存在,可以<strong>增加额外数据影响</strong>,导致最终的矩阵是可逆的.</p>

<p>\[\theta=(X^TX+\lambda I)^{-1}X^TY\]</p>

<p>注意:最小二乘法直接求解的难点:矩阵逆的求解是一个难处.<br/>
因此,后面会说到另一种求解办法,即,梯度下降法来求解.</p>

<h1 id="toc_10">线性回归案例</h1>

<p><strong>数据来源</strong>:<a href="https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption">https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption</a></p>

<p>数据描述:现有一批描述家庭用电情况的数据,对数据进行算法模型预测,并最终得到预测模型(每天各个时间段和功率之间的关系,功率与电流之间的关系等)</p>

<p><img src="media/15248143200628/15264383529325.jpg" alt=""/></p>

<p>我们使用 <code>sklearn</code> 库中的 <code>linear_model</code> 中的 <code>LinerRegression</code>来获取算法,让我们来做一个成功的<code>调包侠</code>,哈哈哈哈.</p>

<h2 id="toc_11">线性回归预测时间和功率之间的关系</h2>

<p>虽然调api不用我们来实现算法的实现了,但是学习的过程还是应该掌握公式的推导比较好.</p>

<p>代码示例如下(机器学习的简单开发流程):</p>

<pre class="line-numbers"><code class="language-text"># -*- coding: utf-8 -*-
&#39;&#39;&#39;
    Created by hushiwei on 2018/4/27.

    1:时间与功率之间的关系
&#39;&#39;&#39;

import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 设置字符集,防止中文乱码
mpl.rcParams[&#39;font.sans-serif&#39;]=[u&#39;simHei&#39;]
mpl.rcParams[&#39;axes.unicode_minus&#39;]=False


# 加载数据
df = pd.read_csv(
    &quot;/Users/hushiwei/PycharmProjects/Python-AI/MachineLearning/LinearRegression/datas/household_power_consumption_1000.txt&quot;,
    sep=&quot;;&quot;)
print(df.head())

# 异常数据处理
new_df = df.replace(&#39;?&#39;, np.nan)
datas = new_df.dropna(axis=0, how=&#39;any&#39;)

# 观察数据

print(datas.describe())


# 处理时间

def date_format(dt):
    import time
    t = time.strptime(&#39; &#39;.join(dt), &#39;%d/%m/%Y %H:%M:%S&#39;)
    return (t.tm_year, t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec)


# 获取X和Y,并将时间转换为数值型变量
# X:时间
# Y:用电量

X=datas.iloc[:,0:2]
X=X.apply(lambda x:pd.Series(date_format(x)),axis=1)
Y=datas[&#39;Global_active_power&#39;]


print(X.head())
print(Y.head())


# 划分数据集
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

# 对数据进行标准化
ss=StandardScaler()

# 训练并转换
X_train=ss.fit_transform(X_train)
# 直接使用在模型构建数据上进行一个数据标准化操作
X_test=ss.transform(X_test)

# 这里,fit_transform和transform的区别?
# fit_tranform是计算并转换,在这个过程中会计算出均值和方差,然后将变量进行标准化去量纲
# transform是转换,它将用上面计算出的均值和方差来进行标准化去量纲.
# 因为训练集的数据相较于测试集更多 ,所以测试集也延用训练集算出来的均值和方差
# 因此fit_transform在transform上面调用

# 模型训练

liner=LinearRegression()
liner.fit(X_train,Y_train)


# 模型校验

y_predict=liner.predict(X_test)
time_name=[&#39;年&#39;,&#39;月&#39;,&#39;日&#39;,&#39;时&#39;,&#39;分&#39;,&#39;秒&#39;]
print(&quot;准确率:&quot;,liner.score(X_train,Y_train))
mse=np.average((y_predict-Y_test)**2)
rmse=np.sqrt(mse)
print(&#39;rmse:&#39;,rmse)
print(&quot;特征的系数为:&quot;,list(zip(time_name,liner.coef_)))

# 模型保存

# from sklearn.externals import joblib
#
# joblib.dump(ss,&quot;data_ss.model&quot;) ## 将标准化模型保存
# joblib.dump(liner,&quot;data_lr.model&quot;) ## 将模型保存
#
# joblib.load(&quot;data_ss.model&quot;) ## 加载模型
# joblib.load(&quot;data_lr.model&quot;) ## 加载模型

# 预测值和实际值可视化画图比较

t=np.arange(len(X_test))
plt.figure(facecolor=&#39;w&#39;)
plt.plot(t,Y_test,&#39;r-&#39;,linewidth=2,label=&#39;真实值&#39;)
plt.plot(t,y_predict,&#39;g-&#39;,linewidth=2,label=&#39;预测值&#39;)
plt.legend(loc=&#39;upper left&#39;)
plt.title(&quot;线性回归预测时间与功率之间的关系&quot;,fontsize=20)
plt.grid(b=True)
plt.show()

</code></pre>

<p>结果输出:</p>

<pre class="line-numbers"><code class="language-text">准确率: 0.24409311805909026
rmse: 1.164092345973625
特征的系数为: [(&#39;年&#39;, 0.0), (&#39;月&#39;, 1.1102230246251565e-16), (&#39;日&#39;, -1.415881661733238), (&#39;时&#39;, -0.9349532432495644), (&#39;分&#39;, -0.10214075598497), (&#39;秒&#39;, 0.0)]
</code></pre>

<p>可视化显示:</p>

<p><img src="media/15248143200628/15264444548035.jpg" alt=""/></p>

<p>从这个结果可以看出,预测效果不太好,可能是时间与功率没啥关系,我们现在换一下因变量与自变量</p>

<h2 id="toc_12">线性回归预测功率与电流之间的关系</h2>

<p>代码示例:</p>

<pre class="line-numbers"><code class="language-text"># -*- coding: utf-8 -*-
&#39;&#39;&#39;
    Created by hushiwei on 2018/4/27.

    desc: 功率与电流之间的关系
&#39;&#39;&#39;

import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 设置字符集,防止中文乱码
mpl.rcParams[&#39;font.sans-serif&#39;]=[u&#39;simHei&#39;]
mpl.rcParams[&#39;axes.unicode_minus&#39;]=False


# 加载数据
df = pd.read_csv(
    &quot;/Users/hushiwei/PycharmProjects/Python-AI/MachineLearning/LinearRegression/datas/household_power_consumption_1000.txt&quot;,
    sep=&quot;;&quot;)
print(df.head())

# 异常数据处理
new_df = df.replace(&#39;?&#39;, np.nan)
datas = new_df.dropna(axis=0, how=&#39;any&#39;)

# 观察数据

print(datas.describe())



X=datas.iloc[:,2:4]
Y=datas.iloc[:,5]


print(X.head())
print(Y.head())


# 划分数据集
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

# 对数据进行标准化
ss=StandardScaler()

# 训练并转换
X_train=ss.fit_transform(X_train)
# 直接使用在模型构建数据上进行一个数据标准化操作
X_test=ss.transform(X_test)

# 这里,fit_transform和transform的区别?
# fit_tranform是计算并转换,在这个过程中会计算出均值和方差,然后将变量进行标准化去量纲
# transform是转换,它将用上面计算出的均值和方差来进行标准化去量纲.
# 因为训练集的数据相较于测试集更多 ,所以测试集也延用训练集算出来的均值和方差
# 因此fit_transform在transform上面调用

# 模型训练

liner=LinearRegression()
liner.fit(X_train,Y_train)


# 模型校验

y_predict=liner.predict(X_test)
print(&quot;电流训练准确率: &quot;,liner.score(X_train,Y_train))
print(&quot;电流预测准确率: &quot;,liner.score(X_test,Y_test))
print(&quot;电流参数: &quot;,liner.coef_)



# 预测值和实际值可视化画图比较

t=np.arange(len(X_test))
plt.figure(facecolor=&#39;w&#39;)
plt.plot(t,Y_test,&#39;r-&#39;,linewidth=2,label=&#39;真实值&#39;)
plt.plot(t,y_predict,&#39;g-&#39;,linewidth=2,label=&#39;预测值&#39;)
plt.legend(loc=&#39;upper left&#39;)
plt.title(&quot;线性回归预测时间与功率之间的关系&quot;,fontsize=20)
plt.grid(b=True)
plt.show()

</code></pre>

<p>模型预测结果</p>

<pre class="line-numbers"><code class="language-text">电流训练准确率:  0.9909657573073489
电流预测准确率:  0.9920420609708968
电流参数:  [5.07744316 0.07191391]
</code></pre>

<p><img src="media/15248143200628/15264449452427.jpg" alt=""/></p>

<p>从图中也可以看出,效果很明显,预测得非常好.</p>

<h1 id="toc_13">线性回归的过拟合和正则项</h1>

<p>我们用线性回归的时候,可能拟合的不是那么好,那么可以加大阶数,去拟合.</p>

<p>但是也不是阶数越高效果越好.为什么这么说呢?看例子分析.</p>

<p>我们的目标函数是(之前已经写过推导过程):<br/>
\[J(\theta)=\dfrac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\]</p>

<p>为了防止数据过拟合,也就是\(\theta\)值在样本空间中不能过大/过小,可以在目标函数之上增加一个平方和损失:<br/>
\[J(\theta)=\dfrac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2+\lambda\sum_{i=1}^n\theta_j^2\]</p>

<p>我们如果对这个函数进行求导计算会得出之前写的一个函数,即<br/>
\[\theta=(X^TX+\lambda I)^{-1}X^TY\]</p>

<p>注意:这里新加的\(\lambda\sum_{i=1}^n\theta_j^2\),也叫正则项(norm).这里的这个正则项叫做L2-norm.所以还有其他的正则项,且看后续说明.</p>

<h2 id="toc_14">正则项</h2>

<p><strong>L2正则(L2-norm)</strong>:\(\lambda\sum_{i=1}^n\theta_j^2 \quad \lambda &gt; 0\)</p>

<p><strong>L1正则(L1-norm)</strong>:\(\lambda\sum_{i=1}^n|\theta_j| \quad \lambda &gt; 0\)</p>

<h2 id="toc_15">Ridge回归</h2>

<p>使用L2正则的线性回归模型就称为Ridge回归(也叫岭回归)<br/>
\[J(\theta)=\dfrac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2+\lambda\sum_{i=1}^n\theta_j^2 \qquad \lambda &gt; 0\]</p>

<h2 id="toc_16">Lasso回归</h2>

<p>使用L1正则的线性回归模型就称为LASSO回归(Least Absolute Shrinkage and Selection Operator)<br/>
\[J(\theta)=\dfrac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2+\lambda\sum_{i=1}^n|\theta_j| \qquad \lambda &gt; 0\]</p>

<h2 id="toc_17">Ridge(L2-norm)和LASSO(L1-norm)比较</h2>

<p>L2-norm中,由于对于各个维度的参数缩放是在一个圆内缩放的,不可能导致有维度参数变为0的情况,那么也就不会产生稀疏解;实际应用中,数据的维度中是存在噪音和冗余的,稀疏的解可以找到有用的维度并且减少冗余,提高回归预测的准确性和鲁棒性(减少了overfitting)(L1-norm可以达到最终解的稀疏性的要求)</p>

<p>Ridge模型具有较高的准确性,鲁棒性以及稳定性;LASSO模型具有较高的求解速度.</p>

<p>如果既要考虑稳定性也考虑求解的速度,就使用Elastic Net<br/>
<img src="media/15248143200628/15265465368148.jpg" alt=""/></p>

<h2 id="toc_18">Elastic Net</h2>

<p>同时使用L1正则和L2正则的线性回归模型就称为Elastic Net算法(弹性网络算法)</p>

<p>\[J(\theta)=\dfrac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2+\lambda \left(p\sum_{j=1}^n|\theta_j| +(1-p)\sum_{j=1}^n\theta_j^2 \right) \qquad \lambda &gt; 0 , p \in [0,1]\]</p>

<h1 id="toc_19">模型效果判断</h1>

<p>MSE:误差平方和,越趋近于0表示模型越拟合训练数据<br/>
\[MSE=\dfrac{1}{m}\sum_{i=1}^m(y_i-\hat y_i)^2\]</p>

<p>RMSE:MSE的平方根,作用同MSE<br/>
\[RMSE=\sqrt{MSE}=\sqrt{\dfrac{1}{m}\sum_{i=1}^m(y_i-\hat y_i)^2}\]</p>

<p>\(R^2\):取值范围(负无穷,1],值越大表示模型越拟合训练数据;最优解是1;当模型预测为随机值的时候,有可能为负;若预测值恒为样本期望,\(R^2\)为0</p>

<p>TSS:总平方和TSS(Total Sum Of Squares),表示样本之间的差异情况,是伪方差的m倍.</p>

<p>RSS:残差平方和RSS(Residual Sum Of Squares),表示预测值和样本值之间的差异情况,是MSE的m倍</p>

<p>\[R^2=1-\dfrac{RSS}{TSS}=1-\dfrac{\sum_{i=1}^m(y_i-\hat y_i)^2}{\sum_{i=1}^m(y_i-\overline y)^2} \qquad \overline y=\dfrac{1}{m}\sum_{i=1}^my_i\]</p>

<h1 id="toc_20">机器学习调参</h1>

<h2 id="toc_21">调参</h2>

<p>在实际工作中,对于各种算法模型(线性回归)来讲,我们需要获取\(\theta,\lambda,p\)的值;\(\theta\)的求解其实就是算法模型的求解,一般不需要开发人员参与(算法已经实现),主要需要求解的是\(\lambda\)和p的值,这个过程就叫做<strong>调参(超参)</strong></p>

<h2 id="toc_22">交叉验证</h2>

<p>将训练数据分为多份,其中一份进行数据验证并获取最优的超参:\(\lambda\)和p;比如:十折交叉验证,五折交叉验证(scikit-learn中默认)等</p>

<p><img src="media/15248143200628/15267171709516.jpg" alt=""/></p>

]]></content>
  </entry>
  
</feed>
